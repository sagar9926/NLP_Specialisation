{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week2_HiddenStateActivation and Perplexity calculation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO/5wBGoVElYgyb8p20ybKX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagar9926/NLP_Specialisation/blob/main/SequenceModelling/Week2_HiddenStateActivation_and_Perplexity_calculation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nm0Cuzmud80Z"
      },
      "source": [
        "# Hidden State Activation : Ungraded Lecture Notebook\n",
        "\n",
        "In this notebook you'll take another look at the hidden state activation function. It can be written in two different ways. \n",
        "\n",
        "I'll show you, step by step, how to implement each of them and then how to verify whether the results produced by each of them are same or not.\n",
        "\n",
        "## Background\n",
        "\n",
        "![vanilla rnn](https://github.com/amanjeetsahu/Natural-Language-Processing-Specialization/raw/d562105e68a0b85012ad3ebbb29b2af6344ad4e5/Natural%20Language%20Processing%20with%20Sequence%20Models/Week%202/vanilla_rnn.PNG)\n",
        "\n",
        "\n",
        "This is the hidden state activation function for a vanilla RNN.\n",
        "\n",
        "$h^{<t>}=g(W_{h}[h^{<t-1>},x^{<t>}] + b_h)$                                                    \n",
        "\n",
        "Which is another way of writing this:         \n",
        "\n",
        "$h^{<t>}=g(W_{hh}h^{<t-1>} \\oplus W_{hx}x^{<t>} + b_h)$                                        \n",
        "\n",
        "Where \n",
        "\n",
        "- $W_{h}$ in the first formula is denotes the *horizontal* concatenation of $W_{hh}$ and $W_{hx}$ from the second formula.\n",
        "\n",
        "- $W_{h}$ in the first formula is then multiplied by $[h^{<t-1>},x^{<t>}]$, another concatenation of parameters from the second formula but this time in a different direction, i.e *vertical*!\n",
        "\n",
        "Let us see what this means computationally.\n",
        "\n",
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXkg4eIndgTi"
      },
      "source": [
        "import numpy as np\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZstGHqAeX4f"
      },
      "source": [
        "## Joining (Concatenation)\n",
        "\n",
        "### Weights\n",
        "\n",
        "A join along the vertical boundary is called a *horizontal concatenation* or *horizontal stack*. \n",
        "\n",
        "Visually, it looks like this:- $W_h = \\left [ W_{hh} \\ | \\ W_{hx} \\right ]$\n",
        "\n",
        "I'll show you two different ways to achieve this using numpy.\n",
        "\n",
        "__Note: The values used to populate the arrays, below, have been chosen to aid in visual illustration only. They are NOT what you'd expect to use building a model, which would typically be random variables instead.__\n",
        "\n",
        "* Try using random initializations for the weight arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iUQEPt2eP04",
        "outputId": "932a95c0-b05a-4074-db12-8c65f582abd1"
      },
      "source": [
        "# Create some dummy data\n",
        "\n",
        "# w_hh = np.full((3, 2), 1)  # illustration purposes only, returns an array of size 3x2 filled with all 1s\n",
        "# w_hx = np.full((3, 3), 9)  # illustration purposes only, returns an array of size 3x3 filled with all 9s\n",
        "\n",
        "\n",
        "### START CODE HERE ###\n",
        "# Try using some random initializations, though it will obfuscate the join. eg: uncomment these lines\n",
        "w_hh = np.random.standard_normal((3,2))\n",
        "w_hx = np.random.standard_normal((3,3))\n",
        "### END CODE HERE ###\n",
        "\n",
        "print(\"-- Data --\\n\")\n",
        "print(\"w_hh :\")\n",
        "print(w_hh)\n",
        "print(\"w_hh shape :\", w_hh.shape, \"\\n\")\n",
        "print(\"w_hx :\")\n",
        "print(w_hx)\n",
        "print(\"w_hx shape :\", w_hx.shape, \"\\n\")\n",
        "\n",
        "# Joining the arrays\n",
        "print(\"-- Joining --\\n\")\n",
        "# Option 1: concatenate - horizontal\n",
        "w_h1 = np.concatenate((w_hh, w_hx), axis=1)\n",
        "print(\"option 1 : concatenate\\n\")\n",
        "print(\"w_h :\")\n",
        "print(w_h1)\n",
        "print(\"w_h shape :\", w_h1.shape, \"\\n\")\n",
        "\n",
        "# Option 2: hstack\n",
        "w_h2 = np.hstack((w_hh, w_hx))\n",
        "print(\"option 2 : hstack\\n\")\n",
        "print(\"w_h :\")\n",
        "print(w_h2)\n",
        "print(\"w_h shape :\", w_h2.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Data --\n",
            "\n",
            "w_hh :\n",
            "[[-1.1602095   1.07698639]\n",
            " [ 0.53377345  0.37280108]\n",
            " [-1.69456594  0.39087425]]\n",
            "w_hh shape : (3, 2) \n",
            "\n",
            "w_hx :\n",
            "[[-1.50859014 -0.55515867 -0.38592884]\n",
            " [-0.42146834  0.93811223 -0.54972085]\n",
            " [ 0.70142032  0.41936974  0.65612773]]\n",
            "w_hx shape : (3, 3) \n",
            "\n",
            "-- Joining --\n",
            "\n",
            "option 1 : concatenate\n",
            "\n",
            "w_h :\n",
            "[[-1.1602095   1.07698639 -1.50859014 -0.55515867 -0.38592884]\n",
            " [ 0.53377345  0.37280108 -0.42146834  0.93811223 -0.54972085]\n",
            " [-1.69456594  0.39087425  0.70142032  0.41936974  0.65612773]]\n",
            "w_h shape : (3, 5) \n",
            "\n",
            "option 2 : hstack\n",
            "\n",
            "w_h :\n",
            "[[-1.1602095   1.07698639 -1.50859014 -0.55515867 -0.38592884]\n",
            " [ 0.53377345  0.37280108 -0.42146834  0.93811223 -0.54972085]\n",
            " [-1.69456594  0.39087425  0.70142032  0.41936974  0.65612773]]\n",
            "w_h shape : (3, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u9Q4_Uk0m44"
      },
      "source": [
        "### Hidden State & Inputs\n",
        "Joining along a horizontal boundary is called a vertical concatenation or vertical stack. Visually it looks like this:\n",
        "\n",
        "$[h^{<t-1>},x^{<t>}] = \\left[ \\frac{h^{<t-1>}}{x^{<t>}} \\right]$\n",
        "\n",
        "\n",
        "I'll show you two different ways to achieve this using numpy.\n",
        "\n",
        "*Try using random initializations for the hiddent state and input matrices.*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ye-ZjaZtfBDY",
        "outputId": "fb13fb60-f0dc-455b-dc1b-112190b5f77e"
      },
      "source": [
        "# Create some more dummy data\n",
        "h_t_prev = np.full((2, 1), 1)  # illustration purposes only, returns an array of size 2x1 filled with all 1s\n",
        "x_t = np.full((3, 1), 9)       # illustration purposes only, returns an array of size 3x1 filled with all 9s\n",
        "\n",
        "# Try using some random initializations, though it will obfuscate the join. eg: uncomment these lines\n",
        "\n",
        "### START CODE HERE ###\n",
        "# h_t_prev = np.random.standard_normal((2,1))\n",
        "# x_t = np.random.standard_normal((3,1))\n",
        "### END CODE HERE ###\n",
        "\n",
        "print(\"-- Data --\\n\")\n",
        "print(\"h_t_prev :\")\n",
        "print(h_t_prev)\n",
        "print(\"h_t_prev shape :\", h_t_prev.shape, \"\\n\")\n",
        "print(\"x_t :\")\n",
        "print(x_t)\n",
        "print(\"x_t shape :\", x_t.shape, \"\\n\")\n",
        "\n",
        "# Joining the arrays\n",
        "print(\"-- Joining --\\n\")\n",
        "\n",
        "# Option 1: concatenate - vertical\n",
        "ax_1 = np.concatenate(\n",
        "    (h_t_prev, x_t), axis=0\n",
        ")  # note the difference in axis parameter vs earlier\n",
        "print(\"option 1 : concatenate\\n\")\n",
        "print(\"ax_1 :\")\n",
        "print(ax_1)\n",
        "print(\"ax_1 shape :\", ax_1.shape, \"\\n\")\n",
        "\n",
        "# Option 2: vstack\n",
        "ax_2 = np.vstack((h_t_prev, x_t))\n",
        "print(\"option 2 : vstack\\n\")\n",
        "print(\"ax_2 :\")\n",
        "print(ax_2)\n",
        "print(\"ax_2 shape :\", ax_2.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Data --\n",
            "\n",
            "h_t_prev :\n",
            "[[1]\n",
            " [1]]\n",
            "h_t_prev shape : (2, 1) \n",
            "\n",
            "x_t :\n",
            "[[9]\n",
            " [9]\n",
            " [9]]\n",
            "x_t shape : (3, 1) \n",
            "\n",
            "-- Joining --\n",
            "\n",
            "option 1 : concatenate\n",
            "\n",
            "ax_1 :\n",
            "[[1]\n",
            " [1]\n",
            " [9]\n",
            " [9]\n",
            " [9]]\n",
            "ax_1 shape : (5, 1) \n",
            "\n",
            "option 2 : vstack\n",
            "\n",
            "ax_2 :\n",
            "[[1]\n",
            " [1]\n",
            " [9]\n",
            " [9]\n",
            " [9]]\n",
            "ax_2 shape : (5, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBIjlkGC1AKm"
      },
      "source": [
        "## Verify Formulas\n",
        "Now you know how to do the concatenations, horizontal and vertical, lets verify if the two formulas produce the same result.\n",
        "\n",
        "__Formula 1:__ $h^{<t>}=g(W_{h}[h^{<t-1>},x^{<t>}] + b_h)$ \n",
        "\n",
        "__Formula 2:__ $h^{<t>}=g(W_{hh}h^{<t-1>} \\oplus W_{hx}x^{<t>} + b_h)$\n",
        "\n",
        "\n",
        "To prove:- __Formula 1__ $\\Leftrightarrow$ __Formula 2__\n",
        "\n",
        "We will ignore the bias term $b_h$ and the activation function $g(\\ )$ because the transformation will be identical for each formula. So what we really want to compare is the result of the following parameters inside each formula:\n",
        "\n",
        "$W_{h}[h^{<t-1>},x^{<t>}] \\quad \\Leftrightarrow \\quad W_{hh}h^{<t-1>} \\oplus W_{hx}x^{<t>} $\n",
        "\n",
        "We'll see how to do this using matrix multiplication combined with the data and techniques (stacking/concatenating) from above.\n",
        "\n",
        "* Try adding a sigmoid activation function and bias term to the checks for completeness.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtgQ3UKY0uMl",
        "outputId": "a5c13edd-efa1-4427-af8c-1fe3164f158d"
      },
      "source": [
        "# Data\n",
        "\n",
        "w_hh = np.full((3, 2), 1)  # returns an array of size 3x2 filled with all 1s\n",
        "w_hx = np.full((3, 3), 9)  # returns an array of size 3x3 filled with all 9s\n",
        "h_t_prev = np.full((2, 1), 1)  # returns an array of size 2x1 filled with all 1s\n",
        "x_t = np.full((3, 1), 9)       # returns an array of size 3x1 filled with all 9s\n",
        "\n",
        "\n",
        "# If you want to randomize the values, uncomment the next 4 lines\n",
        "\n",
        "# w_hh = np.random.standard_normal((3,2))\n",
        "# w_hx = np.random.standard_normal((3,3))\n",
        "# h_t_prev = np.random.standard_normal((2,1))\n",
        "# x_t = np.random.standard_normal((3,1))\n",
        "\n",
        "# Results\n",
        "print(\"-- Results --\")\n",
        "# Formula 1\n",
        "stack_1 = np.hstack((w_hh, w_hx))\n",
        "stack_2 = np.vstack((h_t_prev, x_t))\n",
        "\n",
        "print(\"\\nFormula 1\")\n",
        "print(\"Term1:\\n\",stack_1)\n",
        "print(\"Term2:\\n\",stack_2)\n",
        "formula_1 = np.matmul(np.hstack((w_hh, w_hx)), np.vstack((h_t_prev, x_t)))\n",
        "print(\"Output:\")\n",
        "print(formula_1)\n",
        "\n",
        "# Formula 2\n",
        "mul_1 = np.matmul(w_hh, h_t_prev)\n",
        "mul_2 = np.matmul(w_hx, x_t)\n",
        "print(\"\\nFormula 2\")\n",
        "print(\"Term1:\\n\",mul_1)\n",
        "print(\"Term2:\\n\",mul_2)\n",
        "\n",
        "formula_2 = np.matmul(w_hh, h_t_prev) + np.matmul(w_hx, x_t)\n",
        "print(\"\\nOutput:\")\n",
        "print(formula_2, \"\\n\")\n",
        "\n",
        "# Verification \n",
        "# np.allclose - to check if two arrays are elementwise equal upto certain tolerance, here  \n",
        "# https://numpy.org/doc/stable/reference/generated/numpy.allclose.html\n",
        "\n",
        "print(\"-- Verify --\")\n",
        "print(\"Results are the same :\", np.allclose(formula_1, formula_2))\n",
        "\n",
        "### START CODE HERE ###\n",
        "# # Try adding a sigmoid activation function and bias term as a final check\n",
        "# # Activation\n",
        "# def sigmoid(x):\n",
        "#     return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# # Bias and check\n",
        "# b = np.random.standard_normal((formula_1.shape[0],1))\n",
        "# print(\"Formula 1 Output:\\n\",sigmoid(formula_1+b))\n",
        "# print(\"Formula 2 Output:\\n\",sigmoid(formula_2+b))\n",
        "\n",
        "# all_close = np.allclose(sigmoid(formula_1+b), sigmoid(formula_2+b))\n",
        "# print(\"Results after activation are the same :\",all_close)\n",
        "### END CODE HERE ###"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Results --\n",
            "\n",
            "Formula 1\n",
            "Term1:\n",
            " [[1 1 9 9 9]\n",
            " [1 1 9 9 9]\n",
            " [1 1 9 9 9]]\n",
            "Term2:\n",
            " [[1]\n",
            " [1]\n",
            " [9]\n",
            " [9]\n",
            " [9]]\n",
            "Output:\n",
            "[[245]\n",
            " [245]\n",
            " [245]]\n",
            "\n",
            "Formula 2\n",
            "Term1:\n",
            " [[2]\n",
            " [2]\n",
            " [2]]\n",
            "Term2:\n",
            " [[243]\n",
            " [243]\n",
            " [243]]\n",
            "\n",
            "Output:\n",
            "[[245]\n",
            " [245]\n",
            " [245]] \n",
            "\n",
            "-- Verify --\n",
            "Results are the same : True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlRLJQKI7WU2"
      },
      "source": [
        "# Working with JAX numpy and calculating perplexity: Ungraded Lecture Notebook\n",
        "\n",
        "Normally you would import `numpy` and rename it as `np`. \n",
        "\n",
        "However in this week's assignment you will notice that this convention has been changed. \n",
        "\n",
        "Now standard `numpy` is not renamed and `trax.fastmath.numpy` is renamed as `np`. \n",
        "\n",
        "The rationale behind this change is that you will be using Trax's numpy (which is compatible with JAX) far more often. Trax's numpy supports most of the same functions as the regular numpy so the change won't be noticeable in most cases.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZxnTDZx7VsZ",
        "outputId": "bb477a62-dc38-49c1-f2c4-adb7794c23d3"
      },
      "source": [
        "!pip install -q -U trax\n",
        "import numpy\n",
        "import trax\n",
        "import trax.fastmath.numpy as np\n",
        "\n",
        "# Setting random seeds\n",
        "#trax.supervised.trainer_lib.init_random_number_generators(32)\n",
        "numpy.random.seed(32)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 634kB 34.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3MB 15.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 153kB 60.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 256kB 58.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.5MB 33.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 8.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.9MB 37.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 33.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 368kB 61.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 36.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 901kB 41.5MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9EcKUUw8tPL"
      },
      "source": [
        "One important change to take into consideration is that the types of the resulting objects will be different depending on the version of numpy. With regular numpy you get `numpy.ndarray` but with Trax's numpy you will get `jax.interpreters.xla.DeviceArray`. These two types map to each other. So if you find some error logs mentioning DeviceArray type, don't worry about it, treat it like you would treat an ndarray and march ahead.\n",
        "\n",
        "You can get a randomized numpy array by using the `numpy.random.random()` function.\n",
        "\n",
        "This is one of the functionalities that Trax's numpy does not currently support in the same way as the regular numpy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWNv0A4e1Y0I",
        "outputId": "73da4939-f345-4120-cd51-291b79f096d7"
      },
      "source": [
        "numpy_array = numpy.random.random((5,10))\n",
        "print(f\"The regular numpy array looks like this:\\n\\n {numpy_array}\\n\")\n",
        "print(f\"It is of type: {type(numpy_array)}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The regular numpy array looks like this:\n",
            "\n",
            " [[0.85888927 0.37271115 0.55512878 0.95565655 0.7366696  0.81620514\n",
            "  0.10108656 0.92848807 0.60910917 0.59655344]\n",
            " [0.09178413 0.34518624 0.66275252 0.44171349 0.55148779 0.70371249\n",
            "  0.58940123 0.04993276 0.56179184 0.76635847]\n",
            " [0.91090833 0.09290995 0.90252139 0.46096041 0.45201847 0.99942549\n",
            "  0.16242374 0.70937058 0.16062408 0.81077677]\n",
            " [0.03514717 0.53488673 0.16650012 0.30841038 0.04506241 0.23857613\n",
            "  0.67483453 0.78238275 0.69520163 0.32895445]\n",
            " [0.49403187 0.52412136 0.29854125 0.46310814 0.98478429 0.50113492\n",
            "  0.39807245 0.72790532 0.86333097 0.02616954]]\n",
            "\n",
            "It is of type: <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqPCTd3E9lQz"
      },
      "source": [
        "You can easily cast regular numpy arrays or lists into trax numpy arrays using the `trax.fastmath.numpy.array()` function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AP4mKbAv9gln",
        "outputId": "ec7c048f-bff4-4597-a8de-fdc640ee9b11"
      },
      "source": [
        "trax_numpy_array = np.array(numpy_array)\n",
        "print(f\"The trax numpy array looks like this:\\n\\n {trax_numpy_array}\\n\")\n",
        "print(f\"It is of type: {type(trax_numpy_array)}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The trax numpy array looks like this:\n",
            "\n",
            " [[0.8588893  0.37271115 0.55512875 0.9556565  0.7366696  0.81620514\n",
            "  0.10108656 0.9284881  0.60910916 0.59655344]\n",
            " [0.09178413 0.34518623 0.6627525  0.44171348 0.5514878  0.70371246\n",
            "  0.58940125 0.04993276 0.56179184 0.7663585 ]\n",
            " [0.91090834 0.09290995 0.9025214  0.46096042 0.45201847 0.9994255\n",
            "  0.16242374 0.7093706  0.16062407 0.81077677]\n",
            " [0.03514718 0.5348867  0.16650012 0.30841038 0.04506241 0.23857613\n",
            "  0.67483455 0.7823827  0.69520164 0.32895446]\n",
            " [0.49403188 0.52412134 0.29854125 0.46310815 0.9847843  0.50113493\n",
            "  0.39807245 0.72790533 0.86333096 0.02616954]]\n",
            "\n",
            "It is of type: <class 'jaxlib.xla_extension.DeviceArray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfl_PxZc9vhW"
      },
      "source": [
        "Hope you now understand the differences (and similarities) between these two versions and numpy. **Great!**\n",
        "\n",
        "The previous section was a quick look at Trax's numpy. However this notebook also aims to teach you how you can calculate the perplexity of a trained model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb0k3VV19y7D"
      },
      "source": [
        "## Calculating Perplexity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ET-ppx1s9zG0"
      },
      "source": [
        "The perplexity is a metric that measures how well a probability model predicts a sample and it is commonly used to evaluate language models. It is defined as: \n",
        "\n",
        "$$P(W) = \\sqrt[N]{\\prod_{i=1}^{N} \\frac{1}{P(w_i| w_1,...,w_{n-1})}}$$\n",
        "\n",
        "As an implementation hack, you would usually take the log of that formula (to enable us to use the log probabilities we get as output of our `RNN`, convert exponents to products, and products into sums which makes computations less complicated and computationally more efficient). You should also take care of the padding, since you do not want to include the padding when calculating the perplexity (because we do not want to have a perplexity measure artificially good). The algebra behind this process is explained next:\n",
        "\n",
        "\n",
        "$$log P(W) = {log\\big(\\sqrt[N]{\\prod_{i=1}^{N} \\frac{1}{P(w_i| w_1,...,w_{n-1})}}\\big)}$$\n",
        "\n",
        "$$ = {log\\big({\\prod_{i=1}^{N} \\frac{1}{P(w_i| w_1,...,w_{n-1})}}\\big)^{\\frac{1}{N}}}$$ \n",
        "\n",
        "$$ = {log\\big({\\prod_{i=1}^{N}{P(w_i| w_1,...,w_{n-1})}}\\big)^{-\\frac{1}{N}}} $$\n",
        "$$ = -\\frac{1}{N}{log\\big({\\prod_{i=1}^{N}{P(w_i| w_1,...,w_{n-1})}}\\big)} $$\n",
        "$$ = -\\frac{1}{N}{\\big({\\sum_{i=1}^{N}{logP(w_i| w_1,...,w_{n-1})}}\\big)} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBOj1OiGAGnD"
      },
      "source": [
        "You will be working with a real example from this week's assignment. The example is made up of:\n",
        "   - `predictions` : batch of tensors corresponding to lines of text predicted by the model.\n",
        "   - `targets` : batch of actual tensors corresponding to lines of text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j17dN4IM9rPu",
        "outputId": "3f0d44d9-fb50-4e97-da90-fc88f3fe725b"
      },
      "source": [
        "!git clone https://github.com/amanjeetsahu/Natural-Language-Processing-Specialization.git"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Natural-Language-Processing-Specialization'...\n",
            "remote: Enumerating objects: 586, done.\u001b[K\n",
            "remote: Total 586 (delta 0), reused 0 (delta 0), pack-reused 586\u001b[K\n",
            "Receiving objects: 100% (586/586), 292.43 MiB | 36.11 MiB/s, done.\n",
            "Resolving deltas: 100% (75/75), done.\n",
            "Checking out files: 100% (496/496), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuEGvmYoEFR_",
        "outputId": "61ced2cf-1fe1-49fc-d2f3-96c3942d4d6d"
      },
      "source": [
        "from trax import layers as tl\n",
        "\n",
        "# Load from .npy files\n",
        "predictions = numpy.load('/content/Natural-Language-Processing-Specialization/Natural Language Processing with Sequence Models/Week 2/predictions.npy')\n",
        "targets = numpy.load('/content/Natural-Language-Processing-Specialization/Natural Language Processing with Sequence Models/Week 2/targets.npy')\n",
        "# Cast to jax.interpreters.xla.DeviceArray\n",
        "predictions = np.array(predictions)\n",
        "targets = np.array(targets)\n",
        "\n",
        "# Print shapes\n",
        "print(f'predictions has shape: {predictions.shape}')\n",
        "print(f'targets has shape: {targets.shape}')\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predictions has shape: (32, 64, 256)\n",
            "targets has shape: (32, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRFtDjViGGGN"
      },
      "source": [
        "Notice that the predictions have an extra dimension with the same length as the size of the vocabulary used.\n",
        "\n",
        "Because of this you will need a way of reshaping `targets` to match this shape. For this you can use `trax.layers.one_hot()`.\n",
        "\n",
        "Notice that `predictions.shape[-1]` will return the size of the last dimension of `predictions`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYzsJEbTEW6L",
        "outputId": "89eb054e-f6e9-49a1-ac57-cc48dadf9827"
      },
      "source": [
        "reshaped_targets = tl.one_hot(targets, predictions.shape[-1]) #trax's one_hot function takes the input as one_hot(x, n_categories, dtype=optional)\n",
        "print(f'reshaped_targets has shape: {reshaped_targets.shape}')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reshaped_targets has shape: (32, 64, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYptmKvwGlGW"
      },
      "source": [
        "By calculating the product of the predictions and the reshaped targets and summing across the last dimension, the total log perplexity can be computed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ_AurlMGPGa"
      },
      "source": [
        "total_log_ppx = np.sum(predictions * reshaped_targets, axis= -1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRMTsp6Y-m5W",
        "outputId": "02b7b278-527e-44b3-95e5-d4e5ee0383d4"
      },
      "source": [
        "total_log_ppx.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QCksQbW-x09"
      },
      "source": [
        "Now you will need to account for the padding so this metric is not artificially deflated (since a lower perplexity means a better model). For identifying which elements are padding and which are not, you can use `np.equal()` and get a tensor with `1s` in the positions of actual values and `0s` where there are paddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOxY767n-osM",
        "outputId": "7929fc59-591f-4261-c63f-7e6065400354"
      },
      "source": [
        "#test\n",
        "np.equal(np.array([0, 1, 3]), 1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([False,  True, False], dtype=bool)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsTFKI6W-_gl",
        "outputId": "c3f60c4f-a7f0-4fe2-8e5b-230b643be50f"
      },
      "source": [
        "targets"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[105, 110,  32, ...,   0,   0,   0],\n",
              "             [ 97, 110, 110, ...,   0,   0,   0],\n",
              "             [111, 102,  32, ...,   0,   0,   0],\n",
              "             ...,\n",
              "             [105,  32,  97, ...,   0,   0,   0],\n",
              "             [101, 100, 103, ...,   0,   0,   0],\n",
              "             [121, 111, 117, ...,   0,   0,   0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ie1DrQa_Qku",
        "outputId": "8c05c195-0fde-433b-96b0-fe80d411e943"
      },
      "source": [
        "non_pad = 1.0 - np.equal(targets, 0)\n",
        "print(f'non_pad has shape: {non_pad.shape}\\n')\n",
        "print(f'non_pad looks like this: \\n\\n {non_pad}')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "non_pad has shape: (32, 64)\n",
            "\n",
            "non_pad looks like this: \n",
            "\n",
            " [[1. 1. 1. ... 0. 0. 0.]\n",
            " [1. 1. 1. ... 0. 0. 0.]\n",
            " [1. 1. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 1. 1. ... 0. 0. 0.]\n",
            " [1. 1. 1. ... 0. 0. 0.]\n",
            " [1. 1. 1. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrAIamsr_ajn"
      },
      "source": [
        "By computing the product of the total log perplexity and the non_pad tensor we remove the effect of padding on the metric:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTymbbSr_V8v",
        "outputId": "5f852644-0250-4cad-9e1f-461bc07d986e"
      },
      "source": [
        "real_log_ppx = total_log_ppx * non_pad\n",
        "print(f'real perplexity still has shape: {real_log_ppx.shape}')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "real perplexity still has shape: (32, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3abU3Yrz_hFy"
      },
      "source": [
        "You can check the effect of filtering out the padding by looking at the two log perplexity tensors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C9W-AAB_Y10",
        "outputId": "be4db348-ac06-4ce7-fe64-f5ea8004d0b5"
      },
      "source": [
        "print(f'log perplexity tensor before filtering padding: \\n\\n {total_log_ppx}\\n')\n",
        "print(f'log perplexity tensor after filtering padding: \\n\\n {real_log_ppx}')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "log perplexity tensor before filtering padding: \n",
            "\n",
            " [[ -5.396545    -1.0311184   -0.66916656 ... -22.37673    -23.18771\n",
            "  -21.843483  ]\n",
            " [ -4.5857706   -1.1341286   -8.538033   ... -20.15686    -26.837097\n",
            "  -23.57502   ]\n",
            " [ -5.2223887   -1.2824144   -0.17312431 ... -21.328228   -19.854412\n",
            "  -33.88444   ]\n",
            " ...\n",
            " [ -5.396545   -17.291681    -4.360766   ... -20.825802   -21.065838\n",
            "  -22.443115  ]\n",
            " [ -5.9313164  -14.247417    -0.2637329  ... -26.743248   -18.38433\n",
            "  -22.355278  ]\n",
            " [ -5.670536    -0.10595131   0.         ... -23.332523   -28.087376\n",
            "  -23.878807  ]]\n",
            "\n",
            "log perplexity tensor after filtering padding: \n",
            "\n",
            " [[ -5.396545    -1.0311184   -0.66916656 ...  -0.          -0.\n",
            "   -0.        ]\n",
            " [ -4.5857706   -1.1341286   -8.538033   ...  -0.          -0.\n",
            "   -0.        ]\n",
            " [ -5.2223887   -1.2824144   -0.17312431 ...  -0.          -0.\n",
            "   -0.        ]\n",
            " ...\n",
            " [ -5.396545   -17.291681    -4.360766   ...  -0.          -0.\n",
            "   -0.        ]\n",
            " [ -5.9313164  -14.247417    -0.2637329  ...  -0.          -0.\n",
            "   -0.        ]\n",
            " [ -5.670536    -0.10595131   0.         ...  -0.          -0.\n",
            "   -0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf33Y_lv_v_p"
      },
      "source": [
        "To get a single average log perplexity across all the elements in the batch you can sum across both dimensions and divide by the number of elements. Notice that the result will be the negative of the real log perplexity of the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvGvZLVY_oGB",
        "outputId": "a6353d97-9015-4e9f-b6b2-608f50b6b056"
      },
      "source": [
        "log_ppx = np.sum(real_log_ppx) / np.sum(non_pad)\n",
        "log_ppx = -log_ppx\n",
        "print(f'The log perplexity and perplexity of the model are respectively: {log_ppx} and {np.exp(log_ppx)}')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The log perplexity and perplexity of the model are respectively: 2.3281209468841553 and 10.258646965026855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhyO8CR9_7K1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}