{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week3_Assignment NER Tagging Using LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPVBGhpNyV4hbaDMcOOCb5c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagar9926/NLP_Specialisation/blob/main/SequenceModelling/Week3_Assignment_NER_Tagging_Using_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4MqlfbdRcKI"
      },
      "source": [
        "# Assignment 3 - Named Entity Recognition (NER)\n",
        "\n",
        "Welcome to the third programming assignment of Course 3. In this assignment, you will learn to build more complicated models with Trax. By completing this assignment, you will be able to: \n",
        "\n",
        "- Design the architecture of a neural network, train it, and test it. \n",
        "- Process features and represents them\n",
        "- Understand word padding\n",
        "- Implement LSTMs\n",
        "- Test with your own sentence\n",
        "\n",
        "## Outline\n",
        "- [Introduction](#0)\n",
        "- [Part 1:  Exploring the data](#1)\n",
        "    - [1.1  Importing the Data](#1.1)\n",
        "    - [1.2  Data generator](#1.2)\n",
        "\t\t- [Exercise 01](#ex01)\n",
        "- [Part 2:  Building the model](#2)\n",
        "\t- [Exercise 02](#ex02)\n",
        "- [Part 3:  Train the Model ](#3)\n",
        "\t- [Exercise 03](#ex03)\n",
        "- [Part 4:  Compute Accuracy](#4)\n",
        "\t- [Exercise 04](#ex04)\n",
        "- [Part 5:  Testing with your own sentence](#5)\n",
        "\n",
        "\n",
        "<a name=\"0\"></a>\n",
        "# Introduction\n",
        "\n",
        "We first start by defining named entity recognition (NER). NER is a subtask of information extraction that locates and classifies named entities in a text. The named entities could be organizations, persons, locations, times, etc. \n",
        "\n",
        "For example:\n",
        "\n",
        "<img src = 'https://github.com/amanjeetsahu/Natural-Language-Processing-Specialization/raw/d562105e68a0b85012ad3ebbb29b2af6344ad4e5/Natural%20Language%20Processing%20with%20Sequence%20Models/Week%203/ner.png' width=\"width\" height=\"height\" style=\"width:600px;height:150px;\"/>\n",
        "\n",
        "Is labeled as follows: \n",
        "\n",
        "- French: geopolitical entity\n",
        "- Morocco: geographic entity \n",
        "- Christmas: time indicator\n",
        "\n",
        "Everything else that is labeled with an `O` is not considered to be a named entity. In this assignment, you will train a named entity recognition system that could be trained in a few seconds (on a GPU) and will get around 75% accuracy. Then, you will load in the exact version of your model, which was trained for a longer period of time. You could then evaluate the trained version of your model to get 96% accuracy! Finally, you will be able to test your named entity recognition system with your own sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9qvqs9vQyw2",
        "outputId": "62586746-85b6-4554-c725-7b12923b84a6"
      },
      "source": [
        "!pip install -q -U trax\n",
        "\n",
        "import trax \n",
        "from trax import layers as tl\n",
        "import os \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import random as rnd\n",
        "!git clone https://github.com/amanjeetsahu/Natural-Language-Processing-Specialization.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 634kB 12.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3MB 29.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 153kB 36.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 256kB 39.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 368kB 35.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.9MB 37.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 33.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 6.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.5MB 29.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 901kB 28.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 28.5MB/s \n",
            "\u001b[?25hCloning into 'Natural-Language-Processing-Specialization'...\n",
            "remote: Enumerating objects: 586, done.\u001b[K\n",
            "remote: Total 586 (delta 0), reused 0 (delta 0), pack-reused 586\u001b[K\n",
            "Receiving objects: 100% (586/586), 292.43 MiB | 28.03 MiB/s, done.\n",
            "Resolving deltas: 100% (75/75), done.\n",
            "Checking out files: 100% (496/496), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sG5zRatESH35"
      },
      "source": [
        "<a name=\"1\"></a>\n",
        "# Part 1:  Exploring the data\n",
        "\n",
        "We will be using a dataset from Kaggle, which we will preprocess for you. The original data consists of four columns, the sentence number, the word, the part of speech of the word, and the tags.  A few tags you might expect to see are: \n",
        "\n",
        "* geo: geographical entity\n",
        "* org: organization\n",
        "* per: person \n",
        "* gpe: geopolitical entity\n",
        "* tim: time indicator\n",
        "* art: artifact\n",
        "* eve: event\n",
        "* nat: natural phenomenon\n",
        "* O: filler word\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-gkd7rTSwbE"
      },
      "source": [
        "# helper functions\n",
        "\n",
        "def get_vocab(vocab_path, tags_path):\n",
        "    vocab = {}\n",
        "    with open(vocab_path) as f:\n",
        "        for i, l in enumerate(f.read().splitlines()):\n",
        "            vocab[l] = i  # to avoid the 0\n",
        "        # loading tags (we require this to map tags to their indices)\n",
        "    vocab['<PAD>'] = len(vocab) # 35180\n",
        "    tag_map = {}\n",
        "    with open(tags_path) as f:\n",
        "        for i, t in enumerate(f.read().splitlines()):\n",
        "            tag_map[t] = i \n",
        "    \n",
        "    return vocab, tag_map\n",
        "\n",
        "def get_params(vocab, tag_map, sentences_file, labels_file):\n",
        "    sentences = []\n",
        "    labels = []\n",
        "\n",
        "    with open(sentences_file) as f:\n",
        "        for sentence in f.read().splitlines():\n",
        "            # replace each token by its index if it is in vocab\n",
        "            # else use index of UNK_WORD\n",
        "            s = [vocab[token] if token in vocab \n",
        "                 else vocab['UNK']\n",
        "                 for token in sentence.split(' ')]\n",
        "            sentences.append(s)\n",
        "\n",
        "    with open(labels_file) as f:\n",
        "        for sentence in f.read().splitlines():\n",
        "            # replace each label by its index\n",
        "            l = [tag_map[label] for label in sentence.split(' ')] # I added plus 1 here\n",
        "            labels.append(l) \n",
        "    return sentences, labels, len(sentences)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Xl7DoM4TQOc"
      },
      "source": [
        "<a name=\"1.1\"></a>\n",
        "## 1.1  Importing the Data\n",
        "\n",
        "In this part, we will import the preprocessed data and explore it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xozdPJPJSFyu",
        "outputId": "d6abb045-aa75-4f0a-e19f-9bfee31efbcb"
      },
      "source": [
        "cd /content/Natural-Language-Processing-Specialization/Natural Language Processing with Sequence Models/Week 3"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Natural-Language-Processing-Specialization/Natural Language Processing with Sequence Models/Week 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oh6fPnvITb8o",
        "outputId": "996c81a9-7b36-46cd-a1e9-3eaf064dc32a"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C3_W3_Assignment.ipynb\t\t\t\t  model     sigmoid_tangent.png\n",
            "C3_W3_Assignment_Solution.ipynb\t\t\t  ner1.png  utils.py\n",
            "C3_W3_Lecture_Notebook_Vanishing_Gradients.ipynb  ner2.png\n",
            "data\t\t\t\t\t\t  ner.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrOoqpgaTVFp"
      },
      "source": [
        "vocab, tag_map = get_vocab('data/large/words.txt', 'data/large/tags.txt')\n",
        "t_sentences, t_labels, t_size = get_params(vocab, tag_map, 'data/large/train/sentences.txt', 'data/large/train/labels.txt')\n",
        "v_sentences, v_labels, v_size = get_params(vocab, tag_map, 'data/large/val/sentences.txt', 'data/large/val/labels.txt')\n",
        "test_sentences, test_labels, test_size = get_params(vocab, tag_map, 'data/large/test/sentences.txt', 'data/large/test/labels.txt')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxlteAZxt39L"
      },
      "source": [
        "`vocab` is a dictionary that translates a word string to a unique number. Given a sentence, you can represent it as an array of numbers translating with this dictionary. The dictionary contains a `<PAD>` token. \n",
        "\n",
        "When training an LSTM using batches, all your input sentences must be the same size. To accomplish this, you set the length of your sentences to a certain number and add the generic `<PAD>` token to fill all the empty spaces. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SZbCmlatvC_",
        "outputId": "97ca9bda-06c2-42a3-97e6-ccd318f454ad"
      },
      "source": [
        "# vocab translates from a word to a unique number\n",
        "print('vocab[\"the\"]:', vocab[\"the\"])\n",
        "# Pad token\n",
        "print('padded token:', vocab['<PAD>'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab[\"the\"]: 9\n",
            "padded token: 35180\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jwobvmkuBqa"
      },
      "source": [
        "The tag_map corresponds to one of the possible tags a word can have. Run the cell below to see the possible classes you will be predicting. The prepositions in the tags mean:\n",
        "* I: Token is inside an entity.\n",
        "* B: Token begins an entity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEYC1FHSuUj-"
      },
      "source": [
        "So the coding scheme that tags the entities is a minimal one where B- indicates the first token in a multi-token entity, and I- indicates one in the middle of a multi-token entity. If you had the sentence \n",
        "\n",
        "**\"Sharon flew to Miami on Friday\"**\n",
        "\n",
        "the outputs would look like:\n",
        "\n",
        "```\n",
        "Sharon B-per\n",
        "flew   O\n",
        "to     O\n",
        "Miami  B-geo\n",
        "on     O\n",
        "Friday B-tim\n",
        "```\n",
        "\n",
        "your tags would reflect three tokens beginning with B-, since there are no multi-token entities in the sequence. But if you added Sharon's last name to the sentence: \n",
        "\n",
        "**\"Sharon Floyd flew to Miami on Friday\"**\n",
        "\n",
        "```\n",
        "Sharon B-per\n",
        "Floyd  I-per\n",
        "flew   O\n",
        "to     O\n",
        "Miami  B-geo\n",
        "on     O\n",
        "Friday B-tim\n",
        "```\n",
        "\n",
        "then your tags would change to show first \"Sharon\" as B-per, and \"Floyd\" as I-per, where I- indicates an inner token in a multi-token sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aXc-jC2twZU",
        "outputId": "74e11333-1272-4344-9136-21e5d538671e"
      },
      "source": [
        "# Exploring information about the data\n",
        "print('The number of outputs is tag_map', len(tag_map))\n",
        "# The number of vocabulary tokens (including <PAD>)\n",
        "g_vocab_size = len(vocab)\n",
        "print(f\"Num of vocabulary words: {g_vocab_size}\")\n",
        "print('The vocab size is', len(vocab))\n",
        "print('The training size is', t_size)\n",
        "print('The validation size is', v_size)\n",
        "print('An example of the first sentence is', t_sentences[0])\n",
        "print('An example of its corresponding label is', t_labels[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of outputs is tag_map 17\n",
            "Num of vocabulary words: 35181\n",
            "The vocab size is 35181\n",
            "The training size is 33570\n",
            "The validation size is 7194\n",
            "An example of the first sentence is [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 9, 15, 1, 16, 17, 18, 19, 20, 21]\n",
            "An example of its corresponding label is [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLFkkqjAugeA"
      },
      "source": [
        "So you can see that we have already encoded each sentence into a tensor by converting it into a number. We also have 16 possible classes, as shown in the tag map.\n",
        "\n",
        "\n",
        "<a name=\"1.2\"></a>\n",
        "## 1.2  Data generator\n",
        "\n",
        "In python, a generator is a function that behaves like an iterator. It will return the next item. Here is a [link](https://wiki.python.org/moin/Generators) to review python generators. \n",
        "\n",
        "In many AI applications it is very useful to have a data generator. You will now implement a data generator for our NER application.\n",
        "\n",
        "<a name=\"ex01\"></a>\n",
        "### Exercise 01\n",
        "\n",
        "**Instructions:** Implement a data generator function that takes in `batch_size, x, y, pad, shuffle` where x is a large list of sentences, and y is a list of the tags associated with those sentences and pad is a pad value. Return a subset of those inputs in a tuple of two arrays `(X,Y)`. Each is an array of dimension (`batch_size, max_len`), where `max_len` is the length of the longest sentence *in that batch*. You will pad the X and Y examples with the pad argument. If `shuffle=True`, the data will be traversed in a random form.\n",
        "\n",
        "**Details:**\n",
        "\n",
        "This code as an outer loop  \n",
        "```\n",
        "while True:  \n",
        "...  \n",
        "yield((X,Y))  \n",
        "```\n",
        "\n",
        "Which runs continuously in the fashion of generators, pausing when yielding the next values. We will generate a batch_size output on each pass of this loop.    \n",
        "\n",
        "It has two inner loops. \n",
        "1. The first stores in temporal lists the data samples to be included in the next batch, and finds the maximum length of the sentences contained in it. By adjusting the length to include only the size of the longest sentence in each batch, overall computation is reduced. \n",
        "\n",
        "2. The second loop moves those inputs from the temporal list into NumPy arrays pre-filled with pad values.\n",
        "\n",
        "There are three slightly out of the ordinary features. \n",
        "1. The first is the use of the NumPy `full` function to fill the NumPy arrays with a pad value. See [full function documentation](https://numpy.org/doc/1.18/reference/generated/numpy.full.html).\n",
        "\n",
        "2. The second is tracking the current location in the incoming lists of sentences. Generators variables hold their values between invocations, so we create an `index` variable, initialize to zero, and increment by one for each sample included in a batch. However, we do not use the `index` to access the positions of the list of sentences directly. Instead, we use it to select one index from a list of indexes. In this way, we can change the order in which we traverse our original list, keeping untouched our original list.  \n",
        "\n",
        "3. The third also relates to wrapping. Because `batch_size` and the length of the input lists are not aligned, gathering a batch_size group of inputs may involve wrapping back to the beginning of the input loop. In our approach, it is just enough to reset the `index` to 0. We can re-shuffle the list of indexes to produce different batches each time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvP4m08SuYIu"
      },
      "source": [
        "# UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "# GRADED FUNCTION: data_generator\n",
        "def data_generator(batch_size, x, y, pad, shuffle=False, verbose=False):\n",
        "    '''\n",
        "      Input: \n",
        "        batch_size - integer describing the batch size\n",
        "        x - list containing sentences where words are represented as integers\n",
        "        y - list containing tags associated with the sentences\n",
        "        shuffle - Shuffle the data order\n",
        "        pad - an integer representing a pad character\n",
        "        verbose - Print information during runtime\n",
        "      Output:\n",
        "        a tuple containing 2 elements:\n",
        "        X - np.ndarray of dim (batch_size, max_len) of padded sentences\n",
        "        Y - np.ndarray of dim (batch_size, max_len) of tags associated with the sentences in X\n",
        "    '''\n",
        "    \n",
        "    # count the number of lines in data_lines\n",
        "    num_lines = len(x)\n",
        "    \n",
        "    # create an array with the indexes of data_lines that can be shuffled\n",
        "    lines_index = [*range(num_lines)]\n",
        "    \n",
        "    # shuffle the indexes if shuffle is set to True\n",
        "    if shuffle:\n",
        "        rnd.shuffle(lines_index)\n",
        "    \n",
        "    index = 0 # tracks current location in x, y\n",
        "    while True:\n",
        "        buffer_x = [0] * batch_size # Temporal array to store the raw x data for this batch\n",
        "        buffer_y = [0] * batch_size # Temporal array to store the raw y data for this batch\n",
        "                \n",
        "  ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
        "        \n",
        "        # Copy into the temporal buffers the sentences in x[index : index + batch_size] \n",
        "        # along with their corresponding labels y[index : index + batch_size]\n",
        "        # Find maximum length of sentences in x[index : index + batch_size] for this batch. \n",
        "        # Reset the index if we reach the end of the data set, and shuffle the indexes if needed.\n",
        "        max_len = 0\n",
        "        for i in range(batch_size):\n",
        "             # if the index is greater than or equal to the number of lines in x\n",
        "            if index >= num_lines:\n",
        "                # then reset the index to 0\n",
        "                index = 0\n",
        "                # re-shuffle the indexes if shuffle is set to True\n",
        "                if shuffle:\n",
        "                    rnd.shuffle(lines_index)\n",
        "            \n",
        "            # The current position is obtained using `lines_index[index]`\n",
        "            # Store the x value at the current position into the buffer_x\n",
        "            buffer_x[i] = x[lines_index[index]]\n",
        "            \n",
        "            # Store the y value at the current position into the buffer_y\n",
        "            buffer_y[i] = y[lines_index[index]]\n",
        "            \n",
        "            lenx = len(buffer_x[i])    #length of current x[]\n",
        "            if lenx > max_len:\n",
        "                max_len = lenx                   #max_len tracks longest x[]\n",
        "            \n",
        "            # increment index by one\n",
        "            index += 1\n",
        "\n",
        "\n",
        "        # create X,Y, NumPy arrays of size (batch_size, max_len) 'full' of pad value\n",
        "        X = np.full((batch_size, max_len),pad)\n",
        "        Y = np.full((batch_size, max_len),pad)\n",
        "\n",
        "        # copy values from lists to NumPy arrays. Use the buffered values\n",
        "        for i in range(batch_size):\n",
        "            # get the example (sentence as a tensor)\n",
        "            # in `buffer_x` at the `i` index\n",
        "            x_i = buffer_x[i]\n",
        "            \n",
        "            # similarly, get the example's labels\n",
        "            # in `buffer_y` at the `i` index\n",
        "            y_i = buffer_y[i]\n",
        "            \n",
        "            # Walk through each word in x_i\n",
        "            for j in range(len(x_i)):\n",
        "                # store the word in x_i at position j into X\n",
        "                X[i, j] = x_i[j]\n",
        "                \n",
        "                # store the label in y_i at position j into Y\n",
        "                Y[i, j] = y_i[j]\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "        if verbose: print(\"index=\", index)\n",
        "        yield((X,Y))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMCh-f_rwsaq",
        "outputId": "91236aab-de3f-41f5-89f5-417f53075415"
      },
      "source": [
        "batch_size = 5\n",
        "mini_sentences = t_sentences[0: 8]\n",
        "mini_labels = t_labels[0: 8]\n",
        "dg = data_generator(batch_size, mini_sentences, mini_labels, vocab[\"<PAD>\"], shuffle=False, verbose=True)\n",
        "X1, Y1 = next(dg)\n",
        "X2, Y2 = next(dg)\n",
        "print(Y1.shape, X1.shape, Y2.shape, X2.shape)\n",
        "print(X1[0][:], \"\\n\", Y1[0][:])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "index= 5\n",
            "index= 2\n",
            "(5, 30) (5, 30) (5, 30) (5, 30)\n",
            "[    0     1     2     3     4     5     6     7     8     9    10    11\n",
            "    12    13    14     9    15     1    16    17    18    19    20    21\n",
            " 35180 35180 35180 35180 35180 35180] \n",
            " [    0     0     0     0     0     0     1     0     0     0     0     0\n",
            "     1     0     0     0     0     0     2     0     0     0     0     0\n",
            " 35180 35180 35180 35180 35180 35180]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEVioHUjw6Ih"
      },
      "source": [
        "<a name=\"2\"></a>\n",
        "# Part 2:  Building the model\n",
        "\n",
        "You will now implement the model. You will be using Google's TensorFlow. Your model will be able to distinguish the following:\n",
        "<table>\n",
        "    <tr>\n",
        "        <td>\n",
        "<img src = 'https://github.com/amanjeetsahu/Natural-Language-Processing-Specialization/raw/d562105e68a0b85012ad3ebbb29b2af6344ad4e5/Natural%20Language%20Processing%20with%20Sequence%20Models/Week%203/ner1.png' width=\"width\" height=\"height\" style=\"width:500px;height:150px;\"/>\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n",
        "The model architecture will be as follows: \n",
        "\n",
        "<img src = 'https://github.com/amanjeetsahu/Natural-Language-Processing-Specialization/raw/d562105e68a0b85012ad3ebbb29b2af6344ad4e5/Natural%20Language%20Processing%20with%20Sequence%20Models/Week%203/ner2.png' width=\"width\" height=\"height\" style=\"width:600px;height:250px;\"/>\n",
        "\n",
        "Concretely: \n",
        "\n",
        "* Use the input tensors you built in your data generator\n",
        "* Feed it into an Embedding layer, to produce more semantic entries\n",
        "* Feed it into an LSTM layer\n",
        "* Run the output through a linear layer\n",
        "* Run the result through a log softmax layer to get the predicted class for each word.\n",
        "\n",
        "Good news! We won't make you implement the LSTM unit drawn above. However, we will ask you to build the model. \n",
        "\n",
        "<a name=\"ex02\"></a>\n",
        "### Exercise 02\n",
        "\n",
        "**Instructions:** Implement the initialization step and the forward function of your Named Entity Recognition system.  \n",
        "Please utilize help function e.g. `help(tl.Dense)` for more information on a layer\n",
        "   \n",
        "- [tl.Serial](https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/combinators.py#L26): Combinator that applies layers serially (by function composition).\n",
        "    - You can pass in the layers as arguments to `Serial`, separated by commas. \n",
        "    - For example: `tl.Serial(tl.Embeddings(...), tl.Mean(...), tl.Dense(...), tl.LogSoftmax(...))` \n",
        "\n",
        "\n",
        "-  [tl.Embedding](https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/core.py#L113): Initializes the embedding. In this case it is the dimension of the model by the size of the vocabulary. \n",
        "    - `tl.Embedding(vocab_size, d_feature)`.\n",
        "    - `vocab_size` is the number of unique words in the given vocabulary.\n",
        "    - `d_feature` is the number of elements in the word embedding (some choices for a word embedding size range from 150 to 300, for example).\n",
        "    \n",
        "\n",
        "-  [tl.LSTM](https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/rnn.py#L87):`Trax` LSTM layer of size d_model. \n",
        "    - `LSTM(n_units)` Builds an LSTM layer of n_cells.\n",
        "\n",
        "\n",
        "\n",
        "-  [tl.Dense](https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/core.py#L28):  A dense layer.\n",
        "    - `tl.Dense(n_units)`: The parameter `n_units` is the number of units chosen for this dense layer.  \n",
        "\n",
        "\n",
        "- [tl.LogSoftmax](https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/core.py#L242): Log of the output probabilities.\n",
        "    - Here, you don't need to set any parameters for `LogSoftMax()`.\n",
        " \n",
        "\n",
        "**Online documentation**\n",
        "\n",
        "- [tl.Serial](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#module-trax.layers.combinators)\n",
        "\n",
        "- [tl.Embedding](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Embedding)\n",
        "\n",
        "-  [tl.LSTM](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.rnn.LSTM)\n",
        "\n",
        "-  [tl.Dense](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense)\n",
        "\n",
        "- [tl.LogSoftmax](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.LogSoftmax)    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ts5ShIglwvpT"
      },
      "source": [
        "# UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "# GRADED FUNCTION: NER\n",
        "def NER(vocab_size=35181, d_model=50, tags=tag_map):\n",
        "    '''\n",
        "      Input: \n",
        "        vocab_size - integer containing the size of the vocabulary\n",
        "        d_model - integer describing the embedding size\n",
        "      Output:\n",
        "        model - a trax serial model\n",
        "    '''\n",
        "    ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
        "    model = tl.Serial(\n",
        "      tl.Embedding(vocab_size,d_model), # Embedding layer\n",
        "      tl.LSTM(d_model), # LSTM layer\n",
        "      tl.Dense(len(tags)), # Dense layer with len(tags) units\n",
        "      tl.LogSoftmax()  # LogSoftmax layer\n",
        "      )\n",
        "      ### END CODE HERE ###\n",
        "    return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY0pxiGqxgI9",
        "outputId": "d2f2c8c2-a98a-400e-d35a-43d94b2347b3"
      },
      "source": [
        "# initializing your model\n",
        "model = NER()\n",
        "# display your model\n",
        "print(model)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Serial[\n",
            "  Embedding_35181_50\n",
            "  LSTM_50\n",
            "  Dense_17\n",
            "  LogSoftmax\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4oqcZbexjj9"
      },
      "source": [
        "<a name=\"3\"></a>\n",
        "# Part 3:  Train the Model \n",
        "\n",
        "This section will train your model.\n",
        "\n",
        "Before you start, you need to create the data generators for training and validation data. It is important that you mask padding in the loss weights of your data, which can be done using the `id_to_mask` argument of `trax.supervised.inputs.add_loss_weights`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx7L4AAcxhof"
      },
      "source": [
        "from trax.supervised import training\n",
        "\n",
        "rnd.seed(33)\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# Create training data, mask pad id=35180 for training.\n",
        "train_generator = trax.data.inputs.add_loss_weights(\n",
        "    data_generator(batch_size, t_sentences, t_labels, vocab['<PAD>'], True),\n",
        "    id_to_mask=vocab['<PAD>'])\n",
        "\n",
        "# Create validation data, mask pad id=35180 for training.\n",
        "eval_generator = trax.data.inputs.add_loss_weights(\n",
        "    data_generator(batch_size, v_sentences, v_labels, vocab['<PAD>'], True),\n",
        "    id_to_mask=vocab['<PAD>'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTdp1W50yfPZ"
      },
      "source": [
        "<a name='3.1'></a>\n",
        "### 3.1 Training the model\n",
        "\n",
        "You will now write a function that takes in your model and trains it.\n",
        "\n",
        "As you've seen in the previous assignments, you will first create the [TrainTask](https://trax-ml.readthedocs.io/en/stable/trax.supervised.html#trax.supervised.training.TrainTask) and [EvalTask](https://trax-ml.readthedocs.io/en/stable/trax.supervised.html#trax.supervised.training.EvalTask) using your data generator. Then you will use the `training.Loop` to train your model.\n",
        "\n",
        "<a name=\"ex03\"></a>\n",
        "### Exercise 03\n",
        "\n",
        "**Instructions:** Implement the `train_model` program below to train the neural network above. Here is a list of things you should do: \n",
        "- Create the trainer object by calling [`trax.supervised.training.Loop`](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.Loop) and pass in the following:\n",
        "\n",
        "    - model = [NER](#ex02)\n",
        "    - [training task](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.TrainTask) that uses the train data generator defined in the cell above\n",
        "        - loss_layer = [tl.CrossEntropyLoss()](https://github.com/google/trax/blob/22765bb18608d376d8cd660f9865760e4ff489cd/trax/layers/metrics.py#L71)\n",
        "        - optimizer = [trax.optimizers.Adam(0.01)](https://github.com/google/trax/blob/03cb32995e83fc1455b0c8d1c81a14e894d0b7e3/trax/optimizers/adam.py#L23)\n",
        "    - [evaluation task](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.EvalTask) that uses the validation data generator defined in the cell above\n",
        "        - metrics for `EvalTask`: `tl.CrossEntropyLoss()` and `tl.Accuracy()`\n",
        "        - in `EvalTask` set `n_eval_batches=10` for better evaluation accuracy\n",
        "    - output_dir = output_dir\n",
        "\n",
        "You'll be using a [cross entropy loss](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.metrics.CrossEntropyLoss), with an [Adam optimizer](https://trax-ml.readthedocs.io/en/latest/trax.optimizers.html#trax.optimizers.adam.Adam). Please read the [trax](https://trax-ml.readthedocs.io/en/latest/trax.html) documentation to get a full understanding. The [trax GitHub](https://github.com/google/trax) also contains some useful information and a link to a colab notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeKKB92pyEdy"
      },
      "source": [
        "# UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "# GRADED FUNCTION: train_model\n",
        "def train_model(NER, train_generator, eval_generator, train_steps=1, output_dir='model'):\n",
        "    '''\n",
        "    Input: \n",
        "        NER - the model you are building\n",
        "        train_generator - The data generator for training examples\n",
        "        eval_generator - The data generator for validation examples,\n",
        "        train_steps - number of training steps\n",
        "        output_dir - folder to save your model\n",
        "    Output:\n",
        "        training_loop - a trax supervised training Loop\n",
        "    '''\n",
        "    ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
        "    train_task = training.TrainTask(\n",
        "      train_generator, # A train data generator\n",
        "      loss_layer = tl.CrossEntropyLoss(), # A cross-entropy loss function\n",
        "      optimizer = trax.optimizers.Adam(0.01),  # The adam optimizer\n",
        "    )\n",
        "\n",
        "    eval_task = training.EvalTask(\n",
        "      labeled_data = eval_generator, # A labeled data generator\n",
        "      metrics = [tl.CrossEntropyLoss(), tl.Accuracy()], # Evaluate with cross-entropy loss and accuracy\n",
        "      n_eval_batches = 10 # Number of batches to use on each evaluation\n",
        "    )\n",
        "\n",
        "    training_loop = training.Loop(\n",
        "        NER, # A model to train\n",
        "        train_task, # A train task\n",
        "        eval_tasks = eval_task, # The evaluation task\n",
        "        output_dir = output_dir) # The output directory\n",
        "\n",
        "    # Train with train_steps\n",
        "    training_loop.run(n_steps = train_steps)\n",
        "    ### END CODE HERE ###\n",
        "    return training_loop"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F7SJ7v-ozWXv",
        "outputId": "5676b84b-5aa6-45ce-ee99-9d5f93e6b7e2"
      },
      "source": [
        "train_steps = 100000          # In coursera we can only train 100 steps\n",
        "!rm -f 'model/model.pkl.gz'  # Remove old model.pkl if it exists\n",
        "\n",
        "# Train the model\n",
        "training_loop = train_model(NER(), train_generator, eval_generator, train_steps)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/jax/lib/xla_bridge.py:304: UserWarning: jax.host_id has been renamed to jax.process_index. This alias will eventually be removed; please update your code.\n",
            "  \"jax.host_id has been renamed to jax.process_index. This alias \"\n",
            "/usr/local/lib/python3.7/dist-packages/jax/lib/xla_bridge.py:317: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n",
            "  \"jax.host_count has been renamed to jax.process_count. This alias \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Step      1: Total number of trainable weights: 1780117\n",
            "Step      1: Ran 1 train steps in 3.77 secs\n",
            "Step      1: train CrossEntropyLoss |  3.30076027\n",
            "Step      1: eval  CrossEntropyLoss |  2.30610003\n",
            "Step      1: eval          Accuracy |  0.01480957\n",
            "\n",
            "Step    100: Ran 99 train steps in 76.08 secs\n",
            "Step    100: train CrossEntropyLoss |  0.54135591\n",
            "Step    100: eval  CrossEntropyLoss |  0.25676669\n",
            "Step    100: eval          Accuracy |  0.93444465\n",
            "\n",
            "Step    200: Ran 100 train steps in 13.57 secs\n",
            "Step    200: train CrossEntropyLoss |  0.20264614\n",
            "Step    200: eval  CrossEntropyLoss |  0.17598961\n",
            "Step    200: eval          Accuracy |  0.94975359\n",
            "\n",
            "Step    300: Ran 100 train steps in 21.94 secs\n",
            "Step    300: train CrossEntropyLoss |  0.16375719\n",
            "Step    300: eval  CrossEntropyLoss |  0.14824719\n",
            "Step    300: eval          Accuracy |  0.95555531\n",
            "\n",
            "Step    400: Ran 100 train steps in 6.98 secs\n",
            "Step    400: train CrossEntropyLoss |  0.14546825\n",
            "Step    400: eval  CrossEntropyLoss |  0.13619188\n",
            "Step    400: eval          Accuracy |  0.95773250\n",
            "\n",
            "Step    500: Ran 100 train steps in 4.80 secs\n",
            "Step    500: train CrossEntropyLoss |  0.11613698\n",
            "Step    500: eval  CrossEntropyLoss |  0.12938995\n",
            "Step    500: eval          Accuracy |  0.95938833\n",
            "\n",
            "Step    600: Ran 100 train steps in 7.03 secs\n",
            "Step    600: train CrossEntropyLoss |  0.11200197\n",
            "Step    600: eval  CrossEntropyLoss |  0.14101084\n",
            "Step    600: eval          Accuracy |  0.95491234\n",
            "\n",
            "Step    700: Ran 100 train steps in 4.78 secs\n",
            "Step    700: train CrossEntropyLoss |  0.10901097\n",
            "Step    700: eval  CrossEntropyLoss |  0.12925449\n",
            "Step    700: eval          Accuracy |  0.96190887\n",
            "\n",
            "Step    800: Ran 100 train steps in 4.87 secs\n",
            "Step    800: train CrossEntropyLoss |  0.11232267\n",
            "Step    800: eval  CrossEntropyLoss |  0.12860157\n",
            "Step    800: eval          Accuracy |  0.95917204\n",
            "\n",
            "Step    900: Ran 100 train steps in 4.81 secs\n",
            "Step    900: train CrossEntropyLoss |  0.11036286\n",
            "Step    900: eval  CrossEntropyLoss |  0.12547622\n",
            "Step    900: eval          Accuracy |  0.95923291\n",
            "\n",
            "Step   1000: Ran 100 train steps in 4.80 secs\n",
            "Step   1000: train CrossEntropyLoss |  0.09732069\n",
            "Step   1000: eval  CrossEntropyLoss |  0.14406857\n",
            "Step   1000: eval          Accuracy |  0.95617956\n",
            "\n",
            "Step   1100: Ran 100 train steps in 4.87 secs\n",
            "Step   1100: train CrossEntropyLoss |  0.08377498\n",
            "Step   1100: eval  CrossEntropyLoss |  0.13547863\n",
            "Step   1100: eval          Accuracy |  0.95890874\n",
            "\n",
            "Step   1200: Ran 100 train steps in 4.83 secs\n",
            "Step   1200: train CrossEntropyLoss |  0.08688127\n",
            "Step   1200: eval  CrossEntropyLoss |  0.13955658\n",
            "Step   1200: eval          Accuracy |  0.95737868\n",
            "\n",
            "Step   1300: Ran 100 train steps in 4.84 secs\n",
            "Step   1300: train CrossEntropyLoss |  0.08522156\n",
            "Step   1300: eval  CrossEntropyLoss |  0.12692447\n",
            "Step   1300: eval          Accuracy |  0.96205819\n",
            "\n",
            "Step   1400: Ran 100 train steps in 4.91 secs\n",
            "Step   1400: train CrossEntropyLoss |  0.08845505\n",
            "Step   1400: eval  CrossEntropyLoss |  0.12845862\n",
            "Step   1400: eval          Accuracy |  0.96037298\n",
            "\n",
            "Step   1500: Ran 100 train steps in 4.85 secs\n",
            "Step   1500: train CrossEntropyLoss |  0.08219770\n",
            "Step   1500: eval  CrossEntropyLoss |  0.13057200\n",
            "Step   1500: eval          Accuracy |  0.96080472\n",
            "\n",
            "Step   1600: Ran 100 train steps in 4.83 secs\n",
            "Step   1600: train CrossEntropyLoss |  0.06986045\n",
            "Step   1600: eval  CrossEntropyLoss |  0.14201261\n",
            "Step   1600: eval          Accuracy |  0.96033781\n",
            "\n",
            "Step   1700: Ran 100 train steps in 4.88 secs\n",
            "Step   1700: train CrossEntropyLoss |  0.07252695\n",
            "Step   1700: eval  CrossEntropyLoss |  0.12746077\n",
            "Step   1700: eval          Accuracy |  0.95987189\n",
            "\n",
            "Step   1800: Ran 100 train steps in 4.86 secs\n",
            "Step   1800: train CrossEntropyLoss |  0.07276916\n",
            "Step   1800: eval  CrossEntropyLoss |  0.14268371\n",
            "Step   1800: eval          Accuracy |  0.95975370\n",
            "\n",
            "Step   1900: Ran 100 train steps in 4.90 secs\n",
            "Step   1900: train CrossEntropyLoss |  0.07882407\n",
            "Step   1900: eval  CrossEntropyLoss |  0.12379672\n",
            "Step   1900: eval          Accuracy |  0.96392723\n",
            "\n",
            "Step   2000: Ran 100 train steps in 4.83 secs\n",
            "Step   2000: train CrossEntropyLoss |  0.07549696\n",
            "Step   2000: eval  CrossEntropyLoss |  0.13236081\n",
            "Step   2000: eval          Accuracy |  0.96238617\n",
            "\n",
            "Step   2100: Ran 100 train steps in 4.99 secs\n",
            "Step   2100: train CrossEntropyLoss |  0.06148193\n",
            "Step   2100: eval  CrossEntropyLoss |  0.12271655\n",
            "Step   2100: eval          Accuracy |  0.96293055\n",
            "\n",
            "Step   2200: Ran 100 train steps in 7.91 secs\n",
            "Step   2200: train CrossEntropyLoss |  0.06482998\n",
            "Step   2200: eval  CrossEntropyLoss |  0.14260302\n",
            "Step   2200: eval          Accuracy |  0.96016952\n",
            "\n",
            "Step   2300: Ran 100 train steps in 4.86 secs\n",
            "Step   2300: train CrossEntropyLoss |  0.06475228\n",
            "Step   2300: eval  CrossEntropyLoss |  0.13750478\n",
            "Step   2300: eval          Accuracy |  0.96099098\n",
            "\n",
            "Step   2400: Ran 100 train steps in 4.85 secs\n",
            "Step   2400: train CrossEntropyLoss |  0.06626358\n",
            "Step   2400: eval  CrossEntropyLoss |  0.14153803\n",
            "Step   2400: eval          Accuracy |  0.95978389\n",
            "\n",
            "Step   2500: Ran 100 train steps in 4.82 secs\n",
            "Step   2500: train CrossEntropyLoss |  0.06873260\n",
            "Step   2500: eval  CrossEntropyLoss |  0.13940416\n",
            "Step   2500: eval          Accuracy |  0.95917574\n",
            "\n",
            "Step   2600: Ran 100 train steps in 4.90 secs\n",
            "Step   2600: train CrossEntropyLoss |  0.05770193\n",
            "Step   2600: eval  CrossEntropyLoss |  0.15808803\n",
            "Step   2600: eval          Accuracy |  0.95666242\n",
            "\n",
            "Step   2700: Ran 100 train steps in 4.94 secs\n",
            "Step   2700: train CrossEntropyLoss |  0.05681932\n",
            "Step   2700: eval  CrossEntropyLoss |  0.16891425\n",
            "Step   2700: eval          Accuracy |  0.95698614\n",
            "\n",
            "Step   2800: Ran 100 train steps in 4.93 secs\n",
            "Step   2800: train CrossEntropyLoss |  0.06039001\n",
            "Step   2800: eval  CrossEntropyLoss |  0.15758846\n",
            "Step   2800: eval          Accuracy |  0.95910138\n",
            "\n",
            "Step   2900: Ran 100 train steps in 4.82 secs\n",
            "Step   2900: train CrossEntropyLoss |  0.05984971\n",
            "Step   2900: eval  CrossEntropyLoss |  0.15098854\n",
            "Step   2900: eval          Accuracy |  0.95940365\n",
            "\n",
            "Step   3000: Ran 100 train steps in 4.86 secs\n",
            "Step   3000: train CrossEntropyLoss |  0.05914232\n",
            "Step   3000: eval  CrossEntropyLoss |  0.16871491\n",
            "Step   3000: eval          Accuracy |  0.95497600\n",
            "\n",
            "Step   3100: Ran 100 train steps in 4.90 secs\n",
            "Step   3100: train CrossEntropyLoss |  0.05333068\n",
            "Step   3100: eval  CrossEntropyLoss |  0.15148538\n",
            "Step   3100: eval          Accuracy |  0.96036855\n",
            "\n",
            "Step   3200: Ran 100 train steps in 4.85 secs\n",
            "Step   3200: train CrossEntropyLoss |  0.05142917\n",
            "Step   3200: eval  CrossEntropyLoss |  0.16855585\n",
            "Step   3200: eval          Accuracy |  0.95643870\n",
            "\n",
            "Step   3300: Ran 100 train steps in 4.94 secs\n",
            "Step   3300: train CrossEntropyLoss |  0.05505650\n",
            "Step   3300: eval  CrossEntropyLoss |  0.15379020\n",
            "Step   3300: eval          Accuracy |  0.96001132\n",
            "\n",
            "Step   3400: Ran 100 train steps in 4.89 secs\n",
            "Step   3400: train CrossEntropyLoss |  0.05114526\n",
            "Step   3400: eval  CrossEntropyLoss |  0.16526661\n",
            "Step   3400: eval          Accuracy |  0.95830368\n",
            "\n",
            "Step   3500: Ran 100 train steps in 4.94 secs\n",
            "Step   3500: train CrossEntropyLoss |  0.05626849\n",
            "Step   3500: eval  CrossEntropyLoss |  0.16388917\n",
            "Step   3500: eval          Accuracy |  0.95847959\n",
            "\n",
            "Step   3600: Ran 100 train steps in 4.92 secs\n",
            "Step   3600: train CrossEntropyLoss |  0.05296349\n",
            "Step   3600: eval  CrossEntropyLoss |  0.15510636\n",
            "Step   3600: eval          Accuracy |  0.96089571\n",
            "\n",
            "Step   3700: Ran 100 train steps in 4.90 secs\n",
            "Step   3700: train CrossEntropyLoss |  0.04488217\n",
            "Step   3700: eval  CrossEntropyLoss |  0.17135974\n",
            "Step   3700: eval          Accuracy |  0.95472844\n",
            "\n",
            "Step   3800: Ran 100 train steps in 4.96 secs\n",
            "Step   3800: train CrossEntropyLoss |  0.04866855\n",
            "Step   3800: eval  CrossEntropyLoss |  0.15862462\n",
            "Step   3800: eval          Accuracy |  0.95978526\n",
            "\n",
            "Step   3900: Ran 100 train steps in 4.88 secs\n",
            "Step   3900: train CrossEntropyLoss |  0.05130301\n",
            "Step   3900: eval  CrossEntropyLoss |  0.18750419\n",
            "Step   3900: eval          Accuracy |  0.95463556\n",
            "\n",
            "Step   4000: Ran 100 train steps in 4.91 secs\n",
            "Step   4000: train CrossEntropyLoss |  0.05023866\n",
            "Step   4000: eval  CrossEntropyLoss |  0.17088061\n",
            "Step   4000: eval          Accuracy |  0.95797526\n",
            "\n",
            "Step   4100: Ran 100 train steps in 4.99 secs\n",
            "Step   4100: train CrossEntropyLoss |  0.05191183\n",
            "Step   4100: eval  CrossEntropyLoss |  0.16983773\n",
            "Step   4100: eval          Accuracy |  0.95783866\n",
            "\n",
            "Step   4200: Ran 100 train steps in 4.98 secs\n",
            "Step   4200: train CrossEntropyLoss |  0.04376448\n",
            "Step   4200: eval  CrossEntropyLoss |  0.17693058\n",
            "Step   4200: eval          Accuracy |  0.95826088\n",
            "\n",
            "Step   4300: Ran 100 train steps in 5.03 secs\n",
            "Step   4300: train CrossEntropyLoss |  0.04317262\n",
            "Step   4300: eval  CrossEntropyLoss |  0.19002749\n",
            "Step   4300: eval          Accuracy |  0.95484273\n",
            "\n",
            "Step   4400: Ran 100 train steps in 4.90 secs\n",
            "Step   4400: train CrossEntropyLoss |  0.04523901\n",
            "Step   4400: eval  CrossEntropyLoss |  0.16914199\n",
            "Step   4400: eval          Accuracy |  0.95832580\n",
            "\n",
            "Step   4500: Ran 100 train steps in 4.85 secs\n",
            "Step   4500: train CrossEntropyLoss |  0.04716823\n",
            "Step   4500: eval  CrossEntropyLoss |  0.16915936\n",
            "Step   4500: eval          Accuracy |  0.95767618\n",
            "\n",
            "Step   4600: Ran 100 train steps in 4.98 secs\n",
            "Step   4600: train CrossEntropyLoss |  0.04829094\n",
            "Step   4600: eval  CrossEntropyLoss |  0.19125670\n",
            "Step   4600: eval          Accuracy |  0.95348786\n",
            "\n",
            "Step   4700: Ran 100 train steps in 4.96 secs\n",
            "Step   4700: train CrossEntropyLoss |  0.04057803\n",
            "Step   4700: eval  CrossEntropyLoss |  0.18388388\n",
            "Step   4700: eval          Accuracy |  0.95666494\n",
            "\n",
            "Step   4800: Ran 100 train steps in 4.86 secs\n",
            "Step   4800: train CrossEntropyLoss |  0.04183752\n",
            "Step   4800: eval  CrossEntropyLoss |  0.18532117\n",
            "Step   4800: eval          Accuracy |  0.95780467\n",
            "\n",
            "Step   4900: Ran 100 train steps in 4.94 secs\n",
            "Step   4900: train CrossEntropyLoss |  0.04455711\n",
            "Step   4900: eval  CrossEntropyLoss |  0.21471634\n",
            "Step   4900: eval          Accuracy |  0.95469277\n",
            "\n",
            "Step   5000: Ran 100 train steps in 4.91 secs\n",
            "Step   5000: train CrossEntropyLoss |  0.04329351\n",
            "Step   5000: eval  CrossEntropyLoss |  0.16443573\n",
            "Step   5000: eval          Accuracy |  0.96170939\n",
            "\n",
            "Step   5100: Ran 100 train steps in 4.89 secs\n",
            "Step   5100: train CrossEntropyLoss |  0.04391962\n",
            "Step   5100: eval  CrossEntropyLoss |  0.21998580\n",
            "Step   5100: eval          Accuracy |  0.95351833\n",
            "\n",
            "Step   5200: Ran 100 train steps in 4.98 secs\n",
            "Step   5200: train CrossEntropyLoss |  0.03985831\n",
            "Step   5200: eval  CrossEntropyLoss |  0.17915666\n",
            "Step   5200: eval          Accuracy |  0.95910576\n",
            "\n",
            "Step   5300: Ran 100 train steps in 4.97 secs\n",
            "Step   5300: train CrossEntropyLoss |  0.03745200\n",
            "Step   5300: eval  CrossEntropyLoss |  0.17949682\n",
            "Step   5300: eval          Accuracy |  0.96269042\n",
            "\n",
            "Step   5400: Ran 100 train steps in 4.92 secs\n",
            "Step   5400: train CrossEntropyLoss |  0.03916579\n",
            "Step   5400: eval  CrossEntropyLoss |  0.18087271\n",
            "Step   5400: eval          Accuracy |  0.95983373\n",
            "\n",
            "Step   5500: Ran 100 train steps in 4.87 secs\n",
            "Step   5500: train CrossEntropyLoss |  0.04023695\n",
            "Step   5500: eval  CrossEntropyLoss |  0.22238724\n",
            "Step   5500: eval          Accuracy |  0.95553898\n",
            "\n",
            "Step   5600: Ran 100 train steps in 4.85 secs\n",
            "Step   5600: train CrossEntropyLoss |  0.04424050\n",
            "Step   5600: eval  CrossEntropyLoss |  0.19015546\n",
            "Step   5600: eval          Accuracy |  0.95595941\n",
            "\n",
            "Step   5700: Ran 100 train steps in 4.92 secs\n",
            "Step   5700: train CrossEntropyLoss |  0.04147295\n",
            "Step   5700: eval  CrossEntropyLoss |  0.19668973\n",
            "Step   5700: eval          Accuracy |  0.95573773\n",
            "\n",
            "Step   5800: Ran 100 train steps in 4.88 secs\n",
            "Step   5800: train CrossEntropyLoss |  0.03442756\n",
            "Step   5800: eval  CrossEntropyLoss |  0.19316072\n",
            "Step   5800: eval          Accuracy |  0.95907026\n",
            "\n",
            "Step   5900: Ran 100 train steps in 4.86 secs\n",
            "Step   5900: train CrossEntropyLoss |  0.03740108\n",
            "Step   5900: eval  CrossEntropyLoss |  0.20522508\n",
            "Step   5900: eval          Accuracy |  0.95361698\n",
            "\n",
            "Step   6000: Ran 100 train steps in 4.83 secs\n",
            "Step   6000: train CrossEntropyLoss |  0.03882932\n",
            "Step   6000: eval  CrossEntropyLoss |  0.23680456\n",
            "Step   6000: eval          Accuracy |  0.95333598\n",
            "\n",
            "Step   6100: Ran 100 train steps in 4.92 secs\n",
            "Step   6100: train CrossEntropyLoss |  0.03932067\n",
            "Step   6100: eval  CrossEntropyLoss |  0.17850370\n",
            "Step   6100: eval          Accuracy |  0.96125763\n",
            "\n",
            "Step   6200: Ran 100 train steps in 4.91 secs\n",
            "Step   6200: train CrossEntropyLoss |  0.04039375\n",
            "Step   6200: eval  CrossEntropyLoss |  0.18277602\n",
            "Step   6200: eval          Accuracy |  0.96099564\n",
            "\n",
            "Step   6300: Ran 100 train steps in 4.89 secs\n",
            "Step   6300: train CrossEntropyLoss |  0.03338759\n",
            "Step   6300: eval  CrossEntropyLoss |  0.21526333\n",
            "Step   6300: eval          Accuracy |  0.95561898\n",
            "\n",
            "Step   6400: Ran 100 train steps in 4.89 secs\n",
            "Step   6400: train CrossEntropyLoss |  0.03631762\n",
            "Step   6400: eval  CrossEntropyLoss |  0.21430316\n",
            "Step   6400: eval          Accuracy |  0.95556360\n",
            "\n",
            "Step   6500: Ran 100 train steps in 4.83 secs\n",
            "Step   6500: train CrossEntropyLoss |  0.03688716\n",
            "Step   6500: eval  CrossEntropyLoss |  0.22836282\n",
            "Step   6500: eval          Accuracy |  0.95514843\n",
            "\n",
            "Step   6600: Ran 100 train steps in 4.91 secs\n",
            "Step   6600: train CrossEntropyLoss |  0.03712523\n",
            "Step   6600: eval  CrossEntropyLoss |  0.20296596\n",
            "Step   6600: eval          Accuracy |  0.95562570\n",
            "\n",
            "Step   6700: Ran 100 train steps in 4.92 secs\n",
            "Step   6700: train CrossEntropyLoss |  0.03871882\n",
            "Step   6700: eval  CrossEntropyLoss |  0.22349010\n",
            "Step   6700: eval          Accuracy |  0.95353340\n",
            "\n",
            "Step   6800: Ran 100 train steps in 4.91 secs\n",
            "Step   6800: train CrossEntropyLoss |  0.03424604\n",
            "Step   6800: eval  CrossEntropyLoss |  0.20404058\n",
            "Step   6800: eval          Accuracy |  0.95845801\n",
            "\n",
            "Step   6900: Ran 100 train steps in 4.93 secs\n",
            "Step   6900: train CrossEntropyLoss |  0.03237421\n",
            "Step   6900: eval  CrossEntropyLoss |  0.20962374\n",
            "Step   6900: eval          Accuracy |  0.95605975\n",
            "\n",
            "Step   7000: Ran 100 train steps in 4.88 secs\n",
            "Step   7000: train CrossEntropyLoss |  0.03527811\n",
            "Step   7000: eval  CrossEntropyLoss |  0.25008385\n",
            "Step   7000: eval          Accuracy |  0.95051831\n",
            "\n",
            "Step   7100: Ran 100 train steps in 4.95 secs\n",
            "Step   7100: train CrossEntropyLoss |  0.03701025\n",
            "Step   7100: eval  CrossEntropyLoss |  0.19843965\n",
            "Step   7100: eval          Accuracy |  0.95865270\n",
            "\n",
            "Step   7200: Ran 100 train steps in 4.93 secs\n",
            "Step   7200: train CrossEntropyLoss |  0.03604259\n",
            "Step   7200: eval  CrossEntropyLoss |  0.23720466\n",
            "Step   7200: eval          Accuracy |  0.95146604\n",
            "\n",
            "Step   7300: Ran 100 train steps in 5.04 secs\n",
            "Step   7300: train CrossEntropyLoss |  0.03339300\n",
            "Step   7300: eval  CrossEntropyLoss |  0.21025278\n",
            "Step   7300: eval          Accuracy |  0.95821850\n",
            "\n",
            "Step   7400: Ran 100 train steps in 4.86 secs\n",
            "Step   7400: train CrossEntropyLoss |  0.03021117\n",
            "Step   7400: eval  CrossEntropyLoss |  0.20465277\n",
            "Step   7400: eval          Accuracy |  0.95801468\n",
            "\n",
            "Step   7500: Ran 100 train steps in 4.91 secs\n",
            "Step   7500: train CrossEntropyLoss |  0.03307040\n",
            "Step   7500: eval  CrossEntropyLoss |  0.22739249\n",
            "Step   7500: eval          Accuracy |  0.95380376\n",
            "\n",
            "Step   7600: Ran 100 train steps in 4.94 secs\n",
            "Step   7600: train CrossEntropyLoss |  0.03607288\n",
            "Step   7600: eval  CrossEntropyLoss |  0.22394723\n",
            "Step   7600: eval          Accuracy |  0.95622999\n",
            "\n",
            "Step   7700: Ran 100 train steps in 4.93 secs\n",
            "Step   7700: train CrossEntropyLoss |  0.03725535\n",
            "Step   7700: eval  CrossEntropyLoss |  0.21506385\n",
            "Step   7700: eval          Accuracy |  0.95393056\n",
            "\n",
            "Step   7800: Ran 100 train steps in 4.90 secs\n",
            "Step   7800: train CrossEntropyLoss |  0.03405213\n",
            "Step   7800: eval  CrossEntropyLoss |  0.21351889\n",
            "Step   7800: eval          Accuracy |  0.95999523\n",
            "\n",
            "Step   7900: Ran 100 train steps in 5.01 secs\n",
            "Step   7900: train CrossEntropyLoss |  0.03103863\n",
            "Step   7900: eval  CrossEntropyLoss |  0.19853133\n",
            "Step   7900: eval          Accuracy |  0.95766531\n",
            "\n",
            "Step   8000: Ran 100 train steps in 4.94 secs\n",
            "Step   8000: train CrossEntropyLoss |  0.03102046\n",
            "Step   8000: eval  CrossEntropyLoss |  0.22626946\n",
            "Step   8000: eval          Accuracy |  0.95463805\n",
            "\n",
            "Step   8100: Ran 100 train steps in 4.88 secs\n",
            "Step   8100: train CrossEntropyLoss |  0.03231738\n",
            "Step   8100: eval  CrossEntropyLoss |  0.22916219\n",
            "Step   8100: eval          Accuracy |  0.95336657\n",
            "\n",
            "Step   8200: Ran 100 train steps in 4.92 secs\n",
            "Step   8200: train CrossEntropyLoss |  0.03470822\n",
            "Step   8200: eval  CrossEntropyLoss |  0.25915881\n",
            "Step   8200: eval          Accuracy |  0.95132238\n",
            "\n",
            "Step   8300: Ran 100 train steps in 4.88 secs\n",
            "Step   8300: train CrossEntropyLoss |  0.03643078\n",
            "Step   8300: eval  CrossEntropyLoss |  0.22982072\n",
            "Step   8300: eval          Accuracy |  0.95286286\n",
            "\n",
            "Step   8400: Ran 100 train steps in 4.88 secs\n",
            "Step   8400: train CrossEntropyLoss |  0.02917650\n",
            "Step   8400: eval  CrossEntropyLoss |  0.24468738\n",
            "Step   8400: eval          Accuracy |  0.95460723\n",
            "\n",
            "Step   8500: Ran 100 train steps in 4.87 secs\n",
            "Step   8500: train CrossEntropyLoss |  0.03049855\n",
            "Step   8500: eval  CrossEntropyLoss |  0.24135863\n",
            "Step   8500: eval          Accuracy |  0.95416802\n",
            "\n",
            "Step   8600: Ran 100 train steps in 4.94 secs\n",
            "Step   8600: train CrossEntropyLoss |  0.03110057\n",
            "Step   8600: eval  CrossEntropyLoss |  0.23030310\n",
            "Step   8600: eval          Accuracy |  0.95793169\n",
            "\n",
            "Step   8700: Ran 100 train steps in 4.92 secs\n",
            "Step   8700: train CrossEntropyLoss |  0.03630383\n",
            "Step   8700: eval  CrossEntropyLoss |  0.20469021\n",
            "Step   8700: eval          Accuracy |  0.95900282\n",
            "\n",
            "Step   8800: Ran 100 train steps in 4.89 secs\n",
            "Step   8800: train CrossEntropyLoss |  0.03451693\n",
            "Step   8800: eval  CrossEntropyLoss |  0.24809228\n",
            "Step   8800: eval          Accuracy |  0.95056553\n",
            "\n",
            "Step   8900: Ran 100 train steps in 4.95 secs\n",
            "Step   8900: train CrossEntropyLoss |  0.02983365\n",
            "Step   8900: eval  CrossEntropyLoss |  0.27875521\n",
            "Step   8900: eval          Accuracy |  0.95028982\n",
            "\n",
            "Step   9000: Ran 100 train steps in 4.93 secs\n",
            "Step   9000: train CrossEntropyLoss |  0.02939017\n",
            "Step   9000: eval  CrossEntropyLoss |  0.20038815\n",
            "Step   9000: eval          Accuracy |  0.95778376\n",
            "\n",
            "Step   9100: Ran 100 train steps in 4.88 secs\n",
            "Step   9100: train CrossEntropyLoss |  0.03069820\n",
            "Step   9100: eval  CrossEntropyLoss |  0.20253153\n",
            "Step   9100: eval          Accuracy |  0.95809343\n",
            "\n",
            "Step   9200: Ran 100 train steps in 4.92 secs\n",
            "Step   9200: train CrossEntropyLoss |  0.03242422\n",
            "Step   9200: eval  CrossEntropyLoss |  0.25489300\n",
            "Step   9200: eval          Accuracy |  0.95632673\n",
            "\n",
            "Step   9300: Ran 100 train steps in 4.92 secs\n",
            "Step   9300: train CrossEntropyLoss |  0.03363055\n",
            "Step   9300: eval  CrossEntropyLoss |  0.22652013\n",
            "Step   9300: eval          Accuracy |  0.95813614\n",
            "\n",
            "Step   9400: Ran 100 train steps in 4.94 secs\n",
            "Step   9400: train CrossEntropyLoss |  0.03050291\n",
            "Step   9400: eval  CrossEntropyLoss |  0.21690507\n",
            "Step   9400: eval          Accuracy |  0.95861420\n",
            "\n",
            "Step   9500: Ran 100 train steps in 4.93 secs\n",
            "Step   9500: train CrossEntropyLoss |  0.02809137\n",
            "Step   9500: eval  CrossEntropyLoss |  0.24580826\n",
            "Step   9500: eval          Accuracy |  0.95683542\n",
            "\n",
            "Step   9600: Ran 100 train steps in 4.90 secs\n",
            "Step   9600: train CrossEntropyLoss |  0.02952977\n",
            "Step   9600: eval  CrossEntropyLoss |  0.26060107\n",
            "Step   9600: eval          Accuracy |  0.95200487\n",
            "\n",
            "Step   9700: Ran 100 train steps in 4.97 secs\n",
            "Step   9700: train CrossEntropyLoss |  0.03218891\n",
            "Step   9700: eval  CrossEntropyLoss |  0.23277034\n",
            "Step   9700: eval          Accuracy |  0.95659024\n",
            "\n",
            "Step   9800: Ran 100 train steps in 4.85 secs\n",
            "Step   9800: train CrossEntropyLoss |  0.03033944\n",
            "Step   9800: eval  CrossEntropyLoss |  0.25582552\n",
            "Step   9800: eval          Accuracy |  0.95164747\n",
            "\n",
            "Step   9900: Ran 100 train steps in 4.95 secs\n",
            "Step   9900: train CrossEntropyLoss |  0.03050824\n",
            "Step   9900: eval  CrossEntropyLoss |  0.25966871\n",
            "Step   9900: eval          Accuracy |  0.95206290\n",
            "\n",
            "Step  10000: Ran 100 train steps in 4.90 secs\n",
            "Step  10000: train CrossEntropyLoss |  0.02842061\n",
            "Step  10000: eval  CrossEntropyLoss |  0.22286558\n",
            "Step  10000: eval          Accuracy |  0.95603838\n",
            "\n",
            "Step  10100: Ran 100 train steps in 4.91 secs\n",
            "Step  10100: train CrossEntropyLoss |  0.02803221\n",
            "Step  10100: eval  CrossEntropyLoss |  0.24652427\n",
            "Step  10100: eval          Accuracy |  0.95393030\n",
            "\n",
            "Step  10200: Ran 100 train steps in 4.91 secs\n",
            "Step  10200: train CrossEntropyLoss |  0.02941588\n",
            "Step  10200: eval  CrossEntropyLoss |  0.22521104\n",
            "Step  10200: eval          Accuracy |  0.95846426\n",
            "\n",
            "Step  10300: Ran 100 train steps in 4.94 secs\n",
            "Step  10300: train CrossEntropyLoss |  0.02903104\n",
            "Step  10300: eval  CrossEntropyLoss |  0.25666848\n",
            "Step  10300: eval          Accuracy |  0.95482978\n",
            "\n",
            "Step  10400: Ran 100 train steps in 4.90 secs\n",
            "Step  10400: train CrossEntropyLoss |  0.03209244\n",
            "Step  10400: eval  CrossEntropyLoss |  0.28461246\n",
            "Step  10400: eval          Accuracy |  0.95157040\n",
            "\n",
            "Step  10500: Ran 100 train steps in 4.90 secs\n",
            "Step  10500: train CrossEntropyLoss |  0.02634134\n",
            "Step  10500: eval  CrossEntropyLoss |  0.26781581\n",
            "Step  10500: eval          Accuracy |  0.95243233\n",
            "\n",
            "Step  10600: Ran 100 train steps in 4.98 secs\n",
            "Step  10600: train CrossEntropyLoss |  0.02853242\n",
            "Step  10600: eval  CrossEntropyLoss |  0.26800146\n",
            "Step  10600: eval          Accuracy |  0.95239928\n",
            "\n",
            "Step  10700: Ran 100 train steps in 4.89 secs\n",
            "Step  10700: train CrossEntropyLoss |  0.02871610\n",
            "Step  10700: eval  CrossEntropyLoss |  0.24798166\n",
            "Step  10700: eval          Accuracy |  0.95402398\n",
            "\n",
            "Step  10800: Ran 100 train steps in 4.93 secs\n",
            "Step  10800: train CrossEntropyLoss |  0.03159463\n",
            "Step  10800: eval  CrossEntropyLoss |  0.22095925\n",
            "Step  10800: eval          Accuracy |  0.95833800\n",
            "\n",
            "Step  10900: Ran 100 train steps in 4.91 secs\n",
            "Step  10900: train CrossEntropyLoss |  0.03148589\n",
            "Step  10900: eval  CrossEntropyLoss |  0.23384192\n",
            "Step  10900: eval          Accuracy |  0.95914280\n",
            "\n",
            "Step  11000: Ran 100 train steps in 4.98 secs\n",
            "Step  11000: train CrossEntropyLoss |  0.02605086\n",
            "Step  11000: eval  CrossEntropyLoss |  0.27612552\n",
            "Step  11000: eval          Accuracy |  0.95230376\n",
            "\n",
            "Step  11100: Ran 100 train steps in 4.95 secs\n",
            "Step  11100: train CrossEntropyLoss |  0.02795641\n",
            "Step  11100: eval  CrossEntropyLoss |  0.24394120\n",
            "Step  11100: eval          Accuracy |  0.95567302\n",
            "\n",
            "Step  11200: Ran 100 train steps in 4.93 secs\n",
            "Step  11200: train CrossEntropyLoss |  0.02914907\n",
            "Step  11200: eval  CrossEntropyLoss |  0.23336928\n",
            "Step  11200: eval          Accuracy |  0.95636135\n",
            "\n",
            "Step  11300: Ran 100 train steps in 4.92 secs\n",
            "Step  11300: train CrossEntropyLoss |  0.03094017\n",
            "Step  11300: eval  CrossEntropyLoss |  0.23589494\n",
            "Step  11300: eval          Accuracy |  0.95378688\n",
            "\n",
            "Step  11400: Ran 100 train steps in 4.89 secs\n",
            "Step  11400: train CrossEntropyLoss |  0.03159397\n",
            "Step  11400: eval  CrossEntropyLoss |  0.27261778\n",
            "Step  11400: eval          Accuracy |  0.95123391\n",
            "\n",
            "Step  11500: Ran 100 train steps in 4.92 secs\n",
            "Step  11500: train CrossEntropyLoss |  0.02720048\n",
            "Step  11500: eval  CrossEntropyLoss |  0.26033370\n",
            "Step  11500: eval          Accuracy |  0.95426313\n",
            "\n",
            "Step  11600: Ran 100 train steps in 4.90 secs\n",
            "Step  11600: train CrossEntropyLoss |  0.02783435\n",
            "Step  11600: eval  CrossEntropyLoss |  0.23479432\n",
            "Step  11600: eval          Accuracy |  0.95756071\n",
            "\n",
            "Step  11700: Ran 100 train steps in 4.90 secs\n",
            "Step  11700: train CrossEntropyLoss |  0.02887570\n",
            "Step  11700: eval  CrossEntropyLoss |  0.28603336\n",
            "Step  11700: eval          Accuracy |  0.95145155\n",
            "\n",
            "Step  11800: Ran 100 train steps in 5.00 secs\n",
            "Step  11800: train CrossEntropyLoss |  0.02909405\n",
            "Step  11800: eval  CrossEntropyLoss |  0.23070237\n",
            "Step  11800: eval          Accuracy |  0.95700961\n",
            "\n",
            "Step  11900: Ran 100 train steps in 4.91 secs\n",
            "Step  11900: train CrossEntropyLoss |  0.03058123\n",
            "Step  11900: eval  CrossEntropyLoss |  0.23977901\n",
            "Step  11900: eval          Accuracy |  0.95784333\n",
            "\n",
            "Step  12000: Ran 100 train steps in 4.95 secs\n",
            "Step  12000: train CrossEntropyLoss |  0.02804769\n",
            "Step  12000: eval  CrossEntropyLoss |  0.26305541\n",
            "Step  12000: eval          Accuracy |  0.95516053\n",
            "\n",
            "Step  12100: Ran 100 train steps in 4.96 secs\n",
            "Step  12100: train CrossEntropyLoss |  0.02482599\n",
            "Step  12100: eval  CrossEntropyLoss |  0.25318093\n",
            "Step  12100: eval          Accuracy |  0.95233534\n",
            "\n",
            "Step  12200: Ran 100 train steps in 4.92 secs\n",
            "Step  12200: train CrossEntropyLoss |  0.02660408\n",
            "Step  12200: eval  CrossEntropyLoss |  0.25205650\n",
            "Step  12200: eval          Accuracy |  0.95276750\n",
            "\n",
            "Step  12300: Ran 100 train steps in 4.95 secs\n",
            "Step  12300: train CrossEntropyLoss |  0.02710485\n",
            "Step  12300: eval  CrossEntropyLoss |  0.28540176\n",
            "Step  12300: eval          Accuracy |  0.95298410\n",
            "\n",
            "Step  12400: Ran 100 train steps in 4.91 secs\n",
            "Step  12400: train CrossEntropyLoss |  0.02822561\n",
            "Step  12400: eval  CrossEntropyLoss |  0.24683642\n",
            "Step  12400: eval          Accuracy |  0.95381712\n",
            "\n",
            "Step  12500: Ran 100 train steps in 4.95 secs\n",
            "Step  12500: train CrossEntropyLoss |  0.02874941\n",
            "Step  12500: eval  CrossEntropyLoss |  0.27320663\n",
            "Step  12500: eval          Accuracy |  0.95384655\n",
            "\n",
            "Step  12600: Ran 100 train steps in 4.99 secs\n",
            "Step  12600: train CrossEntropyLoss |  0.02418293\n",
            "Step  12600: eval  CrossEntropyLoss |  0.26682191\n",
            "Step  12600: eval          Accuracy |  0.95642073\n",
            "\n",
            "Step  12700: Ran 100 train steps in 4.89 secs\n",
            "Step  12700: train CrossEntropyLoss |  0.02507129\n",
            "Step  12700: eval  CrossEntropyLoss |  0.26771675\n",
            "Step  12700: eval          Accuracy |  0.95134717\n",
            "\n",
            "Step  12800: Ran 100 train steps in 4.89 secs\n",
            "Step  12800: train CrossEntropyLoss |  0.02510171\n",
            "Step  12800: eval  CrossEntropyLoss |  0.26162937\n",
            "Step  12800: eval          Accuracy |  0.95570175\n",
            "\n",
            "Step  12900: Ran 100 train steps in 4.85 secs\n",
            "Step  12900: train CrossEntropyLoss |  0.02737096\n",
            "Step  12900: eval  CrossEntropyLoss |  0.28765938\n",
            "Step  12900: eval          Accuracy |  0.95335884\n",
            "\n",
            "Step  13000: Ran 100 train steps in 4.91 secs\n",
            "Step  13000: train CrossEntropyLoss |  0.03097895\n",
            "Step  13000: eval  CrossEntropyLoss |  0.19778678\n",
            "Step  13000: eval          Accuracy |  0.96238641\n",
            "\n",
            "Step  13100: Ran 100 train steps in 4.89 secs\n",
            "Step  13100: train CrossEntropyLoss |  0.02377463\n",
            "Step  13100: eval  CrossEntropyLoss |  0.27840807\n",
            "Step  13100: eval          Accuracy |  0.95270671\n",
            "\n",
            "Step  13200: Ran 100 train steps in 4.97 secs\n",
            "Step  13200: train CrossEntropyLoss |  0.02492542\n",
            "Step  13200: eval  CrossEntropyLoss |  0.27370501\n",
            "Step  13200: eval          Accuracy |  0.95275449\n",
            "\n",
            "Step  13300: Ran 100 train steps in 4.97 secs\n",
            "Step  13300: train CrossEntropyLoss |  0.02750043\n",
            "Step  13300: eval  CrossEntropyLoss |  0.27107221\n",
            "Step  13300: eval          Accuracy |  0.95476077\n",
            "\n",
            "Step  13400: Ran 100 train steps in 4.92 secs\n",
            "Step  13400: train CrossEntropyLoss |  0.02860798\n",
            "Step  13400: eval  CrossEntropyLoss |  0.25179979\n",
            "Step  13400: eval          Accuracy |  0.95579315\n",
            "\n",
            "Step  13500: Ran 100 train steps in 4.90 secs\n",
            "Step  13500: train CrossEntropyLoss |  0.02741897\n",
            "Step  13500: eval  CrossEntropyLoss |  0.25409042\n",
            "Step  13500: eval          Accuracy |  0.95634983\n",
            "\n",
            "Step  13600: Ran 100 train steps in 4.91 secs\n",
            "Step  13600: train CrossEntropyLoss |  0.02589678\n",
            "Step  13600: eval  CrossEntropyLoss |  0.30050913\n",
            "Step  13600: eval          Accuracy |  0.95253487\n",
            "\n",
            "Step  13700: Ran 100 train steps in 4.97 secs\n",
            "Step  13700: train CrossEntropyLoss |  0.02394540\n",
            "Step  13700: eval  CrossEntropyLoss |  0.26823495\n",
            "Step  13700: eval          Accuracy |  0.95357137\n",
            "\n",
            "Step  13800: Ran 100 train steps in 4.95 secs\n",
            "Step  13800: train CrossEntropyLoss |  0.02546205\n",
            "Step  13800: eval  CrossEntropyLoss |  0.29010044\n",
            "Step  13800: eval          Accuracy |  0.95521739\n",
            "\n",
            "Step  13900: Ran 100 train steps in 4.97 secs\n",
            "Step  13900: train CrossEntropyLoss |  0.02777708\n",
            "Step  13900: eval  CrossEntropyLoss |  0.27136312\n",
            "Step  13900: eval          Accuracy |  0.95424752\n",
            "\n",
            "Step  14000: Ran 100 train steps in 4.93 secs\n",
            "Step  14000: train CrossEntropyLoss |  0.02949958\n",
            "Step  14000: eval  CrossEntropyLoss |  0.25602424\n",
            "Step  14000: eval          Accuracy |  0.95263458\n",
            "\n",
            "Step  14100: Ran 100 train steps in 4.92 secs\n",
            "Step  14100: train CrossEntropyLoss |  0.02786341\n",
            "Step  14100: eval  CrossEntropyLoss |  0.26610681\n",
            "Step  14100: eval          Accuracy |  0.95514330\n",
            "\n",
            "Step  14200: Ran 100 train steps in 4.90 secs\n",
            "Step  14200: train CrossEntropyLoss |  0.02497931\n",
            "Step  14200: eval  CrossEntropyLoss |  0.26962964\n",
            "Step  14200: eval          Accuracy |  0.95534774\n",
            "\n",
            "Step  14300: Ran 100 train steps in 4.89 secs\n",
            "Step  14300: train CrossEntropyLoss |  0.02737940\n",
            "Step  14300: eval  CrossEntropyLoss |  0.25412256\n",
            "Step  14300: eval          Accuracy |  0.95439504\n",
            "\n",
            "Step  14400: Ran 100 train steps in 4.89 secs\n",
            "Step  14400: train CrossEntropyLoss |  0.02878186\n",
            "Step  14400: eval  CrossEntropyLoss |  0.22338688\n",
            "Step  14400: eval          Accuracy |  0.95549223\n",
            "\n",
            "Step  14500: Ran 100 train steps in 4.92 secs\n",
            "Step  14500: train CrossEntropyLoss |  0.02832721\n",
            "Step  14500: eval  CrossEntropyLoss |  0.26553386\n",
            "Step  14500: eval          Accuracy |  0.95477785\n",
            "\n",
            "Step  14600: Ran 100 train steps in 4.93 secs\n",
            "Step  14600: train CrossEntropyLoss |  0.02886957\n",
            "Step  14600: eval  CrossEntropyLoss |  0.27064442\n",
            "Step  14600: eval          Accuracy |  0.95461891\n",
            "\n",
            "Step  14700: Ran 100 train steps in 4.91 secs\n",
            "Step  14700: train CrossEntropyLoss |  0.02575055\n",
            "Step  14700: eval  CrossEntropyLoss |  0.27380014\n",
            "Step  14700: eval          Accuracy |  0.95562074\n",
            "\n",
            "Step  14800: Ran 100 train steps in 4.97 secs\n",
            "Step  14800: train CrossEntropyLoss |  0.02392744\n",
            "Step  14800: eval  CrossEntropyLoss |  0.28248149\n",
            "Step  14800: eval          Accuracy |  0.95511461\n",
            "\n",
            "Step  14900: Ran 100 train steps in 4.93 secs\n",
            "Step  14900: train CrossEntropyLoss |  0.02747950\n",
            "Step  14900: eval  CrossEntropyLoss |  0.30286929\n",
            "Step  14900: eval          Accuracy |  0.95297781\n",
            "\n",
            "Step  15000: Ran 100 train steps in 4.87 secs\n",
            "Step  15000: train CrossEntropyLoss |  0.02568032\n",
            "Step  15000: eval  CrossEntropyLoss |  0.27757823\n",
            "Step  15000: eval          Accuracy |  0.95319061\n",
            "\n",
            "Step  15100: Ran 100 train steps in 4.98 secs\n",
            "Step  15100: train CrossEntropyLoss |  0.02773324\n",
            "Step  15100: eval  CrossEntropyLoss |  0.23630227\n",
            "Step  15100: eval          Accuracy |  0.95662019\n",
            "\n",
            "Step  15200: Ran 100 train steps in 4.97 secs\n",
            "Step  15200: train CrossEntropyLoss |  0.02390944\n",
            "Step  15200: eval  CrossEntropyLoss |  0.25021469\n",
            "Step  15200: eval          Accuracy |  0.95874450\n",
            "\n",
            "Step  15300: Ran 100 train steps in 4.86 secs\n",
            "Step  15300: train CrossEntropyLoss |  0.02376456\n",
            "Step  15300: eval  CrossEntropyLoss |  0.27414332\n",
            "Step  15300: eval          Accuracy |  0.95579994\n",
            "\n",
            "Step  15400: Ran 100 train steps in 4.94 secs\n",
            "Step  15400: train CrossEntropyLoss |  0.02377014\n",
            "Step  15400: eval  CrossEntropyLoss |  0.27379884\n",
            "Step  15400: eval          Accuracy |  0.95326697\n",
            "\n",
            "Step  15500: Ran 100 train steps in 4.83 secs\n",
            "Step  15500: train CrossEntropyLoss |  0.02562551\n",
            "Step  15500: eval  CrossEntropyLoss |  0.27435037\n",
            "Step  15500: eval          Accuracy |  0.95465393\n",
            "\n",
            "Step  15600: Ran 100 train steps in 4.94 secs\n",
            "Step  15600: train CrossEntropyLoss |  0.02793318\n",
            "Step  15600: eval  CrossEntropyLoss |  0.26976732\n",
            "Step  15600: eval          Accuracy |  0.95336446\n",
            "\n",
            "Step  15700: Ran 100 train steps in 4.95 secs\n",
            "Step  15700: train CrossEntropyLoss |  0.02436496\n",
            "Step  15700: eval  CrossEntropyLoss |  0.32807748\n",
            "Step  15700: eval          Accuracy |  0.95180446\n",
            "\n",
            "Step  15800: Ran 100 train steps in 4.90 secs\n",
            "Step  15800: train CrossEntropyLoss |  0.02392073\n",
            "Step  15800: eval  CrossEntropyLoss |  0.29366978\n",
            "Step  15800: eval          Accuracy |  0.95409691\n",
            "\n",
            "Step  15900: Ran 100 train steps in 4.92 secs\n",
            "Step  15900: train CrossEntropyLoss |  0.02534679\n",
            "Step  15900: eval  CrossEntropyLoss |  0.27461579\n",
            "Step  15900: eval          Accuracy |  0.95459498\n",
            "\n",
            "Step  16000: Ran 100 train steps in 4.88 secs\n",
            "Step  16000: train CrossEntropyLoss |  0.02854981\n",
            "Step  16000: eval  CrossEntropyLoss |  0.26861931\n",
            "Step  16000: eval          Accuracy |  0.95499115\n",
            "\n",
            "Step  16100: Ran 100 train steps in 4.87 secs\n",
            "Step  16100: train CrossEntropyLoss |  0.02867344\n",
            "Step  16100: eval  CrossEntropyLoss |  0.28444202\n",
            "Step  16100: eval          Accuracy |  0.95256854\n",
            "\n",
            "Step  16200: Ran 100 train steps in 4.96 secs\n",
            "Step  16200: train CrossEntropyLoss |  0.02627707\n",
            "Step  16200: eval  CrossEntropyLoss |  0.28121476\n",
            "Step  16200: eval          Accuracy |  0.95394434\n",
            "\n",
            "Step  16300: Ran 100 train steps in 4.96 secs\n",
            "Step  16300: train CrossEntropyLoss |  0.02459813\n",
            "Step  16300: eval  CrossEntropyLoss |  0.26817069\n",
            "Step  16300: eval          Accuracy |  0.95745166\n",
            "\n",
            "Step  16400: Ran 100 train steps in 4.93 secs\n",
            "Step  16400: train CrossEntropyLoss |  0.02365868\n",
            "Step  16400: eval  CrossEntropyLoss |  0.24966185\n",
            "Step  16400: eval          Accuracy |  0.95688854\n",
            "\n",
            "Step  16500: Ran 100 train steps in 5.03 secs\n",
            "Step  16500: train CrossEntropyLoss |  0.02554789\n",
            "Step  16500: eval  CrossEntropyLoss |  0.24170350\n",
            "Step  16500: eval          Accuracy |  0.95576134\n",
            "\n",
            "Step  16600: Ran 100 train steps in 4.95 secs\n",
            "Step  16600: train CrossEntropyLoss |  0.02738483\n",
            "Step  16600: eval  CrossEntropyLoss |  0.27322189\n",
            "Step  16600: eval          Accuracy |  0.95262265\n",
            "\n",
            "Step  16700: Ran 100 train steps in 4.87 secs\n",
            "Step  16700: train CrossEntropyLoss |  0.02674086\n",
            "Step  16700: eval  CrossEntropyLoss |  0.29486377\n",
            "Step  16700: eval          Accuracy |  0.95545031\n",
            "\n",
            "Step  16800: Ran 100 train steps in 4.89 secs\n",
            "Step  16800: train CrossEntropyLoss |  0.02281946\n",
            "Step  16800: eval  CrossEntropyLoss |  0.27485335\n",
            "Step  16800: eval          Accuracy |  0.95354044\n",
            "\n",
            "Step  16900: Ran 100 train steps in 4.98 secs\n",
            "Step  16900: train CrossEntropyLoss |  0.02311370\n",
            "Step  16900: eval  CrossEntropyLoss |  0.25896233\n",
            "Step  16900: eval          Accuracy |  0.95758594\n",
            "\n",
            "Step  17000: Ran 100 train steps in 4.92 secs\n",
            "Step  17000: train CrossEntropyLoss |  0.02625807\n",
            "Step  17000: eval  CrossEntropyLoss |  0.27369674\n",
            "Step  17000: eval          Accuracy |  0.95379090\n",
            "\n",
            "Step  17100: Ran 100 train steps in 4.90 secs\n",
            "Step  17100: train CrossEntropyLoss |  0.02914332\n",
            "Step  17100: eval  CrossEntropyLoss |  0.29614066\n",
            "Step  17100: eval          Accuracy |  0.95371061\n",
            "\n",
            "Step  17200: Ran 100 train steps in 4.92 secs\n",
            "Step  17200: train CrossEntropyLoss |  0.02732607\n",
            "Step  17200: eval  CrossEntropyLoss |  0.26219002\n",
            "Step  17200: eval          Accuracy |  0.95592176\n",
            "\n",
            "Step  17300: Ran 100 train steps in 4.89 secs\n",
            "Step  17300: train CrossEntropyLoss |  0.02216065\n",
            "Step  17300: eval  CrossEntropyLoss |  0.28023591\n",
            "Step  17300: eval          Accuracy |  0.95321293\n",
            "\n",
            "Step  17400: Ran 100 train steps in 4.94 secs\n",
            "Step  17400: train CrossEntropyLoss |  0.02440002\n",
            "Step  17400: eval  CrossEntropyLoss |  0.27695781\n",
            "Step  17400: eval          Accuracy |  0.95634645\n",
            "\n",
            "Step  17500: Ran 100 train steps in 4.88 secs\n",
            "Step  17500: train CrossEntropyLoss |  0.02597102\n",
            "Step  17500: eval  CrossEntropyLoss |  0.25545228\n",
            "Step  17500: eval          Accuracy |  0.95622851\n",
            "\n",
            "Step  17600: Ran 100 train steps in 4.94 secs\n",
            "Step  17600: train CrossEntropyLoss |  0.02687937\n",
            "Step  17600: eval  CrossEntropyLoss |  0.30556403\n",
            "Step  17600: eval          Accuracy |  0.95275530\n",
            "\n",
            "Step  17700: Ran 100 train steps in 4.95 secs\n",
            "Step  17700: train CrossEntropyLoss |  0.02768926\n",
            "Step  17700: eval  CrossEntropyLoss |  0.25785775\n",
            "Step  17700: eval          Accuracy |  0.95549201\n",
            "\n",
            "Step  17800: Ran 100 train steps in 4.94 secs\n",
            "Step  17800: train CrossEntropyLoss |  0.02465576\n",
            "Step  17800: eval  CrossEntropyLoss |  0.27114404\n",
            "Step  17800: eval          Accuracy |  0.95769507\n",
            "\n",
            "Step  17900: Ran 100 train steps in 4.88 secs\n",
            "Step  17900: train CrossEntropyLoss |  0.02330356\n",
            "Step  17900: eval  CrossEntropyLoss |  0.29094635\n",
            "Step  17900: eval          Accuracy |  0.95528188\n",
            "\n",
            "Step  18000: Ran 100 train steps in 4.95 secs\n",
            "Step  18000: train CrossEntropyLoss |  0.02466743\n",
            "Step  18000: eval  CrossEntropyLoss |  0.30478004\n",
            "Step  18000: eval          Accuracy |  0.95025606\n",
            "\n",
            "Step  18100: Ran 100 train steps in 4.97 secs\n",
            "Step  18100: train CrossEntropyLoss |  0.02692505\n",
            "Step  18100: eval  CrossEntropyLoss |  0.25665457\n",
            "Step  18100: eval          Accuracy |  0.95500503\n",
            "\n",
            "Step  18200: Ran 100 train steps in 4.94 secs\n",
            "Step  18200: train CrossEntropyLoss |  0.02959444\n",
            "Step  18200: eval  CrossEntropyLoss |  0.33226890\n",
            "Step  18200: eval          Accuracy |  0.94940559\n",
            "\n",
            "Step  18300: Ran 100 train steps in 4.95 secs\n",
            "Step  18300: train CrossEntropyLoss |  0.02726680\n",
            "Step  18300: eval  CrossEntropyLoss |  0.24430537\n",
            "Step  18300: eval          Accuracy |  0.95481550\n",
            "\n",
            "Step  18400: Ran 100 train steps in 4.99 secs\n",
            "Step  18400: train CrossEntropyLoss |  0.02313332\n",
            "Step  18400: eval  CrossEntropyLoss |  0.28348910\n",
            "Step  18400: eval          Accuracy |  0.95471040\n",
            "\n",
            "Step  18500: Ran 100 train steps in 4.94 secs\n",
            "Step  18500: train CrossEntropyLoss |  0.02457263\n",
            "Step  18500: eval  CrossEntropyLoss |  0.28299568\n",
            "Step  18500: eval          Accuracy |  0.95294110\n",
            "\n",
            "Step  18600: Ran 100 train steps in 4.94 secs\n",
            "Step  18600: train CrossEntropyLoss |  0.02459397\n",
            "Step  18600: eval  CrossEntropyLoss |  0.25371575\n",
            "Step  18600: eval          Accuracy |  0.95926999\n",
            "\n",
            "Step  18700: Ran 100 train steps in 4.85 secs\n",
            "Step  18700: train CrossEntropyLoss |  0.02692035\n",
            "Step  18700: eval  CrossEntropyLoss |  0.28247916\n",
            "Step  18700: eval          Accuracy |  0.95201327\n",
            "\n",
            "Step  18800: Ran 100 train steps in 4.91 secs\n",
            "Step  18800: train CrossEntropyLoss |  0.02552187\n",
            "Step  18800: eval  CrossEntropyLoss |  0.31234207\n",
            "Step  18800: eval          Accuracy |  0.95146093\n",
            "\n",
            "Step  18900: Ran 100 train steps in 4.86 secs\n",
            "Step  18900: train CrossEntropyLoss |  0.02263629\n",
            "Step  18900: eval  CrossEntropyLoss |  0.29078168\n",
            "Step  18900: eval          Accuracy |  0.95471957\n",
            "\n",
            "Step  19000: Ran 100 train steps in 4.95 secs\n",
            "Step  19000: train CrossEntropyLoss |  0.02231415\n",
            "Step  19000: eval  CrossEntropyLoss |  0.27355054\n",
            "Step  19000: eval          Accuracy |  0.95441877\n",
            "\n",
            "Step  19100: Ran 100 train steps in 5.00 secs\n",
            "Step  19100: train CrossEntropyLoss |  0.02401092\n",
            "Step  19100: eval  CrossEntropyLoss |  0.28256518\n",
            "Step  19100: eval          Accuracy |  0.95345826\n",
            "\n",
            "Step  19200: Ran 100 train steps in 4.93 secs\n",
            "Step  19200: train CrossEntropyLoss |  0.02695766\n",
            "Step  19200: eval  CrossEntropyLoss |  0.29989437\n",
            "Step  19200: eval          Accuracy |  0.95180182\n",
            "\n",
            "Step  19300: Ran 100 train steps in 4.96 secs\n",
            "Step  19300: train CrossEntropyLoss |  0.02740575\n",
            "Step  19300: eval  CrossEntropyLoss |  0.29402774\n",
            "Step  19300: eval          Accuracy |  0.95158574\n",
            "\n",
            "Step  19400: Ran 100 train steps in 4.94 secs\n",
            "Step  19400: train CrossEntropyLoss |  0.02356087\n",
            "Step  19400: eval  CrossEntropyLoss |  0.27869782\n",
            "Step  19400: eval          Accuracy |  0.95378107\n",
            "\n",
            "Step  19500: Ran 100 train steps in 4.94 secs\n",
            "Step  19500: train CrossEntropyLoss |  0.02339783\n",
            "Step  19500: eval  CrossEntropyLoss |  0.28249974\n",
            "Step  19500: eval          Accuracy |  0.95404271\n",
            "\n",
            "Step  19600: Ran 100 train steps in 4.89 secs\n",
            "Step  19600: train CrossEntropyLoss |  0.02468227\n",
            "Step  19600: eval  CrossEntropyLoss |  0.25355552\n",
            "Step  19600: eval          Accuracy |  0.95663188\n",
            "\n",
            "Step  19700: Ran 100 train steps in 4.93 secs\n",
            "Step  19700: train CrossEntropyLoss |  0.02485909\n",
            "Step  19700: eval  CrossEntropyLoss |  0.30189552\n",
            "Step  19700: eval          Accuracy |  0.95302007\n",
            "\n",
            "Step  19800: Ran 100 train steps in 7.52 secs\n",
            "Step  19800: train CrossEntropyLoss |  0.02741232\n",
            "Step  19800: eval  CrossEntropyLoss |  0.26213893\n",
            "Step  19800: eval          Accuracy |  0.95507820\n",
            "\n",
            "Step  19900: Ran 100 train steps in 4.96 secs\n",
            "Step  19900: train CrossEntropyLoss |  0.02416979\n",
            "Step  19900: eval  CrossEntropyLoss |  0.30537858\n",
            "Step  19900: eval          Accuracy |  0.95436966\n",
            "\n",
            "Step  20000: Ran 100 train steps in 4.93 secs\n",
            "Step  20000: train CrossEntropyLoss |  0.02318648\n",
            "Step  20000: eval  CrossEntropyLoss |  0.27040908\n",
            "Step  20000: eval          Accuracy |  0.95697265\n",
            "\n",
            "Step  20100: Ran 100 train steps in 4.99 secs\n",
            "Step  20100: train CrossEntropyLoss |  0.02425270\n",
            "Step  20100: eval  CrossEntropyLoss |  0.32295448\n",
            "Step  20100: eval          Accuracy |  0.94973888\n",
            "\n",
            "Step  20200: Ran 100 train steps in 5.01 secs\n",
            "Step  20200: train CrossEntropyLoss |  0.02544891\n",
            "Step  20200: eval  CrossEntropyLoss |  0.27530162\n",
            "Step  20200: eval          Accuracy |  0.95354024\n",
            "\n",
            "Step  20300: Ran 100 train steps in 4.89 secs\n",
            "Step  20300: train CrossEntropyLoss |  0.02693385\n",
            "Step  20300: eval  CrossEntropyLoss |  0.30125242\n",
            "Step  20300: eval          Accuracy |  0.95286258\n",
            "\n",
            "Step  20400: Ran 100 train steps in 5.02 secs\n",
            "Step  20400: train CrossEntropyLoss |  0.02584822\n",
            "Step  20400: eval  CrossEntropyLoss |  0.29478819\n",
            "Step  20400: eval          Accuracy |  0.95257156\n",
            "\n",
            "Step  20500: Ran 100 train steps in 4.89 secs\n",
            "Step  20500: train CrossEntropyLoss |  0.02359872\n",
            "Step  20500: eval  CrossEntropyLoss |  0.27989027\n",
            "Step  20500: eval          Accuracy |  0.95472393\n",
            "\n",
            "Step  20600: Ran 100 train steps in 4.88 secs\n",
            "Step  20600: train CrossEntropyLoss |  0.02354335\n",
            "Step  20600: eval  CrossEntropyLoss |  0.32918503\n",
            "Step  20600: eval          Accuracy |  0.95061764\n",
            "\n",
            "Step  20700: Ran 100 train steps in 4.89 secs\n",
            "Step  20700: train CrossEntropyLoss |  0.02618646\n",
            "Step  20700: eval  CrossEntropyLoss |  0.25209122\n",
            "Step  20700: eval          Accuracy |  0.95487244\n",
            "\n",
            "Step  20800: Ran 100 train steps in 4.85 secs\n",
            "Step  20800: train CrossEntropyLoss |  0.02728573\n",
            "Step  20800: eval  CrossEntropyLoss |  0.24286512\n",
            "Step  20800: eval          Accuracy |  0.95736495\n",
            "\n",
            "Step  20900: Ran 100 train steps in 4.93 secs\n",
            "Step  20900: train CrossEntropyLoss |  0.02839245\n",
            "Step  20900: eval  CrossEntropyLoss |  0.26230308\n",
            "Step  20900: eval          Accuracy |  0.95776929\n",
            "\n",
            "Step  21000: Ran 100 train steps in 4.92 secs\n",
            "Step  21000: train CrossEntropyLoss |  0.02236080\n",
            "Step  21000: eval  CrossEntropyLoss |  0.33634161\n",
            "Step  21000: eval          Accuracy |  0.94834885\n",
            "\n",
            "Step  21100: Ran 100 train steps in 4.91 secs\n",
            "Step  21100: train CrossEntropyLoss |  0.02455110\n",
            "Step  21100: eval  CrossEntropyLoss |  0.28806066\n",
            "Step  21100: eval          Accuracy |  0.95340955\n",
            "\n",
            "Step  21200: Ran 100 train steps in 4.87 secs\n",
            "Step  21200: train CrossEntropyLoss |  0.02688238\n",
            "Step  21200: eval  CrossEntropyLoss |  0.29121177\n",
            "Step  21200: eval          Accuracy |  0.95274073\n",
            "\n",
            "Step  21300: Ran 100 train steps in 4.86 secs\n",
            "Step  21300: train CrossEntropyLoss |  0.02646519\n",
            "Step  21300: eval  CrossEntropyLoss |  0.25081599\n",
            "Step  21300: eval          Accuracy |  0.95777637\n",
            "\n",
            "Step  21400: Ran 100 train steps in 4.98 secs\n",
            "Step  21400: train CrossEntropyLoss |  0.02685949\n",
            "Step  21400: eval  CrossEntropyLoss |  0.27907484\n",
            "Step  21400: eval          Accuracy |  0.95595011\n",
            "\n",
            "Step  21500: Ran 100 train steps in 4.94 secs\n",
            "Step  21500: train CrossEntropyLoss |  0.02365653\n",
            "Step  21500: eval  CrossEntropyLoss |  0.26858491\n",
            "Step  21500: eval          Accuracy |  0.95521336\n",
            "\n",
            "Step  21600: Ran 100 train steps in 4.90 secs\n",
            "Step  21600: train CrossEntropyLoss |  0.02493707\n",
            "Step  21600: eval  CrossEntropyLoss |  0.29980329\n",
            "Step  21600: eval          Accuracy |  0.95202139\n",
            "\n",
            "Step  21700: Ran 100 train steps in 4.95 secs\n",
            "Step  21700: train CrossEntropyLoss |  0.02644541\n",
            "Step  21700: eval  CrossEntropyLoss |  0.27794078\n",
            "Step  21700: eval          Accuracy |  0.95392982\n",
            "\n",
            "Step  21800: Ran 100 train steps in 4.87 secs\n",
            "Step  21800: train CrossEntropyLoss |  0.02595049\n",
            "Step  21800: eval  CrossEntropyLoss |  0.27774374\n",
            "Step  21800: eval          Accuracy |  0.95570274\n",
            "\n",
            "Step  21900: Ran 100 train steps in 4.92 secs\n",
            "Step  21900: train CrossEntropyLoss |  0.02639462\n",
            "Step  21900: eval  CrossEntropyLoss |  0.28470229\n",
            "Step  21900: eval          Accuracy |  0.95380642\n",
            "\n",
            "Step  22000: Ran 100 train steps in 4.91 secs\n",
            "Step  22000: train CrossEntropyLoss |  0.02184938\n",
            "Step  22000: eval  CrossEntropyLoss |  0.28971137\n",
            "Step  22000: eval          Accuracy |  0.95353662\n",
            "\n",
            "Step  22100: Ran 100 train steps in 4.88 secs\n",
            "Step  22100: train CrossEntropyLoss |  0.02256152\n",
            "Step  22100: eval  CrossEntropyLoss |  0.28417396\n",
            "Step  22100: eval          Accuracy |  0.95651482\n",
            "\n",
            "Step  22200: Ran 100 train steps in 4.86 secs\n",
            "Step  22200: train CrossEntropyLoss |  0.02378336\n",
            "Step  22200: eval  CrossEntropyLoss |  0.29566508\n",
            "Step  22200: eval          Accuracy |  0.95410525\n",
            "\n",
            "Step  22300: Ran 100 train steps in 4.90 secs\n",
            "Step  22300: train CrossEntropyLoss |  0.02363010\n",
            "Step  22300: eval  CrossEntropyLoss |  0.28658791\n",
            "Step  22300: eval          Accuracy |  0.95588467\n",
            "\n",
            "Step  22400: Ran 100 train steps in 4.92 secs\n",
            "Step  22400: train CrossEntropyLoss |  0.02633260\n",
            "Step  22400: eval  CrossEntropyLoss |  0.27231612\n",
            "Step  22400: eval          Accuracy |  0.95405964\n",
            "\n",
            "Step  22500: Ran 100 train steps in 4.96 secs\n",
            "Step  22500: train CrossEntropyLoss |  0.02605294\n",
            "Step  22500: eval  CrossEntropyLoss |  0.30269292\n",
            "Step  22500: eval          Accuracy |  0.95477829\n",
            "\n",
            "Step  22600: Ran 100 train steps in 4.87 secs\n",
            "Step  22600: train CrossEntropyLoss |  0.02119619\n",
            "Step  22600: eval  CrossEntropyLoss |  0.30910389\n",
            "Step  22600: eval          Accuracy |  0.95257810\n",
            "\n",
            "Step  22700: Ran 100 train steps in 5.00 secs\n",
            "Step  22700: train CrossEntropyLoss |  0.02259215\n",
            "Step  22700: eval  CrossEntropyLoss |  0.33497632\n",
            "Step  22700: eval          Accuracy |  0.94844782\n",
            "\n",
            "Step  22800: Ran 100 train steps in 4.83 secs\n",
            "Step  22800: train CrossEntropyLoss |  0.02216887\n",
            "Step  22800: eval  CrossEntropyLoss |  0.23966785\n",
            "Step  22800: eval          Accuracy |  0.96172141\n",
            "\n",
            "Step  22900: Ran 100 train steps in 4.83 secs\n",
            "Step  22900: train CrossEntropyLoss |  0.02633477\n",
            "Step  22900: eval  CrossEntropyLoss |  0.28863524\n",
            "Step  22900: eval          Accuracy |  0.95163897\n",
            "\n",
            "Step  23000: Ran 100 train steps in 4.96 secs\n",
            "Step  23000: train CrossEntropyLoss |  0.02449305\n",
            "Step  23000: eval  CrossEntropyLoss |  0.29755165\n",
            "Step  23000: eval          Accuracy |  0.95410305\n",
            "\n",
            "Step  23100: Ran 100 train steps in 4.92 secs\n",
            "Step  23100: train CrossEntropyLoss |  0.01964963\n",
            "Step  23100: eval  CrossEntropyLoss |  0.29359590\n",
            "Step  23100: eval          Accuracy |  0.95465549\n",
            "\n",
            "Step  23200: Ran 100 train steps in 4.85 secs\n",
            "Step  23200: train CrossEntropyLoss |  0.02285751\n",
            "Step  23200: eval  CrossEntropyLoss |  0.31891187\n",
            "Step  23200: eval          Accuracy |  0.95239136\n",
            "\n",
            "Step  23300: Ran 100 train steps in 4.84 secs\n",
            "Step  23300: train CrossEntropyLoss |  0.02484332\n",
            "Step  23300: eval  CrossEntropyLoss |  0.28803788\n",
            "Step  23300: eval          Accuracy |  0.95479165\n",
            "\n",
            "Step  23400: Ran 100 train steps in 4.87 secs\n",
            "Step  23400: train CrossEntropyLoss |  0.02443797\n",
            "Step  23400: eval  CrossEntropyLoss |  0.29765919\n",
            "Step  23400: eval          Accuracy |  0.95524232\n",
            "\n",
            "Step  23500: Ran 100 train steps in 4.85 secs\n",
            "Step  23500: train CrossEntropyLoss |  0.02648404\n",
            "Step  23500: eval  CrossEntropyLoss |  0.28359656\n",
            "Step  23500: eval          Accuracy |  0.95498384\n",
            "\n",
            "Step  23600: Ran 100 train steps in 4.92 secs\n",
            "Step  23600: train CrossEntropyLoss |  0.02095919\n",
            "Step  23600: eval  CrossEntropyLoss |  0.30084805\n",
            "Step  23600: eval          Accuracy |  0.95164903\n",
            "\n",
            "Step  23700: Ran 100 train steps in 5.00 secs\n",
            "Step  23700: train CrossEntropyLoss |  0.02124705\n",
            "Step  23700: eval  CrossEntropyLoss |  0.29315692\n",
            "Step  23700: eval          Accuracy |  0.95455117\n",
            "\n",
            "Step  23800: Ran 100 train steps in 4.90 secs\n",
            "Step  23800: train CrossEntropyLoss |  0.02296201\n",
            "Step  23800: eval  CrossEntropyLoss |  0.30908139\n",
            "Step  23800: eval          Accuracy |  0.95434029\n",
            "\n",
            "Step  23900: Ran 100 train steps in 4.80 secs\n",
            "Step  23900: train CrossEntropyLoss |  0.02493534\n",
            "Step  23900: eval  CrossEntropyLoss |  0.33311512\n",
            "Step  23900: eval          Accuracy |  0.95042965\n",
            "\n",
            "Step  24000: Ran 100 train steps in 4.91 secs\n",
            "Step  24000: train CrossEntropyLoss |  0.02624198\n",
            "Step  24000: eval  CrossEntropyLoss |  0.28815081\n",
            "Step  24000: eval          Accuracy |  0.95745018\n",
            "\n",
            "Step  24100: Ran 100 train steps in 4.89 secs\n",
            "Step  24100: train CrossEntropyLoss |  0.02355924\n",
            "Step  24100: eval  CrossEntropyLoss |  0.29796663\n",
            "Step  24100: eval          Accuracy |  0.95551324\n",
            "\n",
            "Step  24200: Ran 100 train steps in 4.82 secs\n",
            "Step  24200: train CrossEntropyLoss |  0.02329881\n",
            "Step  24200: eval  CrossEntropyLoss |  0.31993391\n",
            "Step  24200: eval          Accuracy |  0.95489326\n",
            "\n",
            "Step  24300: Ran 100 train steps in 4.90 secs\n",
            "Step  24300: train CrossEntropyLoss |  0.02351302\n",
            "Step  24300: eval  CrossEntropyLoss |  0.29642472\n",
            "Step  24300: eval          Accuracy |  0.95346745\n",
            "\n",
            "Step  24400: Ran 100 train steps in 4.96 secs\n",
            "Step  24400: train CrossEntropyLoss |  0.02483552\n",
            "Step  24400: eval  CrossEntropyLoss |  0.29239840\n",
            "Step  24400: eval          Accuracy |  0.95352591\n",
            "\n",
            "Step  24500: Ran 100 train steps in 4.89 secs\n",
            "Step  24500: train CrossEntropyLoss |  0.02704873\n",
            "Step  24500: eval  CrossEntropyLoss |  0.29748940\n",
            "Step  24500: eval          Accuracy |  0.95393558\n",
            "\n",
            "Step  24600: Ran 100 train steps in 4.91 secs\n",
            "Step  24600: train CrossEntropyLoss |  0.02555885\n",
            "Step  24600: eval  CrossEntropyLoss |  0.30828509\n",
            "Step  24600: eval          Accuracy |  0.95422127\n",
            "\n",
            "Step  24700: Ran 100 train steps in 4.84 secs\n",
            "Step  24700: train CrossEntropyLoss |  0.02361700\n",
            "Step  24700: eval  CrossEntropyLoss |  0.31218571\n",
            "Step  24700: eval          Accuracy |  0.95371887\n",
            "\n",
            "Step  24800: Ran 100 train steps in 4.89 secs\n",
            "Step  24800: train CrossEntropyLoss |  0.02327417\n",
            "Step  24800: eval  CrossEntropyLoss |  0.31534228\n",
            "Step  24800: eval          Accuracy |  0.95134015\n",
            "\n",
            "Step  24900: Ran 100 train steps in 4.86 secs\n",
            "Step  24900: train CrossEntropyLoss |  0.02468519\n",
            "Step  24900: eval  CrossEntropyLoss |  0.27889325\n",
            "Step  24900: eval          Accuracy |  0.95408785\n",
            "\n",
            "Step  25000: Ran 100 train steps in 4.88 secs\n",
            "Step  25000: train CrossEntropyLoss |  0.02457287\n",
            "Step  25000: eval  CrossEntropyLoss |  0.29176632\n",
            "Step  25000: eval          Accuracy |  0.95322340\n",
            "\n",
            "Step  25100: Ran 100 train steps in 4.97 secs\n",
            "Step  25100: train CrossEntropyLoss |  0.02498616\n",
            "Step  25100: eval  CrossEntropyLoss |  0.29360070\n",
            "Step  25100: eval          Accuracy |  0.95537463\n",
            "\n",
            "Step  25200: Ran 100 train steps in 4.93 secs\n",
            "Step  25200: train CrossEntropyLoss |  0.02108165\n",
            "Step  25200: eval  CrossEntropyLoss |  0.27242222\n",
            "Step  25200: eval          Accuracy |  0.95714844\n",
            "\n",
            "Step  25300: Ran 100 train steps in 5.00 secs\n",
            "Step  25300: train CrossEntropyLoss |  0.02381295\n",
            "Step  25300: eval  CrossEntropyLoss |  0.30220031\n",
            "Step  25300: eval          Accuracy |  0.95434107\n",
            "\n",
            "Step  25400: Ran 100 train steps in 4.84 secs\n",
            "Step  25400: train CrossEntropyLoss |  0.02533272\n",
            "Step  25400: eval  CrossEntropyLoss |  0.31304724\n",
            "Step  25400: eval          Accuracy |  0.95278389\n",
            "\n",
            "Step  25500: Ran 100 train steps in 4.87 secs\n",
            "Step  25500: train CrossEntropyLoss |  0.02641772\n",
            "Step  25500: eval  CrossEntropyLoss |  0.30454311\n",
            "Step  25500: eval          Accuracy |  0.95376405\n",
            "\n",
            "Step  25600: Ran 100 train steps in 4.83 secs\n",
            "Step  25600: train CrossEntropyLoss |  0.02642516\n",
            "Step  25600: eval  CrossEntropyLoss |  0.32813745\n",
            "Step  25600: eval          Accuracy |  0.95146858\n",
            "\n",
            "Step  25700: Ran 100 train steps in 4.90 secs\n",
            "Step  25700: train CrossEntropyLoss |  0.02230790\n",
            "Step  25700: eval  CrossEntropyLoss |  0.27852707\n",
            "Step  25700: eval          Accuracy |  0.95825109\n",
            "\n",
            "Step  25800: Ran 100 train steps in 4.87 secs\n",
            "Step  25800: train CrossEntropyLoss |  0.02364866\n",
            "Step  25800: eval  CrossEntropyLoss |  0.30858491\n",
            "Step  25800: eval          Accuracy |  0.95135122\n",
            "\n",
            "Step  25900: Ran 100 train steps in 4.93 secs\n",
            "Step  25900: train CrossEntropyLoss |  0.02411428\n",
            "Step  25900: eval  CrossEntropyLoss |  0.37628215\n",
            "Step  25900: eval          Accuracy |  0.94699603\n",
            "\n",
            "Step  26000: Ran 100 train steps in 4.87 secs\n",
            "Step  26000: train CrossEntropyLoss |  0.02601150\n",
            "Step  26000: eval  CrossEntropyLoss |  0.28476770\n",
            "Step  26000: eval          Accuracy |  0.95563986\n",
            "\n",
            "Step  26100: Ran 100 train steps in 4.82 secs\n",
            "Step  26100: train CrossEntropyLoss |  0.02584977\n",
            "Step  26100: eval  CrossEntropyLoss |  0.28856047\n",
            "Step  26100: eval          Accuracy |  0.95436187\n",
            "\n",
            "Step  26200: Ran 100 train steps in 4.90 secs\n",
            "Step  26200: train CrossEntropyLoss |  0.02244973\n",
            "Step  26200: eval  CrossEntropyLoss |  0.28433993\n",
            "Step  26200: eval          Accuracy |  0.95523226\n",
            "\n",
            "Step  26300: Ran 100 train steps in 4.87 secs\n",
            "Step  26300: train CrossEntropyLoss |  0.02275973\n",
            "Step  26300: eval  CrossEntropyLoss |  0.29626753\n",
            "Step  26300: eval          Accuracy |  0.95461304\n",
            "\n",
            "Step  26400: Ran 100 train steps in 4.89 secs\n",
            "Step  26400: train CrossEntropyLoss |  0.02272972\n",
            "Step  26400: eval  CrossEntropyLoss |  0.31817195\n",
            "Step  26400: eval          Accuracy |  0.95063656\n",
            "\n",
            "Step  26500: Ran 100 train steps in 4.84 secs\n",
            "Step  26500: train CrossEntropyLoss |  0.02612207\n",
            "Step  26500: eval  CrossEntropyLoss |  0.24962237\n",
            "Step  26500: eval          Accuracy |  0.95796297\n",
            "\n",
            "Step  26600: Ran 100 train steps in 4.88 secs\n",
            "Step  26600: train CrossEntropyLoss |  0.02563306\n",
            "Step  26600: eval  CrossEntropyLoss |  0.26638500\n",
            "Step  26600: eval          Accuracy |  0.95688235\n",
            "\n",
            "Step  26700: Ran 100 train steps in 4.93 secs\n",
            "Step  26700: train CrossEntropyLoss |  0.02478456\n",
            "Step  26700: eval  CrossEntropyLoss |  0.31520820\n",
            "Step  26700: eval          Accuracy |  0.95098835\n",
            "\n",
            "Step  26800: Ran 100 train steps in 4.83 secs\n",
            "Step  26800: train CrossEntropyLoss |  0.02248772\n",
            "Step  26800: eval  CrossEntropyLoss |  0.30329096\n",
            "Step  26800: eval          Accuracy |  0.95410051\n",
            "\n",
            "Step  26900: Ran 100 train steps in 4.89 secs\n",
            "Step  26900: train CrossEntropyLoss |  0.02355843\n",
            "Step  26900: eval  CrossEntropyLoss |  0.31915110\n",
            "Step  26900: eval          Accuracy |  0.95438845\n",
            "\n",
            "Step  27000: Ran 100 train steps in 4.87 secs\n",
            "Step  27000: train CrossEntropyLoss |  0.02374146\n",
            "Step  27000: eval  CrossEntropyLoss |  0.27026073\n",
            "Step  27000: eval          Accuracy |  0.95634651\n",
            "\n",
            "Step  27100: Ran 100 train steps in 4.85 secs\n",
            "Step  27100: train CrossEntropyLoss |  0.02527113\n",
            "Step  27100: eval  CrossEntropyLoss |  0.30184660\n",
            "Step  27100: eval          Accuracy |  0.95534455\n",
            "\n",
            "Step  27200: Ran 100 train steps in 4.91 secs\n",
            "Step  27200: train CrossEntropyLoss |  0.02576686\n",
            "Step  27200: eval  CrossEntropyLoss |  0.28001916\n",
            "Step  27200: eval          Accuracy |  0.95317471\n",
            "\n",
            "Step  27300: Ran 100 train steps in 4.78 secs\n",
            "Step  27300: train CrossEntropyLoss |  0.02148199\n",
            "Step  27300: eval  CrossEntropyLoss |  0.31465414\n",
            "Step  27300: eval          Accuracy |  0.95392859\n",
            "\n",
            "Step  27400: Ran 100 train steps in 4.86 secs\n",
            "Step  27400: train CrossEntropyLoss |  0.02245998\n",
            "Step  27400: eval  CrossEntropyLoss |  0.32246173\n",
            "Step  27400: eval          Accuracy |  0.95212048\n",
            "\n",
            "Step  27500: Ran 100 train steps in 4.91 secs\n",
            "Step  27500: train CrossEntropyLoss |  0.02458535\n",
            "Step  27500: eval  CrossEntropyLoss |  0.29351939\n",
            "Step  27500: eval          Accuracy |  0.95243369\n",
            "\n",
            "Step  27600: Ran 100 train steps in 4.89 secs\n",
            "Step  27600: train CrossEntropyLoss |  0.02490714\n",
            "Step  27600: eval  CrossEntropyLoss |  0.29072199\n",
            "Step  27600: eval          Accuracy |  0.95263684\n",
            "\n",
            "Step  27700: Ran 100 train steps in 4.94 secs\n",
            "Step  27700: train CrossEntropyLoss |  0.02657572\n",
            "Step  27700: eval  CrossEntropyLoss |  0.29053023\n",
            "Step  27700: eval          Accuracy |  0.95370036\n",
            "\n",
            "Step  27800: Ran 100 train steps in 4.89 secs\n",
            "Step  27800: train CrossEntropyLoss |  0.02113278\n",
            "Step  27800: eval  CrossEntropyLoss |  0.28235687\n",
            "Step  27800: eval          Accuracy |  0.95666630\n",
            "\n",
            "Step  27900: Ran 100 train steps in 4.90 secs\n",
            "Step  27900: train CrossEntropyLoss |  0.02113295\n",
            "Step  27900: eval  CrossEntropyLoss |  0.28161137\n",
            "Step  27900: eval          Accuracy |  0.95670620\n",
            "\n",
            "Step  28000: Ran 100 train steps in 4.83 secs\n",
            "Step  28000: train CrossEntropyLoss |  0.02289353\n",
            "Step  28000: eval  CrossEntropyLoss |  0.31449006\n",
            "Step  28000: eval          Accuracy |  0.95237496\n",
            "\n",
            "Step  28100: Ran 100 train steps in 4.91 secs\n",
            "Step  28100: train CrossEntropyLoss |  0.02494498\n",
            "Step  28100: eval  CrossEntropyLoss |  0.28393292\n",
            "Step  28100: eval          Accuracy |  0.95355324\n",
            "\n",
            "Step  28200: Ran 100 train steps in 4.80 secs\n",
            "Step  28200: train CrossEntropyLoss |  0.02556065\n",
            "Step  28200: eval  CrossEntropyLoss |  0.31844165\n",
            "Step  28200: eval          Accuracy |  0.95474708\n",
            "\n",
            "Step  28300: Ran 100 train steps in 4.95 secs\n",
            "Step  28300: train CrossEntropyLoss |  0.02115393\n",
            "Step  28300: eval  CrossEntropyLoss |  0.26171116\n",
            "Step  28300: eval          Accuracy |  0.95952451\n",
            "\n",
            "Step  28400: Ran 100 train steps in 4.87 secs\n",
            "Step  28400: train CrossEntropyLoss |  0.02147097\n",
            "Step  28400: eval  CrossEntropyLoss |  0.33171474\n",
            "Step  28400: eval          Accuracy |  0.95370985\n",
            "\n",
            "Step  28500: Ran 100 train steps in 4.87 secs\n",
            "Step  28500: train CrossEntropyLoss |  0.02011124\n",
            "Step  28500: eval  CrossEntropyLoss |  0.34350442\n",
            "Step  28500: eval          Accuracy |  0.94989217\n",
            "\n",
            "Step  28600: Ran 100 train steps in 4.85 secs\n",
            "Step  28600: train CrossEntropyLoss |  0.02408906\n",
            "Step  28600: eval  CrossEntropyLoss |  0.33183126\n",
            "Step  28600: eval          Accuracy |  0.95225632\n",
            "\n",
            "Step  28700: Ran 100 train steps in 4.91 secs\n",
            "Step  28700: train CrossEntropyLoss |  0.02450660\n",
            "Step  28700: eval  CrossEntropyLoss |  0.26819469\n",
            "Step  28700: eval          Accuracy |  0.95620393\n",
            "\n",
            "Step  28800: Ran 100 train steps in 4.99 secs\n",
            "Step  28800: train CrossEntropyLoss |  0.02394066\n",
            "Step  28800: eval  CrossEntropyLoss |  0.31246788\n",
            "Step  28800: eval          Accuracy |  0.95207564\n",
            "\n",
            "Step  28900: Ran 100 train steps in 4.85 secs\n",
            "Step  28900: train CrossEntropyLoss |  0.02129651\n",
            "Step  28900: eval  CrossEntropyLoss |  0.31147643\n",
            "Step  28900: eval          Accuracy |  0.95514418\n",
            "\n",
            "Step  29000: Ran 100 train steps in 4.90 secs\n",
            "Step  29000: train CrossEntropyLoss |  0.02355717\n",
            "Step  29000: eval  CrossEntropyLoss |  0.31371442\n",
            "Step  29000: eval          Accuracy |  0.95219552\n",
            "\n",
            "Step  29100: Ran 100 train steps in 4.82 secs\n",
            "Step  29100: train CrossEntropyLoss |  0.02549446\n",
            "Step  29100: eval  CrossEntropyLoss |  0.32905490\n",
            "Step  29100: eval          Accuracy |  0.95177781\n",
            "\n",
            "Step  29200: Ran 100 train steps in 4.87 secs\n",
            "Step  29200: train CrossEntropyLoss |  0.02693945\n",
            "Step  29200: eval  CrossEntropyLoss |  0.30737839\n",
            "Step  29200: eval          Accuracy |  0.95404905\n",
            "\n",
            "Step  29300: Ran 100 train steps in 4.88 secs\n",
            "Step  29300: train CrossEntropyLoss |  0.02565357\n",
            "Step  29300: eval  CrossEntropyLoss |  0.28668078\n",
            "Step  29300: eval          Accuracy |  0.95659168\n",
            "\n",
            "Step  29400: Ran 100 train steps in 4.84 secs\n",
            "Step  29400: train CrossEntropyLoss |  0.02065425\n",
            "Step  29400: eval  CrossEntropyLoss |  0.25953876\n",
            "Step  29400: eval          Accuracy |  0.95818115\n",
            "\n",
            "Step  29500: Ran 100 train steps in 4.86 secs\n",
            "Step  29500: train CrossEntropyLoss |  0.02404697\n",
            "Step  29500: eval  CrossEntropyLoss |  0.28833287\n",
            "Step  29500: eval          Accuracy |  0.95499286\n",
            "\n",
            "Step  29600: Ran 100 train steps in 4.85 secs\n",
            "Step  29600: train CrossEntropyLoss |  0.02606491\n",
            "Step  29600: eval  CrossEntropyLoss |  0.32899471\n",
            "Step  29600: eval          Accuracy |  0.95235128\n",
            "\n",
            "Step  29700: Ran 100 train steps in 4.89 secs\n",
            "Step  29700: train CrossEntropyLoss |  0.02492450\n",
            "Step  29700: eval  CrossEntropyLoss |  0.30923800\n",
            "Step  29700: eval          Accuracy |  0.95391625\n",
            "\n",
            "Step  29800: Ran 100 train steps in 4.89 secs\n",
            "Step  29800: train CrossEntropyLoss |  0.02609837\n",
            "Step  29800: eval  CrossEntropyLoss |  0.28965283\n",
            "Step  29800: eval          Accuracy |  0.95447442\n",
            "\n",
            "Step  29900: Ran 100 train steps in 4.91 secs\n",
            "Step  29900: train CrossEntropyLoss |  0.02027932\n",
            "Step  29900: eval  CrossEntropyLoss |  0.30198982\n",
            "Step  29900: eval          Accuracy |  0.95718256\n",
            "\n",
            "Step  30000: Ran 100 train steps in 4.84 secs\n",
            "Step  30000: train CrossEntropyLoss |  0.02363306\n",
            "Step  30000: eval  CrossEntropyLoss |  0.28213213\n",
            "Step  30000: eval          Accuracy |  0.95751649\n",
            "\n",
            "Step  30100: Ran 100 train steps in 4.81 secs\n",
            "Step  30100: train CrossEntropyLoss |  0.02405297\n",
            "Step  30100: eval  CrossEntropyLoss |  0.32367315\n",
            "Step  30100: eval          Accuracy |  0.95271783\n",
            "\n",
            "Step  30200: Ran 100 train steps in 4.81 secs\n",
            "Step  30200: train CrossEntropyLoss |  0.02500363\n",
            "Step  30200: eval  CrossEntropyLoss |  0.26945372\n",
            "Step  30200: eval          Accuracy |  0.95839399\n",
            "\n",
            "Step  30300: Ran 100 train steps in 4.96 secs\n",
            "Step  30300: train CrossEntropyLoss |  0.02566601\n",
            "Step  30300: eval  CrossEntropyLoss |  0.32692446\n",
            "Step  30300: eval          Accuracy |  0.95305335\n",
            "\n",
            "Step  30400: Ran 100 train steps in 4.97 secs\n",
            "Step  30400: train CrossEntropyLoss |  0.02120598\n",
            "Step  30400: eval  CrossEntropyLoss |  0.29377077\n",
            "Step  30400: eval          Accuracy |  0.95445884\n",
            "\n",
            "Step  30500: Ran 100 train steps in 4.89 secs\n",
            "Step  30500: train CrossEntropyLoss |  0.02196331\n",
            "Step  30500: eval  CrossEntropyLoss |  0.30814922\n",
            "Step  30500: eval          Accuracy |  0.95202942\n",
            "\n",
            "Step  30600: Ran 100 train steps in 4.86 secs\n",
            "Step  30600: train CrossEntropyLoss |  0.02291652\n",
            "Step  30600: eval  CrossEntropyLoss |  0.27808941\n",
            "Step  30600: eval          Accuracy |  0.96036761\n",
            "\n",
            "Step  30700: Ran 100 train steps in 4.83 secs\n",
            "Step  30700: train CrossEntropyLoss |  0.02340478\n",
            "Step  30700: eval  CrossEntropyLoss |  0.33026343\n",
            "Step  30700: eval          Accuracy |  0.95140994\n",
            "\n",
            "Step  30800: Ran 100 train steps in 4.88 secs\n",
            "Step  30800: train CrossEntropyLoss |  0.02637711\n",
            "Step  30800: eval  CrossEntropyLoss |  0.30475470\n",
            "Step  30800: eval          Accuracy |  0.95576136\n",
            "\n",
            "Step  30900: Ran 100 train steps in 4.90 secs\n",
            "Step  30900: train CrossEntropyLoss |  0.02241243\n",
            "Step  30900: eval  CrossEntropyLoss |  0.31094298\n",
            "Step  30900: eval          Accuracy |  0.95404394\n",
            "\n",
            "Step  31000: Ran 100 train steps in 4.92 secs\n",
            "Step  31000: train CrossEntropyLoss |  0.02134262\n",
            "Step  31000: eval  CrossEntropyLoss |  0.31092382\n",
            "Step  31000: eval          Accuracy |  0.95501557\n",
            "\n",
            "Step  31100: Ran 100 train steps in 4.91 secs\n",
            "Step  31100: train CrossEntropyLoss |  0.02552926\n",
            "Step  31100: eval  CrossEntropyLoss |  0.31638803\n",
            "Step  31100: eval          Accuracy |  0.95237376\n",
            "\n",
            "Step  31200: Ran 100 train steps in 4.92 secs\n",
            "Step  31200: train CrossEntropyLoss |  0.02573791\n",
            "Step  31200: eval  CrossEntropyLoss |  0.30520535\n",
            "Step  31200: eval          Accuracy |  0.95486428\n",
            "\n",
            "Step  31300: Ran 100 train steps in 4.83 secs\n",
            "Step  31300: train CrossEntropyLoss |  0.02634989\n",
            "Step  31300: eval  CrossEntropyLoss |  0.27775824\n",
            "Step  31300: eval          Accuracy |  0.95419757\n",
            "\n",
            "Step  31400: Ran 100 train steps in 4.84 secs\n",
            "Step  31400: train CrossEntropyLoss |  0.02635667\n",
            "Step  31400: eval  CrossEntropyLoss |  0.28477046\n",
            "Step  31400: eval          Accuracy |  0.95432027\n",
            "\n",
            "Step  31500: Ran 100 train steps in 4.84 secs\n",
            "Step  31500: train CrossEntropyLoss |  0.02213428\n",
            "Step  31500: eval  CrossEntropyLoss |  0.26959302\n",
            "Step  31500: eval          Accuracy |  0.95759107\n",
            "\n",
            "Step  31600: Ran 100 train steps in 4.94 secs\n",
            "Step  31600: train CrossEntropyLoss |  0.02240763\n",
            "Step  31600: eval  CrossEntropyLoss |  0.29510044\n",
            "Step  31600: eval          Accuracy |  0.95512490\n",
            "\n",
            "Step  31700: Ran 100 train steps in 4.83 secs\n",
            "Step  31700: train CrossEntropyLoss |  0.02397512\n",
            "Step  31700: eval  CrossEntropyLoss |  0.33796003\n",
            "Step  31700: eval          Accuracy |  0.95122030\n",
            "\n",
            "Step  31800: Ran 100 train steps in 4.88 secs\n",
            "Step  31800: train CrossEntropyLoss |  0.02631758\n",
            "Step  31800: eval  CrossEntropyLoss |  0.31101809\n",
            "Step  31800: eval          Accuracy |  0.95682312\n",
            "\n",
            "Step  31900: Ran 100 train steps in 4.90 secs\n",
            "Step  31900: train CrossEntropyLoss |  0.02714163\n",
            "Step  31900: eval  CrossEntropyLoss |  0.33136106\n",
            "Step  31900: eval          Accuracy |  0.95061677\n",
            "\n",
            "Step  32000: Ran 100 train steps in 4.87 secs\n",
            "Step  32000: train CrossEntropyLoss |  0.02183348\n",
            "Step  32000: eval  CrossEntropyLoss |  0.27143374\n",
            "Step  32000: eval          Accuracy |  0.95796437\n",
            "\n",
            "Step  32100: Ran 100 train steps in 4.82 secs\n",
            "Step  32100: train CrossEntropyLoss |  0.02334926\n",
            "Step  32100: eval  CrossEntropyLoss |  0.30738494\n",
            "Step  32100: eval          Accuracy |  0.95443680\n",
            "\n",
            "Step  32200: Ran 100 train steps in 4.89 secs\n",
            "Step  32200: train CrossEntropyLoss |  0.02534572\n",
            "Step  32200: eval  CrossEntropyLoss |  0.35847871\n",
            "Step  32200: eval          Accuracy |  0.94878648\n",
            "\n",
            "Step  32300: Ran 100 train steps in 4.87 secs\n",
            "Step  32300: train CrossEntropyLoss |  0.02475679\n",
            "Step  32300: eval  CrossEntropyLoss |  0.28516952\n",
            "Step  32300: eval          Accuracy |  0.95475621\n",
            "\n",
            "Step  32400: Ran 100 train steps in 4.93 secs\n",
            "Step  32400: train CrossEntropyLoss |  0.02563498\n",
            "Step  32400: eval  CrossEntropyLoss |  0.32839299\n",
            "Step  32400: eval          Accuracy |  0.95336052\n",
            "\n",
            "Step  32500: Ran 100 train steps in 4.96 secs\n",
            "Step  32500: train CrossEntropyLoss |  0.02162759\n",
            "Step  32500: eval  CrossEntropyLoss |  0.27920209\n",
            "Step  32500: eval          Accuracy |  0.95310361\n",
            "\n",
            "Step  32600: Ran 100 train steps in 4.88 secs\n",
            "Step  32600: train CrossEntropyLoss |  0.02397639\n",
            "Step  32600: eval  CrossEntropyLoss |  0.29847589\n",
            "Step  32600: eval          Accuracy |  0.95534052\n",
            "\n",
            "Step  32700: Ran 100 train steps in 4.86 secs\n",
            "Step  32700: train CrossEntropyLoss |  0.02225228\n",
            "Step  32700: eval  CrossEntropyLoss |  0.31129081\n",
            "Step  32700: eval          Accuracy |  0.95444396\n",
            "\n",
            "Step  32800: Ran 100 train steps in 4.84 secs\n",
            "Step  32800: train CrossEntropyLoss |  0.02379043\n",
            "Step  32800: eval  CrossEntropyLoss |  0.27057412\n",
            "Step  32800: eval          Accuracy |  0.95585592\n",
            "\n",
            "Step  32900: Ran 100 train steps in 4.97 secs\n",
            "Step  32900: train CrossEntropyLoss |  0.02487475\n",
            "Step  32900: eval  CrossEntropyLoss |  0.26766050\n",
            "Step  32900: eval          Accuracy |  0.95731496\n",
            "\n",
            "Step  33000: Ran 100 train steps in 4.97 secs\n",
            "Step  33000: train CrossEntropyLoss |  0.02461490\n",
            "Step  33000: eval  CrossEntropyLoss |  0.33442661\n",
            "Step  33000: eval          Accuracy |  0.95312631\n",
            "\n",
            "Step  33100: Ran 100 train steps in 4.88 secs\n",
            "Step  33100: train CrossEntropyLoss |  0.02230861\n",
            "Step  33100: eval  CrossEntropyLoss |  0.32756286\n",
            "Step  33100: eval          Accuracy |  0.95487189\n",
            "\n",
            "Step  33200: Ran 100 train steps in 4.91 secs\n",
            "Step  33200: train CrossEntropyLoss |  0.02234980\n",
            "Step  33200: eval  CrossEntropyLoss |  0.32394443\n",
            "Step  33200: eval          Accuracy |  0.95165179\n",
            "\n",
            "Step  33300: Ran 100 train steps in 4.76 secs\n",
            "Step  33300: train CrossEntropyLoss |  0.02229789\n",
            "Step  33300: eval  CrossEntropyLoss |  0.33788303\n",
            "Step  33300: eval          Accuracy |  0.95315437\n",
            "\n",
            "Step  33400: Ran 100 train steps in 4.87 secs\n",
            "Step  33400: train CrossEntropyLoss |  0.02549182\n",
            "Step  33400: eval  CrossEntropyLoss |  0.29738709\n",
            "Step  33400: eval          Accuracy |  0.95605468\n",
            "\n",
            "Step  33500: Ran 100 train steps in 4.90 secs\n",
            "Step  33500: train CrossEntropyLoss |  0.02545936\n",
            "Step  33500: eval  CrossEntropyLoss |  0.28649782\n",
            "Step  33500: eval          Accuracy |  0.95503832\n",
            "\n",
            "Step  33600: Ran 100 train steps in 4.89 secs\n",
            "Step  33600: train CrossEntropyLoss |  0.02206434\n",
            "Step  33600: eval  CrossEntropyLoss |  0.28346328\n",
            "Step  33600: eval          Accuracy |  0.95755380\n",
            "\n",
            "Step  33700: Ran 100 train steps in 4.84 secs\n",
            "Step  33700: train CrossEntropyLoss |  0.02297005\n",
            "Step  33700: eval  CrossEntropyLoss |  0.34568556\n",
            "Step  33700: eval          Accuracy |  0.95143476\n",
            "\n",
            "Step  33800: Ran 100 train steps in 4.96 secs\n",
            "Step  33800: train CrossEntropyLoss |  0.02470982\n",
            "Step  33800: eval  CrossEntropyLoss |  0.33866686\n",
            "Step  33800: eval          Accuracy |  0.95318301\n",
            "\n",
            "Step  33900: Ran 100 train steps in 4.85 secs\n",
            "Step  33900: train CrossEntropyLoss |  0.02496462\n",
            "Step  33900: eval  CrossEntropyLoss |  0.30656208\n",
            "Step  33900: eval          Accuracy |  0.95422016\n",
            "\n",
            "Step  34000: Ran 100 train steps in 4.82 secs\n",
            "Step  34000: train CrossEntropyLoss |  0.02459406\n",
            "Step  34000: eval  CrossEntropyLoss |  0.31861120\n",
            "Step  34000: eval          Accuracy |  0.95312886\n",
            "\n",
            "Step  34100: Ran 100 train steps in 4.87 secs\n",
            "Step  34100: train CrossEntropyLoss |  0.02158516\n",
            "Step  34100: eval  CrossEntropyLoss |  0.29168061\n",
            "Step  34100: eval          Accuracy |  0.95727244\n",
            "\n",
            "Step  34200: Ran 100 train steps in 4.91 secs\n",
            "Step  34200: train CrossEntropyLoss |  0.01989933\n",
            "Step  34200: eval  CrossEntropyLoss |  0.28278561\n",
            "Step  34200: eval          Accuracy |  0.95446970\n",
            "\n",
            "Step  34300: Ran 100 train steps in 4.87 secs\n",
            "Step  34300: train CrossEntropyLoss |  0.02362332\n",
            "Step  34300: eval  CrossEntropyLoss |  0.31334109\n",
            "Step  34300: eval          Accuracy |  0.95517010\n",
            "\n",
            "Step  34400: Ran 100 train steps in 4.93 secs\n",
            "Step  34400: train CrossEntropyLoss |  0.02442603\n",
            "Step  34400: eval  CrossEntropyLoss |  0.30340330\n",
            "Step  34400: eval          Accuracy |  0.95745072\n",
            "\n",
            "Step  34500: Ran 100 train steps in 4.77 secs\n",
            "Step  34500: train CrossEntropyLoss |  0.02695889\n",
            "Step  34500: eval  CrossEntropyLoss |  0.30856327\n",
            "Step  34500: eval          Accuracy |  0.94852352\n",
            "\n",
            "Step  34600: Ran 100 train steps in 4.82 secs\n",
            "Step  34600: train CrossEntropyLoss |  0.02252554\n",
            "Step  34600: eval  CrossEntropyLoss |  0.30087273\n",
            "Step  34600: eval          Accuracy |  0.95261015\n",
            "\n",
            "Step  34700: Ran 100 train steps in 4.81 secs\n",
            "Step  34700: train CrossEntropyLoss |  0.02189381\n",
            "Step  34700: eval  CrossEntropyLoss |  0.29156028\n",
            "Step  34700: eval          Accuracy |  0.95605071\n",
            "\n",
            "Step  34800: Ran 100 train steps in 4.94 secs\n",
            "Step  34800: train CrossEntropyLoss |  0.02268434\n",
            "Step  34800: eval  CrossEntropyLoss |  0.31759982\n",
            "Step  34800: eval          Accuracy |  0.95714156\n",
            "\n",
            "Step  34900: Ran 100 train steps in 4.91 secs\n",
            "Step  34900: train CrossEntropyLoss |  0.02385499\n",
            "Step  34900: eval  CrossEntropyLoss |  0.29920091\n",
            "Step  34900: eval          Accuracy |  0.95605709\n",
            "\n",
            "Step  35000: Ran 100 train steps in 4.90 secs\n",
            "Step  35000: train CrossEntropyLoss |  0.02529007\n",
            "Step  35000: eval  CrossEntropyLoss |  0.39435318\n",
            "Step  35000: eval          Accuracy |  0.94914291\n",
            "\n",
            "Step  35100: Ran 100 train steps in 4.86 secs\n",
            "Step  35100: train CrossEntropyLoss |  0.02383979\n",
            "Step  35100: eval  CrossEntropyLoss |  0.28862945\n",
            "Step  35100: eval          Accuracy |  0.95720705\n",
            "\n",
            "Step  35200: Ran 100 train steps in 4.82 secs\n",
            "Step  35200: train CrossEntropyLoss |  0.02264737\n",
            "Step  35200: eval  CrossEntropyLoss |  0.32804973\n",
            "Step  35200: eval          Accuracy |  0.95056908\n",
            "\n",
            "Step  35300: Ran 100 train steps in 4.83 secs\n",
            "Step  35300: train CrossEntropyLoss |  0.02147079\n",
            "Step  35300: eval  CrossEntropyLoss |  0.33506307\n",
            "Step  35300: eval          Accuracy |  0.95014459\n",
            "\n",
            "Step  35400: Ran 100 train steps in 4.82 secs\n",
            "Step  35400: train CrossEntropyLoss |  0.02471803\n",
            "Step  35400: eval  CrossEntropyLoss |  0.29759283\n",
            "Step  35400: eval          Accuracy |  0.95638338\n",
            "\n",
            "Step  35500: Ran 100 train steps in 4.86 secs\n",
            "Step  35500: train CrossEntropyLoss |  0.02568946\n",
            "Step  35500: eval  CrossEntropyLoss |  0.29701400\n",
            "Step  35500: eval          Accuracy |  0.95138234\n",
            "\n",
            "Step  35600: Ran 100 train steps in 4.87 secs\n",
            "Step  35600: train CrossEntropyLoss |  0.02406364\n",
            "Step  35600: eval  CrossEntropyLoss |  0.29643263\n",
            "Step  35600: eval          Accuracy |  0.95742263\n",
            "\n",
            "Step  35700: Ran 100 train steps in 4.79 secs\n",
            "Step  35700: train CrossEntropyLoss |  0.02129363\n",
            "Step  35700: eval  CrossEntropyLoss |  0.29278149\n",
            "Step  35700: eval          Accuracy |  0.95465062\n",
            "\n",
            "Step  35800: Ran 100 train steps in 4.74 secs\n",
            "Step  35800: train CrossEntropyLoss |  0.02368033\n",
            "Step  35800: eval  CrossEntropyLoss |  0.30489079\n",
            "Step  35800: eval          Accuracy |  0.95462971\n",
            "\n",
            "Step  35900: Ran 100 train steps in 4.77 secs\n",
            "Step  35900: train CrossEntropyLoss |  0.02598757\n",
            "Step  35900: eval  CrossEntropyLoss |  0.30534764\n",
            "Step  35900: eval          Accuracy |  0.95272374\n",
            "\n",
            "Step  36000: Ran 100 train steps in 4.91 secs\n",
            "Step  36000: train CrossEntropyLoss |  0.02575636\n",
            "Step  36000: eval  CrossEntropyLoss |  0.33604212\n",
            "Step  36000: eval          Accuracy |  0.95129397\n",
            "\n",
            "Step  36100: Ran 100 train steps in 4.77 secs\n",
            "Step  36100: train CrossEntropyLoss |  0.02444539\n",
            "Step  36100: eval  CrossEntropyLoss |  0.28792978\n",
            "Step  36100: eval          Accuracy |  0.95746962\n",
            "\n",
            "Step  36200: Ran 100 train steps in 4.88 secs\n",
            "Step  36200: train CrossEntropyLoss |  0.02085269\n",
            "Step  36200: eval  CrossEntropyLoss |  0.30587263\n",
            "Step  36200: eval          Accuracy |  0.95216726\n",
            "\n",
            "Step  36300: Ran 100 train steps in 4.85 secs\n",
            "Step  36300: train CrossEntropyLoss |  0.02229762\n",
            "Step  36300: eval  CrossEntropyLoss |  0.27783387\n",
            "Step  36300: eval          Accuracy |  0.95741976\n",
            "\n",
            "Step  36400: Ran 100 train steps in 4.80 secs\n",
            "Step  36400: train CrossEntropyLoss |  0.02260908\n",
            "Step  36400: eval  CrossEntropyLoss |  0.34554142\n",
            "Step  36400: eval          Accuracy |  0.95134048\n",
            "\n",
            "Step  36500: Ran 100 train steps in 4.80 secs\n",
            "Step  36500: train CrossEntropyLoss |  0.02381248\n",
            "Step  36500: eval  CrossEntropyLoss |  0.33797693\n",
            "Step  36500: eval          Accuracy |  0.95180622\n",
            "\n",
            "Step  36600: Ran 100 train steps in 4.86 secs\n",
            "Step  36600: train CrossEntropyLoss |  0.02616429\n",
            "Step  36600: eval  CrossEntropyLoss |  0.31158491\n",
            "Step  36600: eval          Accuracy |  0.95140657\n",
            "\n",
            "Step  36700: Ran 100 train steps in 4.86 secs\n",
            "Step  36700: train CrossEntropyLoss |  0.02234487\n",
            "Step  36700: eval  CrossEntropyLoss |  0.31079223\n",
            "Step  36700: eval          Accuracy |  0.95495307\n",
            "\n",
            "Step  36800: Ran 100 train steps in 4.83 secs\n",
            "Step  36800: train CrossEntropyLoss |  0.02162025\n",
            "Step  36800: eval  CrossEntropyLoss |  0.29528867\n",
            "Step  36800: eval          Accuracy |  0.95398974\n",
            "\n",
            "Step  36900: Ran 100 train steps in 4.88 secs\n",
            "Step  36900: train CrossEntropyLoss |  0.02156575\n",
            "Step  36900: eval  CrossEntropyLoss |  0.32486922\n",
            "Step  36900: eval          Accuracy |  0.95447776\n",
            "\n",
            "Step  37000: Ran 100 train steps in 4.97 secs\n",
            "Step  37000: train CrossEntropyLoss |  0.02301139\n",
            "Step  37000: eval  CrossEntropyLoss |  0.29028377\n",
            "Step  37000: eval          Accuracy |  0.95716147\n",
            "\n",
            "Step  37100: Ran 100 train steps in 4.86 secs\n",
            "Step  37100: train CrossEntropyLoss |  0.02680014\n",
            "Step  37100: eval  CrossEntropyLoss |  0.32414275\n",
            "Step  37100: eval          Accuracy |  0.95116656\n",
            "\n",
            "Step  37200: Ran 100 train steps in 4.87 secs\n",
            "Step  37200: train CrossEntropyLoss |  0.02595409\n",
            "Step  37200: eval  CrossEntropyLoss |  0.28450815\n",
            "Step  37200: eval          Accuracy |  0.95534478\n",
            "\n",
            "Step  37300: Ran 100 train steps in 4.85 secs\n",
            "Step  37300: train CrossEntropyLoss |  0.02267597\n",
            "Step  37300: eval  CrossEntropyLoss |  0.29979286\n",
            "Step  37300: eval          Accuracy |  0.95445125\n",
            "\n",
            "Step  37400: Ran 100 train steps in 4.79 secs\n",
            "Step  37400: train CrossEntropyLoss |  0.02334302\n",
            "Step  37400: eval  CrossEntropyLoss |  0.33613155\n",
            "Step  37400: eval          Accuracy |  0.94974996\n",
            "\n",
            "Step  37500: Ran 100 train steps in 4.80 secs\n",
            "Step  37500: train CrossEntropyLoss |  0.02459589\n",
            "Step  37500: eval  CrossEntropyLoss |  0.28702981\n",
            "Step  37500: eval          Accuracy |  0.95906086\n",
            "\n",
            "Step  37600: Ran 100 train steps in 4.84 secs\n",
            "Step  37600: train CrossEntropyLoss |  0.02433449\n",
            "Step  37600: eval  CrossEntropyLoss |  0.33430886\n",
            "Step  37600: eval          Accuracy |  0.95186002\n",
            "\n",
            "Step  37700: Ran 100 train steps in 4.87 secs\n",
            "Step  37700: train CrossEntropyLoss |  0.02378526\n",
            "Step  37700: eval  CrossEntropyLoss |  0.33203479\n",
            "Step  37700: eval          Accuracy |  0.95421789\n",
            "\n",
            "Step  37800: Ran 100 train steps in 4.82 secs\n",
            "Step  37800: train CrossEntropyLoss |  0.02215253\n",
            "Step  37800: eval  CrossEntropyLoss |  0.31568965\n",
            "Step  37800: eval          Accuracy |  0.95514690\n",
            "\n",
            "Step  37900: Ran 100 train steps in 4.78 secs\n",
            "Step  37900: train CrossEntropyLoss |  0.02080274\n",
            "Step  37900: eval  CrossEntropyLoss |  0.32074020\n",
            "Step  37900: eval          Accuracy |  0.95510633\n",
            "\n",
            "Step  38000: Ran 100 train steps in 4.80 secs\n",
            "Step  38000: train CrossEntropyLoss |  0.02376527\n",
            "Step  38000: eval  CrossEntropyLoss |  0.30216549\n",
            "Step  38000: eval          Accuracy |  0.95767831\n",
            "\n",
            "Step  38100: Ran 100 train steps in 4.84 secs\n",
            "Step  38100: train CrossEntropyLoss |  0.02491664\n",
            "Step  38100: eval  CrossEntropyLoss |  0.32942627\n",
            "Step  38100: eval          Accuracy |  0.95228537\n",
            "\n",
            "Step  38200: Ran 100 train steps in 4.86 secs\n",
            "Step  38200: train CrossEntropyLoss |  0.02470675\n",
            "Step  38200: eval  CrossEntropyLoss |  0.27902208\n",
            "Step  38200: eval          Accuracy |  0.95878852\n",
            "\n",
            "Step  38300: Ran 100 train steps in 4.81 secs\n",
            "Step  38300: train CrossEntropyLoss |  0.02062260\n",
            "Step  38300: eval  CrossEntropyLoss |  0.29091514\n",
            "Step  38300: eval          Accuracy |  0.95818625\n",
            "\n",
            "Step  38400: Ran 100 train steps in 4.84 secs\n",
            "Step  38400: train CrossEntropyLoss |  0.02143591\n",
            "Step  38400: eval  CrossEntropyLoss |  0.31201376\n",
            "Step  38400: eval          Accuracy |  0.95320156\n",
            "\n",
            "Step  38500: Ran 100 train steps in 4.84 secs\n",
            "Step  38500: train CrossEntropyLoss |  0.02318925\n",
            "Step  38500: eval  CrossEntropyLoss |  0.31297349\n",
            "Step  38500: eval          Accuracy |  0.95509967\n",
            "\n",
            "Step  38600: Ran 100 train steps in 4.72 secs\n",
            "Step  38600: train CrossEntropyLoss |  0.02396902\n",
            "Step  38600: eval  CrossEntropyLoss |  0.31600846\n",
            "Step  38600: eval          Accuracy |  0.95605540\n",
            "\n",
            "Step  38700: Ran 100 train steps in 4.87 secs\n",
            "Step  38700: train CrossEntropyLoss |  0.02488363\n",
            "Step  38700: eval  CrossEntropyLoss |  0.34457064\n",
            "Step  38700: eval          Accuracy |  0.95129238\n",
            "\n",
            "Step  38800: Ran 100 train steps in 4.80 secs\n",
            "Step  38800: train CrossEntropyLoss |  0.02123618\n",
            "Step  38800: eval  CrossEntropyLoss |  0.31243204\n",
            "Step  38800: eval          Accuracy |  0.95377172\n",
            "\n",
            "Step  38900: Ran 100 train steps in 4.78 secs\n",
            "Step  38900: train CrossEntropyLoss |  0.02400105\n",
            "Step  38900: eval  CrossEntropyLoss |  0.33006307\n",
            "Step  38900: eval          Accuracy |  0.95081022\n",
            "\n",
            "Step  39000: Ran 100 train steps in 4.80 secs\n",
            "Step  39000: train CrossEntropyLoss |  0.02378562\n",
            "Step  39000: eval  CrossEntropyLoss |  0.29103511\n",
            "Step  39000: eval          Accuracy |  0.95614685\n",
            "\n",
            "Step  39100: Ran 100 train steps in 4.81 secs\n",
            "Step  39100: train CrossEntropyLoss |  0.02377226\n",
            "Step  39100: eval  CrossEntropyLoss |  0.33087264\n",
            "Step  39100: eval          Accuracy |  0.95533690\n",
            "\n",
            "Step  39200: Ran 100 train steps in 4.79 secs\n",
            "Step  39200: train CrossEntropyLoss |  0.02562317\n",
            "Step  39200: eval  CrossEntropyLoss |  0.29973808\n",
            "Step  39200: eval          Accuracy |  0.95731013\n",
            "\n",
            "Step  39300: Ran 100 train steps in 4.82 secs\n",
            "Step  39300: train CrossEntropyLoss |  0.02200217\n",
            "Step  39300: eval  CrossEntropyLoss |  0.34030504\n",
            "Step  39300: eval          Accuracy |  0.95009243\n",
            "\n",
            "Step  39400: Ran 100 train steps in 4.85 secs\n",
            "Step  39400: train CrossEntropyLoss |  0.02161378\n",
            "Step  39400: eval  CrossEntropyLoss |  0.31744095\n",
            "Step  39400: eval          Accuracy |  0.95136024\n",
            "\n",
            "Step  39500: Ran 100 train steps in 4.75 secs\n",
            "Step  39500: train CrossEntropyLoss |  0.02224038\n",
            "Step  39500: eval  CrossEntropyLoss |  0.30514536\n",
            "Step  39500: eval          Accuracy |  0.95344823\n",
            "\n",
            "Step  39600: Ran 100 train steps in 4.90 secs\n",
            "Step  39600: train CrossEntropyLoss |  0.02260316\n",
            "Step  39600: eval  CrossEntropyLoss |  0.29291695\n",
            "Step  39600: eval          Accuracy |  0.95459516\n",
            "\n",
            "Step  39700: Ran 100 train steps in 4.81 secs\n",
            "Step  39700: train CrossEntropyLoss |  0.02565671\n",
            "Step  39700: eval  CrossEntropyLoss |  0.32395671\n",
            "Step  39700: eval          Accuracy |  0.95465775\n",
            "\n",
            "Step  39800: Ran 100 train steps in 4.79 secs\n",
            "Step  39800: train CrossEntropyLoss |  0.02486606\n",
            "Step  39800: eval  CrossEntropyLoss |  0.30924433\n",
            "Step  39800: eval          Accuracy |  0.95512869\n",
            "\n",
            "Step  39900: Ran 100 train steps in 4.77 secs\n",
            "Step  39900: train CrossEntropyLoss |  0.02238342\n",
            "Step  39900: eval  CrossEntropyLoss |  0.31408060\n",
            "Step  39900: eval          Accuracy |  0.95502885\n",
            "\n",
            "Step  40000: Ran 100 train steps in 4.77 secs\n",
            "Step  40000: train CrossEntropyLoss |  0.02174640\n",
            "Step  40000: eval  CrossEntropyLoss |  0.31584996\n",
            "Step  40000: eval          Accuracy |  0.95351656\n",
            "\n",
            "Step  40100: Ran 100 train steps in 4.76 secs\n",
            "Step  40100: train CrossEntropyLoss |  0.02566599\n",
            "Step  40100: eval  CrossEntropyLoss |  0.30531238\n",
            "Step  40100: eval          Accuracy |  0.95756145\n",
            "\n",
            "Step  40200: Ran 100 train steps in 4.80 secs\n",
            "Step  40200: train CrossEntropyLoss |  0.02694022\n",
            "Step  40200: eval  CrossEntropyLoss |  0.33013633\n",
            "Step  40200: eval          Accuracy |  0.95256666\n",
            "\n",
            "Step  40300: Ran 100 train steps in 4.92 secs\n",
            "Step  40300: train CrossEntropyLoss |  0.02849371\n",
            "Step  40300: eval  CrossEntropyLoss |  0.33667199\n",
            "Step  40300: eval          Accuracy |  0.95102083\n",
            "\n",
            "Step  40400: Ran 100 train steps in 4.85 secs\n",
            "Step  40400: train CrossEntropyLoss |  0.02355887\n",
            "Step  40400: eval  CrossEntropyLoss |  0.30561784\n",
            "Step  40400: eval          Accuracy |  0.95483114\n",
            "\n",
            "Step  40500: Ran 100 train steps in 4.83 secs\n",
            "Step  40500: train CrossEntropyLoss |  0.02391280\n",
            "Step  40500: eval  CrossEntropyLoss |  0.30789884\n",
            "Step  40500: eval          Accuracy |  0.95375648\n",
            "\n",
            "Step  40600: Ran 100 train steps in 4.79 secs\n",
            "Step  40600: train CrossEntropyLoss |  0.02331379\n",
            "Step  40600: eval  CrossEntropyLoss |  0.28381628\n",
            "Step  40600: eval          Accuracy |  0.95668067\n",
            "\n",
            "Step  40700: Ran 100 train steps in 4.78 secs\n",
            "Step  40700: train CrossEntropyLoss |  0.02377715\n",
            "Step  40700: eval  CrossEntropyLoss |  0.29255270\n",
            "Step  40700: eval          Accuracy |  0.95322149\n",
            "\n",
            "Step  40800: Ran 100 train steps in 4.79 secs\n",
            "Step  40800: train CrossEntropyLoss |  0.02779735\n",
            "Step  40800: eval  CrossEntropyLoss |  0.31395961\n",
            "Step  40800: eval          Accuracy |  0.95483581\n",
            "\n",
            "Step  40900: Ran 100 train steps in 4.88 secs\n",
            "Step  40900: train CrossEntropyLoss |  0.02117551\n",
            "Step  40900: eval  CrossEntropyLoss |  0.29796846\n",
            "Step  40900: eval          Accuracy |  0.95638022\n",
            "\n",
            "Step  41000: Ran 100 train steps in 4.74 secs\n",
            "Step  41000: train CrossEntropyLoss |  0.02283902\n",
            "Step  41000: eval  CrossEntropyLoss |  0.33096542\n",
            "Step  41000: eval          Accuracy |  0.95231895\n",
            "\n",
            "Step  41100: Ran 100 train steps in 4.84 secs\n",
            "Step  41100: train CrossEntropyLoss |  0.02286571\n",
            "Step  41100: eval  CrossEntropyLoss |  0.32302343\n",
            "Step  41100: eval          Accuracy |  0.95467007\n",
            "\n",
            "Step  41200: Ran 100 train steps in 4.79 secs\n",
            "Step  41200: train CrossEntropyLoss |  0.02265162\n",
            "Step  41200: eval  CrossEntropyLoss |  0.32230779\n",
            "Step  41200: eval          Accuracy |  0.95109565\n",
            "\n",
            "Step  41300: Ran 100 train steps in 4.81 secs\n",
            "Step  41300: train CrossEntropyLoss |  0.02577933\n",
            "Step  41300: eval  CrossEntropyLoss |  0.33570619\n",
            "Step  41300: eval          Accuracy |  0.95456449\n",
            "\n",
            "Step  41400: Ran 100 train steps in 4.89 secs\n",
            "Step  41400: train CrossEntropyLoss |  0.02396863\n",
            "Step  41400: eval  CrossEntropyLoss |  0.36455495\n",
            "Step  41400: eval          Accuracy |  0.94905436\n",
            "\n",
            "Step  41500: Ran 100 train steps in 4.83 secs\n",
            "Step  41500: train CrossEntropyLoss |  0.02185198\n",
            "Step  41500: eval  CrossEntropyLoss |  0.26750506\n",
            "Step  41500: eval          Accuracy |  0.95776191\n",
            "\n",
            "Step  41600: Ran 100 train steps in 4.88 secs\n",
            "Step  41600: train CrossEntropyLoss |  0.02241955\n",
            "Step  41600: eval  CrossEntropyLoss |  0.29879831\n",
            "Step  41600: eval          Accuracy |  0.95359818\n",
            "\n",
            "Step  41700: Ran 100 train steps in 4.77 secs\n",
            "Step  41700: train CrossEntropyLoss |  0.02237100\n",
            "Step  41700: eval  CrossEntropyLoss |  0.29282226\n",
            "Step  41700: eval          Accuracy |  0.95578542\n",
            "\n",
            "Step  41800: Ran 100 train steps in 4.80 secs\n",
            "Step  41800: train CrossEntropyLoss |  0.02452567\n",
            "Step  41800: eval  CrossEntropyLoss |  0.32398466\n",
            "Step  41800: eval          Accuracy |  0.95230426\n",
            "\n",
            "Step  41900: Ran 100 train steps in 4.73 secs\n",
            "Step  41900: train CrossEntropyLoss |  0.02247477\n",
            "Step  41900: eval  CrossEntropyLoss |  0.30819916\n",
            "Step  41900: eval          Accuracy |  0.95750994\n",
            "\n",
            "Step  42000: Ran 100 train steps in 4.84 secs\n",
            "Step  42000: train CrossEntropyLoss |  0.02006779\n",
            "Step  42000: eval  CrossEntropyLoss |  0.31857452\n",
            "Step  42000: eval          Accuracy |  0.95621805\n",
            "\n",
            "Step  42100: Ran 100 train steps in 4.83 secs\n",
            "Step  42100: train CrossEntropyLoss |  0.02126185\n",
            "Step  42100: eval  CrossEntropyLoss |  0.33204388\n",
            "Step  42100: eval          Accuracy |  0.95171180\n",
            "\n",
            "Step  42200: Ran 100 train steps in 4.73 secs\n",
            "Step  42200: train CrossEntropyLoss |  0.02236464\n",
            "Step  42200: eval  CrossEntropyLoss |  0.29601407\n",
            "Step  42200: eval          Accuracy |  0.95328377\n",
            "\n",
            "Step  42300: Ran 100 train steps in 4.76 secs\n",
            "Step  42300: train CrossEntropyLoss |  0.02455366\n",
            "Step  42300: eval  CrossEntropyLoss |  0.32864321\n",
            "Step  42300: eval          Accuracy |  0.95381420\n",
            "\n",
            "Step  42400: Ran 100 train steps in 4.82 secs\n",
            "Step  42400: train CrossEntropyLoss |  0.02379042\n",
            "Step  42400: eval  CrossEntropyLoss |  0.35419187\n",
            "Step  42400: eval          Accuracy |  0.95184145\n",
            "\n",
            "Step  42500: Ran 100 train steps in 4.78 secs\n",
            "Step  42500: train CrossEntropyLoss |  0.01979630\n",
            "Step  42500: eval  CrossEntropyLoss |  0.33470637\n",
            "Step  42500: eval          Accuracy |  0.95063610\n",
            "\n",
            "Step  42600: Ran 100 train steps in 4.82 secs\n",
            "Step  42600: train CrossEntropyLoss |  0.02138833\n",
            "Step  42600: eval  CrossEntropyLoss |  0.32456400\n",
            "Step  42600: eval          Accuracy |  0.95366594\n",
            "\n",
            "Step  42700: Ran 100 train steps in 4.73 secs\n",
            "Step  42700: train CrossEntropyLoss |  0.02400006\n",
            "Step  42700: eval  CrossEntropyLoss |  0.33182321\n",
            "Step  42700: eval          Accuracy |  0.95166380\n",
            "\n",
            "Step  42800: Ran 100 train steps in 4.78 secs\n",
            "Step  42800: train CrossEntropyLoss |  0.02508339\n",
            "Step  42800: eval  CrossEntropyLoss |  0.28634082\n",
            "Step  42800: eval          Accuracy |  0.95833606\n",
            "\n",
            "Step  42900: Ran 100 train steps in 4.79 secs\n",
            "Step  42900: train CrossEntropyLoss |  0.02546535\n",
            "Step  42900: eval  CrossEntropyLoss |  0.32901819\n",
            "Step  42900: eval          Accuracy |  0.95307277\n",
            "\n",
            "Step  43000: Ran 100 train steps in 4.91 secs\n",
            "Step  43000: train CrossEntropyLoss |  0.02113376\n",
            "Step  43000: eval  CrossEntropyLoss |  0.32489940\n",
            "Step  43000: eval          Accuracy |  0.95209873\n",
            "\n",
            "Step  43100: Ran 100 train steps in 4.80 secs\n",
            "Step  43100: train CrossEntropyLoss |  0.02273155\n",
            "Step  43100: eval  CrossEntropyLoss |  0.32027346\n",
            "Step  43100: eval          Accuracy |  0.95339440\n",
            "\n",
            "Step  43200: Ran 100 train steps in 4.81 secs\n",
            "Step  43200: train CrossEntropyLoss |  0.02234179\n",
            "Step  43200: eval  CrossEntropyLoss |  0.29959246\n",
            "Step  43200: eval          Accuracy |  0.95756623\n",
            "\n",
            "Step  43300: Ran 100 train steps in 4.76 secs\n",
            "Step  43300: train CrossEntropyLoss |  0.02334426\n",
            "Step  43300: eval  CrossEntropyLoss |  0.33630007\n",
            "Step  43300: eval          Accuracy |  0.95395063\n",
            "\n",
            "Step  43400: Ran 100 train steps in 4.71 secs\n",
            "Step  43400: train CrossEntropyLoss |  0.02470238\n",
            "Step  43400: eval  CrossEntropyLoss |  0.32460222\n",
            "Step  43400: eval          Accuracy |  0.95312706\n",
            "\n",
            "Step  43500: Ran 100 train steps in 4.82 secs\n",
            "Step  43500: train CrossEntropyLoss |  0.02305941\n",
            "Step  43500: eval  CrossEntropyLoss |  0.30586907\n",
            "Step  43500: eval          Accuracy |  0.95518109\n",
            "\n",
            "Step  43600: Ran 100 train steps in 4.78 secs\n",
            "Step  43600: train CrossEntropyLoss |  0.02175394\n",
            "Step  43600: eval  CrossEntropyLoss |  0.32552175\n",
            "Step  43600: eval          Accuracy |  0.95162830\n",
            "\n",
            "Step  43700: Ran 100 train steps in 4.80 secs\n",
            "Step  43700: train CrossEntropyLoss |  0.02203300\n",
            "Step  43700: eval  CrossEntropyLoss |  0.32798027\n",
            "Step  43700: eval          Accuracy |  0.95522102\n",
            "\n",
            "Step  43800: Ran 100 train steps in 4.84 secs\n",
            "Step  43800: train CrossEntropyLoss |  0.02403297\n",
            "Step  43800: eval  CrossEntropyLoss |  0.34407022\n",
            "Step  43800: eval          Accuracy |  0.95357252\n",
            "\n",
            "Step  43900: Ran 100 train steps in 4.80 secs\n",
            "Step  43900: train CrossEntropyLoss |  0.02323389\n",
            "Step  43900: eval  CrossEntropyLoss |  0.31691271\n",
            "Step  43900: eval          Accuracy |  0.95285877\n",
            "\n",
            "Step  44000: Ran 100 train steps in 4.90 secs\n",
            "Step  44000: train CrossEntropyLoss |  0.02401005\n",
            "Step  44000: eval  CrossEntropyLoss |  0.35078281\n",
            "Step  44000: eval          Accuracy |  0.95113403\n",
            "\n",
            "Step  44100: Ran 100 train steps in 4.83 secs\n",
            "Step  44100: train CrossEntropyLoss |  0.02144568\n",
            "Step  44100: eval  CrossEntropyLoss |  0.31408054\n",
            "Step  44100: eval          Accuracy |  0.95422082\n",
            "\n",
            "Step  44200: Ran 100 train steps in 4.91 secs\n",
            "Step  44200: train CrossEntropyLoss |  0.02274482\n",
            "Step  44200: eval  CrossEntropyLoss |  0.27387410\n",
            "Step  44200: eval          Accuracy |  0.95984135\n",
            "\n",
            "Step  44300: Ran 100 train steps in 4.86 secs\n",
            "Step  44300: train CrossEntropyLoss |  0.02368279\n",
            "Step  44300: eval  CrossEntropyLoss |  0.29279553\n",
            "Step  44300: eval          Accuracy |  0.95673786\n",
            "\n",
            "Step  44400: Ran 100 train steps in 4.79 secs\n",
            "Step  44400: train CrossEntropyLoss |  0.02343678\n",
            "Step  44400: eval  CrossEntropyLoss |  0.29114956\n",
            "Step  44400: eval          Accuracy |  0.95441985\n",
            "\n",
            "Step  44500: Ran 100 train steps in 4.79 secs\n",
            "Step  44500: train CrossEntropyLoss |  0.02481917\n",
            "Step  44500: eval  CrossEntropyLoss |  0.30458817\n",
            "Step  44500: eval          Accuracy |  0.95511845\n",
            "\n",
            "Step  44600: Ran 100 train steps in 4.79 secs\n",
            "Step  44600: train CrossEntropyLoss |  0.02205925\n",
            "Step  44600: eval  CrossEntropyLoss |  0.35906260\n",
            "Step  44600: eval          Accuracy |  0.95170931\n",
            "\n",
            "Step  44700: Ran 100 train steps in 4.81 secs\n",
            "Step  44700: train CrossEntropyLoss |  0.02271269\n",
            "Step  44700: eval  CrossEntropyLoss |  0.30694801\n",
            "Step  44700: eval          Accuracy |  0.95663843\n",
            "\n",
            "Step  44800: Ran 100 train steps in 4.78 secs\n",
            "Step  44800: train CrossEntropyLoss |  0.02386459\n",
            "Step  44800: eval  CrossEntropyLoss |  0.33649321\n",
            "Step  44800: eval          Accuracy |  0.95202413\n",
            "\n",
            "Step  44900: Ran 100 train steps in 4.76 secs\n",
            "Step  44900: train CrossEntropyLoss |  0.02424294\n",
            "Step  44900: eval  CrossEntropyLoss |  0.32114520\n",
            "Step  44900: eval          Accuracy |  0.95573435\n",
            "\n",
            "Step  45000: Ran 100 train steps in 4.81 secs\n",
            "Step  45000: train CrossEntropyLoss |  0.02713857\n",
            "Step  45000: eval  CrossEntropyLoss |  0.33136607\n",
            "Step  45000: eval          Accuracy |  0.95290723\n",
            "\n",
            "Step  45100: Ran 100 train steps in 4.86 secs\n",
            "Step  45100: train CrossEntropyLoss |  0.02394522\n",
            "Step  45100: eval  CrossEntropyLoss |  0.30950609\n",
            "Step  45100: eval          Accuracy |  0.95598840\n",
            "\n",
            "Step  45200: Ran 100 train steps in 4.75 secs\n",
            "Step  45200: train CrossEntropyLoss |  0.02397113\n",
            "Step  45200: eval  CrossEntropyLoss |  0.33704749\n",
            "Step  45200: eval          Accuracy |  0.94955642\n",
            "\n",
            "Step  45300: Ran 100 train steps in 4.79 secs\n",
            "Step  45300: train CrossEntropyLoss |  0.02436822\n",
            "Step  45300: eval  CrossEntropyLoss |  0.32058765\n",
            "Step  45300: eval          Accuracy |  0.95459006\n",
            "\n",
            "Step  45400: Ran 100 train steps in 4.81 secs\n",
            "Step  45400: train CrossEntropyLoss |  0.02645928\n",
            "Step  45400: eval  CrossEntropyLoss |  0.32359844\n",
            "Step  45400: eval          Accuracy |  0.95400745\n",
            "\n",
            "Step  45500: Ran 100 train steps in 4.72 secs\n",
            "Step  45500: train CrossEntropyLoss |  0.02723171\n",
            "Step  45500: eval  CrossEntropyLoss |  0.29834040\n",
            "Step  45500: eval          Accuracy |  0.95312246\n",
            "\n",
            "Step  45600: Ran 100 train steps in 4.82 secs\n",
            "Step  45600: train CrossEntropyLoss |  0.02461327\n",
            "Step  45600: eval  CrossEntropyLoss |  0.30121413\n",
            "Step  45600: eval          Accuracy |  0.95611419\n",
            "\n",
            "Step  45700: Ran 100 train steps in 4.87 secs\n",
            "Step  45700: train CrossEntropyLoss |  0.02415084\n",
            "Step  45700: eval  CrossEntropyLoss |  0.32117429\n",
            "Step  45700: eval          Accuracy |  0.95297536\n",
            "\n",
            "Step  45800: Ran 100 train steps in 4.77 secs\n",
            "Step  45800: train CrossEntropyLoss |  0.02386229\n",
            "Step  45800: eval  CrossEntropyLoss |  0.32782841\n",
            "Step  45800: eval          Accuracy |  0.95463963\n",
            "\n",
            "Step  45900: Ran 100 train steps in 4.81 secs\n",
            "Step  45900: train CrossEntropyLoss |  0.02618451\n",
            "Step  45900: eval  CrossEntropyLoss |  0.32608668\n",
            "Step  45900: eval          Accuracy |  0.95170141\n",
            "\n",
            "Step  46000: Ran 100 train steps in 4.73 secs\n",
            "Step  46000: train CrossEntropyLoss |  0.02668609\n",
            "Step  46000: eval  CrossEntropyLoss |  0.35708070\n",
            "Step  46000: eval          Accuracy |  0.95171536\n",
            "\n",
            "Step  46100: Ran 100 train steps in 4.83 secs\n",
            "Step  46100: train CrossEntropyLoss |  0.02391982\n",
            "Step  46100: eval  CrossEntropyLoss |  0.31574639\n",
            "Step  46100: eval          Accuracy |  0.95167266\n",
            "\n",
            "Step  46200: Ran 100 train steps in 4.70 secs\n",
            "Step  46200: train CrossEntropyLoss |  0.02334027\n",
            "Step  46200: eval  CrossEntropyLoss |  0.28068643\n",
            "Step  46200: eval          Accuracy |  0.95780401\n",
            "\n",
            "Step  46300: Ran 100 train steps in 4.95 secs\n",
            "Step  46300: train CrossEntropyLoss |  0.02292929\n",
            "Step  46300: eval  CrossEntropyLoss |  0.31894982\n",
            "Step  46300: eval          Accuracy |  0.95299163\n",
            "\n",
            "Step  46400: Ran 100 train steps in 4.83 secs\n",
            "Step  46400: train CrossEntropyLoss |  0.02358442\n",
            "Step  46400: eval  CrossEntropyLoss |  0.26522585\n",
            "Step  46400: eval          Accuracy |  0.96078427\n",
            "\n",
            "Step  46500: Ran 100 train steps in 4.71 secs\n",
            "Step  46500: train CrossEntropyLoss |  0.02505678\n",
            "Step  46500: eval  CrossEntropyLoss |  0.31588171\n",
            "Step  46500: eval          Accuracy |  0.95658133\n",
            "\n",
            "Step  46600: Ran 100 train steps in 4.84 secs\n",
            "Step  46600: train CrossEntropyLoss |  0.02325029\n",
            "Step  46600: eval  CrossEntropyLoss |  0.30902753\n",
            "Step  46600: eval          Accuracy |  0.95392266\n",
            "\n",
            "Step  46700: Ran 100 train steps in 4.72 secs\n",
            "Step  46700: train CrossEntropyLoss |  0.02044716\n",
            "Step  46700: eval  CrossEntropyLoss |  0.33059975\n",
            "Step  46700: eval          Accuracy |  0.95014874\n",
            "\n",
            "Step  46800: Ran 100 train steps in 4.67 secs\n",
            "Step  46800: train CrossEntropyLoss |  0.02174417\n",
            "Step  46800: eval  CrossEntropyLoss |  0.31523443\n",
            "Step  46800: eval          Accuracy |  0.95534188\n",
            "\n",
            "Step  46900: Ran 100 train steps in 4.76 secs\n",
            "Step  46900: train CrossEntropyLoss |  0.02202645\n",
            "Step  46900: eval  CrossEntropyLoss |  0.32690436\n",
            "Step  46900: eval          Accuracy |  0.95170096\n",
            "\n",
            "Step  47000: Ran 100 train steps in 4.87 secs\n",
            "Step  47000: train CrossEntropyLoss |  0.02235689\n",
            "Step  47000: eval  CrossEntropyLoss |  0.32291076\n",
            "Step  47000: eval          Accuracy |  0.95357091\n",
            "\n",
            "Step  47100: Ran 100 train steps in 4.80 secs\n",
            "Step  47100: train CrossEntropyLoss |  0.02524931\n",
            "Step  47100: eval  CrossEntropyLoss |  0.27689823\n",
            "Step  47100: eval          Accuracy |  0.96052683\n",
            "\n",
            "Step  47200: Ran 100 train steps in 4.73 secs\n",
            "Step  47200: train CrossEntropyLoss |  0.02158601\n",
            "Step  47200: eval  CrossEntropyLoss |  0.33226111\n",
            "Step  47200: eval          Accuracy |  0.95115113\n",
            "\n",
            "Step  47300: Ran 100 train steps in 4.82 secs\n",
            "Step  47300: train CrossEntropyLoss |  0.02295418\n",
            "Step  47300: eval  CrossEntropyLoss |  0.28581564\n",
            "Step  47300: eval          Accuracy |  0.95759283\n",
            "\n",
            "Step  47400: Ran 100 train steps in 4.75 secs\n",
            "Step  47400: train CrossEntropyLoss |  0.02221289\n",
            "Step  47400: eval  CrossEntropyLoss |  0.33049880\n",
            "Step  47400: eval          Accuracy |  0.95362537\n",
            "\n",
            "Step  47500: Ran 100 train steps in 4.80 secs\n",
            "Step  47500: train CrossEntropyLoss |  0.02423491\n",
            "Step  47500: eval  CrossEntropyLoss |  0.30649429\n",
            "Step  47500: eval          Accuracy |  0.95446263\n",
            "\n",
            "Step  47600: Ran 100 train steps in 7.39 secs\n",
            "Step  47600: train CrossEntropyLoss |  0.02646042\n",
            "Step  47600: eval  CrossEntropyLoss |  0.34359519\n",
            "Step  47600: eval          Accuracy |  0.95303783\n",
            "\n",
            "Step  47700: Ran 100 train steps in 4.83 secs\n",
            "Step  47700: train CrossEntropyLoss |  0.02409866\n",
            "Step  47700: eval  CrossEntropyLoss |  0.33993691\n",
            "Step  47700: eval          Accuracy |  0.94971755\n",
            "\n",
            "Step  47800: Ran 100 train steps in 4.74 secs\n",
            "Step  47800: train CrossEntropyLoss |  0.02354187\n",
            "Step  47800: eval  CrossEntropyLoss |  0.32494426\n",
            "Step  47800: eval          Accuracy |  0.95179476\n",
            "\n",
            "Step  47900: Ran 100 train steps in 4.79 secs\n",
            "Step  47900: train CrossEntropyLoss |  0.02367549\n",
            "Step  47900: eval  CrossEntropyLoss |  0.32468509\n",
            "Step  47900: eval          Accuracy |  0.95778870\n",
            "\n",
            "Step  48000: Ran 100 train steps in 4.71 secs\n",
            "Step  48000: train CrossEntropyLoss |  0.02506223\n",
            "Step  48000: eval  CrossEntropyLoss |  0.33110660\n",
            "Step  48000: eval          Accuracy |  0.95473849\n",
            "\n",
            "Step  48100: Ran 100 train steps in 4.76 secs\n",
            "Step  48100: train CrossEntropyLoss |  0.02453559\n",
            "Step  48100: eval  CrossEntropyLoss |  0.30261174\n",
            "Step  48100: eval          Accuracy |  0.95550221\n",
            "\n",
            "Step  48200: Ran 100 train steps in 4.76 secs\n",
            "Step  48200: train CrossEntropyLoss |  0.02285775\n",
            "Step  48200: eval  CrossEntropyLoss |  0.33170260\n",
            "Step  48200: eval          Accuracy |  0.95155352\n",
            "\n",
            "Step  48300: Ran 100 train steps in 4.78 secs\n",
            "Step  48300: train CrossEntropyLoss |  0.02164959\n",
            "Step  48300: eval  CrossEntropyLoss |  0.30107338\n",
            "Step  48300: eval          Accuracy |  0.95775533\n",
            "\n",
            "Step  48400: Ran 100 train steps in 4.72 secs\n",
            "Step  48400: train CrossEntropyLoss |  0.02248817\n",
            "Step  48400: eval  CrossEntropyLoss |  0.31886662\n",
            "Step  48400: eval          Accuracy |  0.95429946\n",
            "\n",
            "Step  48500: Ran 100 train steps in 4.71 secs\n",
            "Step  48500: train CrossEntropyLoss |  0.02331505\n",
            "Step  48500: eval  CrossEntropyLoss |  0.26917051\n",
            "Step  48500: eval          Accuracy |  0.95762990\n",
            "\n",
            "Step  48600: Ran 100 train steps in 4.73 secs\n",
            "Step  48600: train CrossEntropyLoss |  0.02366784\n",
            "Step  48600: eval  CrossEntropyLoss |  0.30311354\n",
            "Step  48600: eval          Accuracy |  0.95382424\n",
            "\n",
            "Step  48700: Ran 100 train steps in 4.77 secs\n",
            "Step  48700: train CrossEntropyLoss |  0.02425627\n",
            "Step  48700: eval  CrossEntropyLoss |  0.40426571\n",
            "Step  48700: eval          Accuracy |  0.95062542\n",
            "\n",
            "Step  48800: Ran 100 train steps in 4.72 secs\n",
            "Step  48800: train CrossEntropyLoss |  0.02059319\n",
            "Step  48800: eval  CrossEntropyLoss |  0.28499344\n",
            "Step  48800: eval          Accuracy |  0.95570434\n",
            "\n",
            "Step  48900: Ran 100 train steps in 4.73 secs\n",
            "Step  48900: train CrossEntropyLoss |  0.02261814\n",
            "Step  48900: eval  CrossEntropyLoss |  0.34936188\n",
            "Step  48900: eval          Accuracy |  0.95066275\n",
            "\n",
            "Step  49000: Ran 100 train steps in 4.86 secs\n",
            "Step  49000: train CrossEntropyLoss |  0.02474718\n",
            "Step  49000: eval  CrossEntropyLoss |  0.32001537\n",
            "Step  49000: eval          Accuracy |  0.95473956\n",
            "\n",
            "Step  49100: Ran 100 train steps in 4.82 secs\n",
            "Step  49100: train CrossEntropyLoss |  0.02613361\n",
            "Step  49100: eval  CrossEntropyLoss |  0.29947941\n",
            "Step  49100: eval          Accuracy |  0.95771418\n",
            "\n",
            "Step  49200: Ran 100 train steps in 4.71 secs\n",
            "Step  49200: train CrossEntropyLoss |  0.02575430\n",
            "Step  49200: eval  CrossEntropyLoss |  0.37808399\n",
            "Step  49200: eval          Accuracy |  0.95099791\n",
            "\n",
            "Step  49300: Ran 100 train steps in 4.81 secs\n",
            "Step  49300: train CrossEntropyLoss |  0.02221994\n",
            "Step  49300: eval  CrossEntropyLoss |  0.29778035\n",
            "Step  49300: eval          Accuracy |  0.95425695\n",
            "\n",
            "Step  49400: Ran 100 train steps in 4.81 secs\n",
            "Step  49400: train CrossEntropyLoss |  0.02234296\n",
            "Step  49400: eval  CrossEntropyLoss |  0.31557126\n",
            "Step  49400: eval          Accuracy |  0.95715570\n",
            "\n",
            "Step  49500: Ran 100 train steps in 4.75 secs\n",
            "Step  49500: train CrossEntropyLoss |  0.02351606\n",
            "Step  49500: eval  CrossEntropyLoss |  0.31171121\n",
            "Step  49500: eval          Accuracy |  0.95456663\n",
            "\n",
            "Step  49600: Ran 100 train steps in 4.80 secs\n",
            "Step  49600: train CrossEntropyLoss |  0.02489339\n",
            "Step  49600: eval  CrossEntropyLoss |  0.29107900\n",
            "Step  49600: eval          Accuracy |  0.95514269\n",
            "\n",
            "Step  49700: Ran 100 train steps in 4.80 secs\n",
            "Step  49700: train CrossEntropyLoss |  0.02392825\n",
            "Step  49700: eval  CrossEntropyLoss |  0.31625370\n",
            "Step  49700: eval          Accuracy |  0.95358273\n",
            "\n",
            "Step  49800: Ran 100 train steps in 4.80 secs\n",
            "Step  49800: train CrossEntropyLoss |  0.02270088\n",
            "Step  49800: eval  CrossEntropyLoss |  0.28709522\n",
            "Step  49800: eval          Accuracy |  0.95539700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-ba4258dc50f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtraining_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNER\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-dc146fa2eef1>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(NER, train_generator, eval_generator, train_steps, output_dir)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Train with train_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mtraining_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;31m### END CODE HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/trax/supervised/training.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, n_steps)\u001b[0m\n\u001b[1;32m    446\u001b[0m         optimizer_metrics, loss = fastmath.nested_map(\n\u001b[1;32m    447\u001b[0m             \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_or_pmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_devices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m             (optimizer_metrics, loss))\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0mloss_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/trax/fastmath/numpy.py\u001b[0m in \u001b[0;36mnested_map\u001b[0;34m(f, obj, level, ignore_nones)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnested_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnested_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnested_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/trax/fastmath/numpy.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnested_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnested_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnested_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/trax/fastmath/numpy.py\u001b[0m in \u001b[0;36mnested_map\u001b[0;34m(f, obj, level, ignore_nones)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnested_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnested_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m   \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Non-exhaustive pattern match for {}.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/trax/fastmath/numpy.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnested_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnested_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m   \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Non-exhaustive pattern match for {}.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/trax/fastmath/numpy.py\u001b[0m in \u001b[0;36mnested_map\u001b[0;34m(f, obj, level, ignore_nones)\u001b[0m\n\u001b[1;32m    101\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_is_namedtuple_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/trax/layers/acceleration.py\u001b[0m in \u001b[0;36mmean_or_pmean\u001b[0;34m(n_devices, x, axis)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   2118\u001b[0m   return lax.div(\n\u001b[1;32m   2119\u001b[0m       \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2120\u001b[0;31m       lax.convert_element_type(normalizer, dtype))\n\u001b[0m\u001b[1;32m   2121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2122\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_wraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36mdiv\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m   \u001b[0;34mr\"\"\"Elementwise division: :math:`x \\over y`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mdiv_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    262\u001b[0m         args, used_axis_names(self, params) if self._dispatch_on_params else None)\n\u001b[1;32m    263\u001b[0m     \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfull_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m    230\u001b[0m   \u001b[0;34m\"\"\"Impl rule that compiles and runs a single primitive 'prim' using XLA.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m   \u001b[0mcompiled_fun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxla_primitive_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0munsafe_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_execute_compiled_primitive\u001b[0;34m(prim, compiled, result_handler, *args)\u001b[0m\n\u001b[1;32m    348\u001b[0m   \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m   \u001b[0minput_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_put\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m   \u001b[0mout_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m   \u001b[0mcheck_special\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdUSejIHz436",
        "outputId": "701ec02d-764d-46a6-ff0d-059197407f63"
      },
      "source": [
        "# loading in a pretrained model..\n",
        "model = NER()\n",
        "model.init(trax.shapes.ShapeDtype((1, 1), dtype=np.int32))\n",
        "\n",
        "# Load the pretrained model\n",
        "model.init_from_file('/content/Natural-Language-Processing-Specialization/Natural Language Processing with Sequence Models/Week 3/model/model.pkl.gz', weights_only=True)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([[ 1.0421942 ,  0.23108415, -0.8639535 , ...,  0.12556379,\n",
              "           0.39779294,  0.3115868 ],\n",
              "         [ 0.11315823,  0.5856418 , -0.97187334, ..., -0.09545343,\n",
              "           0.32049927,  0.34755337],\n",
              "         [-1.6308768 , -0.8101889 ,  0.10782199, ..., -0.34588295,\n",
              "          -1.8545029 ,  2.2799802 ],\n",
              "         ...,\n",
              "         [-0.00398068, -0.01248364,  0.04153399, ..., -0.03655881,\n",
              "          -0.07476389,  0.06088355],\n",
              "         [ 0.13364644, -0.13159604,  0.02008977, ..., -0.03047894,\n",
              "           0.00545447,  0.04795966],\n",
              "         [-0.097247  ,  0.06230451, -0.05663563, ..., -0.0547527 ,\n",
              "          -0.01526602, -0.07698585]], dtype=float32),\n",
              "  (((), ((), ())),\n",
              "   ((array([[ 2.5256238 , -1.3724122 , -1.2901902 , ..., -1.6379418 ,\n",
              "             -1.33204   ,  0.8269191 ],\n",
              "            [ 0.5185619 , -1.2585772 , -2.6837897 , ..., -0.69898003,\n",
              "              0.07718208, -0.70147556],\n",
              "            [-1.3750705 , -0.8769574 ,  0.13453577, ...,  2.5489178 ,\n",
              "              1.3559709 ,  0.7678049 ],\n",
              "            ...,\n",
              "            [-0.25015506, -0.3672319 ,  0.11629272, ...,  0.40723804,\n",
              "              0.671567  , -1.0335848 ],\n",
              "            [-1.6398185 ,  0.6857317 ,  0.91394   , ...,  1.2478738 ,\n",
              "             -4.4294806 ,  3.1173675 ],\n",
              "            [ 0.9066772 , -0.99297535, -1.0361432 , ..., -0.46043292,\n",
              "              2.418475  , -0.4208772 ]], dtype=float32),\n",
              "     array([ 0.29221123,  1.9898055 ,  4.2672334 ,  3.1120288 ,  0.6136745 ,\n",
              "             3.4426239 ,  2.2744956 , -0.27337536,  2.0695598 ,  1.6947597 ,\n",
              "             0.98089784, -1.52824   ,  1.7181023 ,  1.6364359 ,  3.604914  ,\n",
              "             0.9291487 ,  1.7148019 , -0.4381548 ,  0.89888334,  2.8458276 ,\n",
              "             2.6732686 ,  2.9056728 ,  0.71833146,  2.3596194 ,  1.8357121 ,\n",
              "             2.4884677 ,  1.6150137 ,  3.1669822 ,  2.0191212 ,  0.6692251 ,\n",
              "             7.652854  ,  2.5338628 , -0.45271003,  3.2814462 ,  1.0999347 ,\n",
              "             1.0237782 ,  1.3752425 ,  0.68782765,  4.836137  ,  4.205761  ,\n",
              "             0.7867481 ,  3.786739  ,  2.788431  ,  1.9860134 ,  1.7532164 ,\n",
              "             0.17618746,  0.938963  ,  3.2356768 ,  2.6359646 ,  0.5566801 ,\n",
              "             0.03649765,  1.5441754 ,  5.0122027 ,  6.308699  ,  0.71054685,\n",
              "             3.9310436 ,  0.9956344 ,  0.22905785,  5.4230914 ,  1.0033361 ,\n",
              "             2.2355402 ,  0.9600592 ,  0.6451409 ,  4.288326  ,  5.0346994 ,\n",
              "             0.47529373,  5.4482307 ,  0.97039163,  4.431715  ,  0.36984125,\n",
              "             1.8796021 ,  4.664031  ,  1.3230911 ,  0.47422785, -0.08787148,\n",
              "             2.2096748 ,  2.6628742 ,  4.614614  ,  2.5503736 ,  3.8075144 ,\n",
              "             6.9373775 ,  0.9805066 ,  3.8626223 ,  5.81311   ,  2.1752174 ,\n",
              "            -1.610277  ,  2.594221  ,  5.318656  ,  4.086823  ,  6.4905686 ,\n",
              "             3.9063692 ,  6.375019  ,  0.9243182 ,  2.2789087 ,  2.2201438 ,\n",
              "             1.2844473 ,  3.4423678 ,  2.0147626 ,  1.5864012 ,  1.2003324 ,\n",
              "             1.3716984 , -0.12379569,  3.1397936 ,  1.982702  ,  0.7964436 ,\n",
              "             1.5764148 ,  1.1589991 ,  1.1360793 ,  0.8070594 , -0.14800513,\n",
              "             1.1536531 ,  0.18413869,  0.26619172,  1.6787918 ,  0.69045866,\n",
              "             1.1933594 ,  2.4664457 ,  0.20956314,  1.7948958 , -0.07080203,\n",
              "             0.46019354,  2.1919754 ,  1.2761915 ,  1.6955624 ,  1.754852  ,\n",
              "             0.97621346,  1.938051  ,  1.1299666 ,  2.3757885 ,  0.5330289 ,\n",
              "             0.24672979,  0.85247   ,  2.2467215 ,  2.3105695 ,  1.3533762 ,\n",
              "             1.0576066 ,  3.4536347 ,  0.52166826,  1.3946338 ,  0.2688011 ,\n",
              "             0.3938704 ,  2.7959278 ,  0.62686265,  0.54163337,  0.18590258,\n",
              "             1.37212   ,  2.8245745 ,  2.3775558 ,  2.1018126 , -1.100012  ,\n",
              "             0.9324861 ,  1.6999077 ,  0.28125432,  2.25398   ,  0.24254972,\n",
              "             1.1411687 ,  1.3397497 ,  1.0040187 ,  1.8067086 ,  2.3423266 ,\n",
              "             0.7314708 ,  1.1190692 ,  2.257888  ,  0.07298587,  1.5867544 ,\n",
              "            -0.17929849,  0.13249339, -0.12932527,  1.1074818 ,  1.4332622 ,\n",
              "             0.4269993 ,  3.227354  ,  0.03066809,  0.50903434,  1.9595022 ,\n",
              "             1.4196541 ,  0.61561453,  1.3283668 ,  0.5887807 ,  0.50164115,\n",
              "             0.2533167 ,  1.8726714 , -0.06221749,  4.79958   ,  0.09593471,\n",
              "             2.8466535 ,  1.018477  ,  0.65352875,  3.236874  ,  0.9368096 ,\n",
              "             2.179035  ,  4.2141695 ,  0.68365   , -0.14945751,  1.625686  ,\n",
              "             1.3374382 ,  1.4502555 ,  0.13968135,  0.8415586 ,  1.4540844 ],\n",
              "           dtype=float32)),),\n",
              "   ()),\n",
              "  (array([[-1.07798088e+00,  1.13166463e+00,  1.61768186e+00,\n",
              "            8.35827589e-01, -1.19040370e+00,  1.89705178e-01,\n",
              "           -4.06162411e-01,  3.08610678e-01, -1.27506363e+00,\n",
              "           -4.77515906e-01,  4.41974886e-02,  3.81166846e-01,\n",
              "            1.78740788e+00, -2.89647150e+00, -1.06116498e+00,\n",
              "           -1.64101326e+00, -2.26180959e+00],\n",
              "          [ 1.81575298e-01, -1.71533376e-01,  1.76496327e+00,\n",
              "           -1.21462321e+00,  2.39861906e-01,  1.67212927e+00,\n",
              "            1.22930980e+00, -2.89833713e+00, -1.07229225e-01,\n",
              "            9.33424056e-01, -1.54171860e+00,  1.57288361e+00,\n",
              "           -2.73745632e+00, -2.20117807e+00, -1.08585596e+00,\n",
              "           -2.60766625e-01, -2.19020033e+00],\n",
              "          [ 2.92437291e+00, -1.45907927e+00, -4.10340071e+00,\n",
              "           -6.02153838e-01, -2.85894656e+00, -1.65649402e+00,\n",
              "           -1.75675499e+00,  1.77746922e-01, -3.88892269e+00,\n",
              "           -3.26793098e+00, -2.59038240e-01, -2.74601936e+00,\n",
              "            1.08497798e-01, -1.94241130e+00, -7.69777393e+00,\n",
              "           -3.19701099e+00, -2.04969668e+00],\n",
              "          [ 8.93102407e-01, -4.48286444e-01,  7.50713050e-01,\n",
              "            1.19117975e+00, -3.05172110e+00,  7.31946409e-01,\n",
              "           -1.02754033e+00, -3.00118756e+00, -4.32414389e+00,\n",
              "           -3.87537289e+00,  8.37466419e-01, -4.75848377e-01,\n",
              "           -1.92889106e+00,  1.21490367e-01, -1.80606633e-01,\n",
              "           -8.79007339e-01, -3.48211718e+00],\n",
              "          [ 4.23587024e-01,  1.41306818e+00, -8.91425848e-01,\n",
              "           -7.06765175e-01, -1.75226808e+00,  8.34031999e-01,\n",
              "           -2.38195166e-01,  3.38021725e-01, -1.65646315e+00,\n",
              "           -1.53500870e-01,  1.12973368e+00,  3.06867599e-01,\n",
              "           -1.36467767e+00, -1.52627373e+00, -5.65100908e-01,\n",
              "            5.71028590e-01,  7.61085823e-02],\n",
              "          [ 8.61705542e-01,  1.81834340e+00, -6.85484290e-01,\n",
              "           -9.68898296e-01, -1.45029795e+00, -1.82994723e-01,\n",
              "            1.26559734e+00, -2.34980106e+00, -1.23895955e+00,\n",
              "           -2.80552459e+00,  1.09750278e-01, -1.88392782e+00,\n",
              "           -1.37440825e+00, -4.26196480e+00, -1.72939062e+00,\n",
              "           -2.69612670e+00, -1.93413508e+00],\n",
              "          [ 7.77517259e-01, -1.11678624e+00,  1.59639835e+00,\n",
              "           -3.10828179e-01, -1.31714201e+00, -8.35687995e-01,\n",
              "           -1.85791445e+00, -5.41451514e-01,  2.42899752e+00,\n",
              "            5.34635723e-01, -5.68066001e-01, -1.72127104e+00,\n",
              "            3.51455480e-01,  1.65681299e-02,  2.18238592e+00,\n",
              "            1.83525443e+00, -8.12828690e-02],\n",
              "          [ 9.88032460e-01,  9.72927272e-01, -6.31829560e-01,\n",
              "            1.65745616e+00, -6.69680178e-01,  1.56036806e+00,\n",
              "           -1.02732420e+00, -1.16376340e+00,  1.15551138e+00,\n",
              "           -1.23105514e+00,  6.55726969e-01, -2.13778710e+00,\n",
              "           -1.69845676e+00,  2.26985693e+00,  9.85440433e-01,\n",
              "           -8.00281942e-01,  7.61448145e-01],\n",
              "          [ 1.23550820e+00, -1.13388860e+00, -2.67631388e+00,\n",
              "            8.91862750e-01, -1.66625941e+00, -1.08168972e+00,\n",
              "            1.28169665e-02, -4.53223176e-02,  2.07682085e+00,\n",
              "            2.12340617e+00, -1.45705223e+00, -3.10163212e+00,\n",
              "           -1.09160256e+00, -3.31478643e+00, -2.82178211e+00,\n",
              "           -5.68146825e-01, -8.27788860e-02],\n",
              "          [ 1.06241524e+00,  1.76369286e+00,  8.21451664e-01,\n",
              "            5.71782231e-01, -6.19584799e-01,  1.52410924e+00,\n",
              "           -2.90787411e+00,  1.86575937e+00,  8.70252848e-01,\n",
              "           -1.76125193e+00, -1.57594669e+00, -7.69136012e-01,\n",
              "            1.17213583e+00,  1.62886083e+00,  3.48358464e+00,\n",
              "           -1.70902085e+00, -1.41629028e+00],\n",
              "          [ 2.36498997e-01, -1.33960283e+00, -2.08377242e-01,\n",
              "           -1.29803133e+00, -1.42778218e-01,  9.62913215e-01,\n",
              "            1.13327980e+00,  1.18146467e+00, -1.25571668e+00,\n",
              "            2.04966247e-01, -1.44096279e+00, -1.63899231e+00,\n",
              "           -2.15268803e+00, -1.99356854e+00, -5.08859038e-01,\n",
              "           -3.53877991e-01, -2.02174425e+00],\n",
              "          [ 2.15038508e-01, -6.39782727e-01, -9.24057126e-01,\n",
              "            2.50381732e+00, -1.01615906e+00, -9.87001598e-01,\n",
              "           -4.65441607e-02,  1.24075897e-02, -1.20862961e+00,\n",
              "            8.08612227e-01,  1.45415378e+00, -6.83347702e-01,\n",
              "            1.34060502e+00, -6.99482977e-01,  7.50039995e-01,\n",
              "            5.55929184e-01, -5.69161832e-01],\n",
              "          [-3.93915504e-01, -1.92656183e+00, -4.20793474e-01,\n",
              "            1.10132921e+00, -9.34221268e-01,  6.15891218e-01,\n",
              "            1.63563931e+00,  1.03713334e+00, -2.40662909e+00,\n",
              "           -2.41137195e+00,  3.77522796e-01,  1.33206010e+00,\n",
              "            1.69772458e+00,  5.06840348e-01, -2.04929376e+00,\n",
              "           -1.76708007e+00, -3.64270359e-02],\n",
              "          [ 8.10757056e-02,  9.06016290e-01,  9.07430500e-02,\n",
              "            6.62773252e-01, -3.16669106e+00,  3.03963512e-01,\n",
              "            7.31126487e-01, -1.15304899e+00,  1.48512447e+00,\n",
              "           -3.56529522e+00, -1.29856586e+00, -2.82713294e+00,\n",
              "           -1.98230124e+00,  3.00852835e-01,  2.26434422e+00,\n",
              "           -2.15840340e+00, -3.32901120e+00],\n",
              "          [ 6.31302893e-01, -1.39547348e+00,  1.61583650e+00,\n",
              "            4.10996467e-01, -2.42853090e-01,  3.81023884e-02,\n",
              "           -4.29471254e-01,  7.63166100e-02, -1.69869721e+00,\n",
              "           -2.45602846e+00, -1.29015326e+00, -1.02109444e+00,\n",
              "            9.30546701e-01, -2.65263486e+00, -2.25731230e+00,\n",
              "            1.34731770e-01, -3.30337596e+00],\n",
              "          [ 1.74694407e+00, -1.96654284e+00,  1.53230500e+00,\n",
              "            5.66948175e-01, -2.09794283e+00, -3.33087295e-01,\n",
              "           -3.65932345e-01, -1.25922918e+00,  1.61310279e+00,\n",
              "            7.33773887e-01,  5.20001590e-01,  7.86389232e-01,\n",
              "           -1.09163105e+00,  1.94584537e+00, -1.22595799e+00,\n",
              "           -1.57782435e+00,  2.04780078e+00],\n",
              "          [ 1.91552055e+00, -4.43860978e-01,  6.81616008e-01,\n",
              "           -1.36605000e+00, -9.75389063e-01, -9.18446258e-02,\n",
              "           -1.69685781e-01, -1.10625005e+00,  3.71926069e-01,\n",
              "           -1.49996376e+00, -2.71394420e+00, -4.22883701e+00,\n",
              "           -8.67410839e-01, -1.29880440e+00, -2.10437512e+00,\n",
              "           -8.43744218e-01, -1.39847183e+00],\n",
              "          [ 1.60360515e-01,  9.61009383e-01, -1.45756996e+00,\n",
              "            5.13520658e-01,  1.25533044e+00, -1.35545814e+00,\n",
              "           -8.48945677e-01,  1.67175615e+00, -2.17719078e+00,\n",
              "           -2.85523653e+00,  7.23335743e-01, -5.37175417e-01,\n",
              "            2.29151440e+00, -5.10040879e-01, -1.92445207e+00,\n",
              "           -2.66454768e+00, -9.85688865e-01],\n",
              "          [ 1.06663799e+00, -5.54475129e-01,  8.83504689e-01,\n",
              "           -1.12149930e+00,  5.47391415e-01,  6.24776661e-01,\n",
              "           -2.89239287e+00, -5.75860560e-01, -1.19628382e+00,\n",
              "           -2.52115297e+00,  1.03854120e+00, -1.51188850e+00,\n",
              "           -5.68937540e-01, -1.26831460e+00, -8.59649777e-01,\n",
              "           -3.12541127e+00, -1.80387414e+00],\n",
              "          [-2.38930702e-01,  1.02238250e+00, -1.02832532e+00,\n",
              "            8.92692804e-01, -5.03790498e-01,  1.46205580e+00,\n",
              "           -4.78189260e-01, -1.09381294e+00, -7.78240338e-02,\n",
              "            3.01056087e-01, -4.14895624e-01,  5.11742413e-01,\n",
              "           -1.40781415e+00,  5.73745906e-01,  3.84645522e-01,\n",
              "           -6.03667021e-01,  6.67078644e-02],\n",
              "          [-3.00808460e-01,  1.71964741e+00,  5.51914930e-01,\n",
              "            6.28121436e-01,  1.96321583e+00,  1.03333533e+00,\n",
              "           -2.53147166e-02, -1.94433153e+00, -2.36754566e-01,\n",
              "           -2.26207256e+00, -1.01827061e+00,  1.77378964e+00,\n",
              "           -1.61764061e+00, -1.95440638e+00, -1.87989092e+00,\n",
              "           -1.86857355e+00, -1.28245687e+00],\n",
              "          [ 6.19691372e-01, -4.98182565e-01, -8.28483820e-01,\n",
              "           -1.82852924e-01,  1.26225126e+00, -1.48851848e+00,\n",
              "           -1.09095240e+00, -5.96250057e-01, -1.92426217e+00,\n",
              "           -7.74110138e-01,  1.34526074e+00,  1.85962164e+00,\n",
              "           -1.25704467e+00, -2.79972243e+00, -2.65215254e+00,\n",
              "            1.46519661e-01, -1.09745312e+00],\n",
              "          [ 9.25576866e-01, -3.25980425e-01,  1.16506052e+00,\n",
              "            4.45415437e-01,  6.12064958e-01, -1.27352393e+00,\n",
              "            7.28060067e-01, -3.51310539e+00,  2.96609139e+00,\n",
              "            1.43760502e+00,  4.64549273e-01,  2.77450037e+00,\n",
              "           -2.34500527e+00, -1.80391717e+00, -2.52127647e+00,\n",
              "           -1.45331764e+00, -1.79445708e+00],\n",
              "          [ 1.92009628e+00, -8.67183685e-01,  4.94267255e-01,\n",
              "            3.28652173e-01,  1.74063489e-01, -1.40706515e+00,\n",
              "           -4.57113177e-01, -3.48057672e-02, -5.54785311e-01,\n",
              "            6.41978920e-01, -2.94025213e-01,  1.00201213e+00,\n",
              "           -3.14606369e-01, -2.49295354e+00, -7.36937761e-01,\n",
              "           -1.16627097e+00, -2.83961773e+00],\n",
              "          [-9.17059064e-01,  4.52642441e-01,  1.12407243e+00,\n",
              "            2.03026366e+00,  1.31390905e+00,  1.91044104e+00,\n",
              "           -4.84754443e-01, -1.73083317e+00,  2.51576543e+00,\n",
              "           -1.01849616e+00,  1.92066419e+00,  1.11258841e+00,\n",
              "           -1.55067396e+00,  1.04712939e+00,  5.31250119e-01,\n",
              "           -6.39751315e-01,  5.90259612e-01],\n",
              "          [-7.98826441e-02,  1.03231736e-01, -1.54168415e+00,\n",
              "           -1.52819324e+00,  1.53044891e+00,  2.49208108e-01,\n",
              "           -1.34646487e+00, -3.05788189e-01, -1.94655740e+00,\n",
              "            1.40749037e+00, -7.78692961e-01, -9.31108057e-01,\n",
              "            2.27038574e+00, -3.09132195e+00, -1.01883221e+00,\n",
              "            1.18317413e+00, -2.03179502e+00],\n",
              "          [ 4.51333046e-01, -4.42921519e-01, -2.85743386e-01,\n",
              "            6.97100520e-01, -1.57852829e+00,  7.57170737e-01,\n",
              "           -3.78069319e-02, -8.30261469e-01, -6.98719859e-01,\n",
              "            6.66876256e-01,  2.00238362e-01, -1.58884835e+00,\n",
              "           -1.60344493e+00,  8.81464779e-01, -1.01829803e+00,\n",
              "            2.08708011e-02, -3.00437778e-01],\n",
              "          [ 6.50212049e-01, -6.50725663e-01, -1.76508272e+00,\n",
              "           -3.46989393e-01,  1.07959008e+00,  2.71887854e-02,\n",
              "            2.10009485e-01, -2.68238544e+00,  4.39636350e-01,\n",
              "           -2.62111878e+00,  2.16830194e-01, -9.23302412e-01,\n",
              "           -1.93788290e-01, -2.43334866e+00,  2.59137124e-01,\n",
              "           -1.12102842e+00, -7.19914138e-01],\n",
              "          [-4.36638713e-01, -4.04949218e-01,  5.82610779e-02,\n",
              "           -1.82136798e+00, -2.28083229e+00,  9.02701020e-01,\n",
              "            8.39359090e-02,  5.51224232e-01, -1.84870315e+00,\n",
              "           -1.32713926e+00, -2.71553397e-01, -9.03203726e-01,\n",
              "            1.67712212e+00, -2.54273319e+00, -5.77476025e-01,\n",
              "            1.90500295e+00, -2.92804867e-01],\n",
              "          [-6.38851047e-01, -1.46977055e+00, -1.95504594e+00,\n",
              "            1.31008875e+00, -1.36688328e+00,  1.94358456e+00,\n",
              "            6.73706234e-01,  2.91319042e-01,  1.46730220e+00,\n",
              "            1.46125233e+00,  1.23514318e+00, -1.64808404e+00,\n",
              "            1.83692619e-01, -6.89116478e-01, -1.93499303e+00,\n",
              "           -2.11298561e+00, -9.25544024e-01],\n",
              "          [-1.14668690e-01,  1.08298779e+00,  7.96245635e-02,\n",
              "            9.39052641e-01, -3.74665523e+00,  1.80190957e+00,\n",
              "           -2.51338792e+00,  6.26338184e-01,  5.78151524e-01,\n",
              "           -2.85349756e-01, -2.50549293e+00, -3.76245070e+00,\n",
              "           -1.28990757e+00, -3.69889975e-01, -3.05986357e+00,\n",
              "           -6.66608572e-01, -3.29094023e-01],\n",
              "          [-1.08946502e+00,  1.18719077e+00,  1.40556049e+00,\n",
              "            1.01346660e+00,  6.11382186e-01, -8.85937870e-01,\n",
              "           -2.79747576e-01, -1.42836586e-01,  4.55723628e-02,\n",
              "            1.22794163e+00,  1.46420085e+00, -1.73277271e+00,\n",
              "           -4.74781573e-01, -9.09202695e-01,  2.81843722e-01,\n",
              "            3.38130176e-01, -1.39469171e+00],\n",
              "          [ 2.17726916e-01, -1.80332696e+00, -4.00067425e+00,\n",
              "            2.93253455e-02, -1.29265174e-01,  5.79370141e-01,\n",
              "            1.12408364e+00,  9.27731097e-01, -2.47248554e+00,\n",
              "           -1.03901279e+00,  6.10623479e-01, -9.07567978e-01,\n",
              "           -1.94228804e+00, -2.30477309e+00, -2.62546158e+00,\n",
              "           -1.26899815e+00, -1.36113632e-02],\n",
              "          [ 1.61836553e+00, -3.19855869e-01, -6.70751870e-01,\n",
              "           -5.83734453e-01, -1.61797523e-01, -3.28965962e-01,\n",
              "           -3.33355874e-01, -1.00610459e+00, -1.85281360e+00,\n",
              "           -1.03473938e+00, -4.46483940e-01, -3.24202776e-02,\n",
              "           -9.45304155e-01,  1.45398664e+00, -1.37744272e+00,\n",
              "           -1.73141897e+00,  1.46429098e+00],\n",
              "          [ 9.73962605e-01, -4.98184487e-02, -1.03994083e+00,\n",
              "           -5.57177126e-01, -2.25121349e-01, -7.40600586e-01,\n",
              "           -1.16612005e+00,  1.54935285e-01, -1.29187852e-01,\n",
              "           -1.50445521e+00,  4.78546083e-01, -1.45626688e+00,\n",
              "           -2.79057115e-01, -1.15782775e-01, -4.71897781e-01,\n",
              "           -1.38913679e+00,  1.88251674e-01],\n",
              "          [-5.41939497e-01,  1.16519809e+00,  2.05727172e+00,\n",
              "            4.30811346e-01, -8.08937371e-01,  1.41348791e+00,\n",
              "           -8.90013397e-01,  1.55664480e+00, -4.74040061e-01,\n",
              "           -2.00967407e+00, -5.88486850e-01,  4.43331376e-02,\n",
              "            9.86374319e-02, -8.40723038e-01, -1.83557796e+00,\n",
              "           -2.16187429e+00, -1.13215959e+00],\n",
              "          [ 9.68939543e-01, -5.35932660e-01, -6.24873256e-03,\n",
              "           -5.69704354e-01, -1.79010487e+00, -2.42150712e+00,\n",
              "           -9.56560373e-01,  2.99164325e-01,  1.56102943e+00,\n",
              "            1.23474747e-02, -1.97959745e+00, -2.38077617e+00,\n",
              "           -2.32997239e-01, -2.06999853e-01, -1.35616863e+00,\n",
              "           -2.95421004e-01, -2.13810539e+00],\n",
              "          [ 2.96085805e-01,  3.22276860e-01,  4.67179507e-01,\n",
              "            9.17203963e-01, -1.33338797e+00, -6.55452132e-01,\n",
              "           -1.92585850e+00,  2.65322995e+00, -2.22950792e+00,\n",
              "           -1.79710761e-01, -2.81644535e+00,  1.56808996e+00,\n",
              "           -2.87648678e+00,  1.56126487e+00,  9.11312699e-01,\n",
              "           -2.97257328e+00, -3.59296250e+00],\n",
              "          [ 6.65326715e-01, -6.10130847e-01,  1.88278461e+00,\n",
              "           -6.68300509e-01, -2.48033786e+00,  1.80948520e+00,\n",
              "           -7.10882694e-02, -2.00306201e+00, -1.56612039e+00,\n",
              "           -1.43003678e+00, -2.24592254e-01, -1.58999956e+00,\n",
              "           -3.32897830e+00, -2.23562694e+00, -1.65420771e+00,\n",
              "           -2.16424966e+00, -1.43695998e+00],\n",
              "          [-2.11573616e-02, -3.37584287e-01, -6.53902173e-01,\n",
              "            1.97073126e+00, -4.93562788e-01,  3.03327963e-02,\n",
              "           -1.59517682e+00,  2.16737652e+00, -1.27227211e+00,\n",
              "           -1.50384521e+00, -2.70232797e-01, -1.49037790e+00,\n",
              "           -3.44107676e+00, -6.36299431e-01,  1.24106467e+00,\n",
              "           -6.29805386e-01, -8.80692303e-02],\n",
              "          [ 3.29902798e-01, -7.38128543e-01, -1.05860248e-01,\n",
              "            9.50261593e-01,  2.63555229e-01, -7.28537917e-01,\n",
              "            4.33179051e-01, -1.47182178e+00,  8.15387130e-01,\n",
              "            8.16553533e-01, -2.63215208e+00,  5.32335877e-01,\n",
              "            1.68727505e+00, -2.57044649e+00,  1.12086666e+00,\n",
              "            1.74034536e+00, -2.29861468e-01],\n",
              "          [ 1.67086685e+00, -1.06333315e+00, -1.46087718e+00,\n",
              "           -4.40726906e-01, -1.20080018e+00, -9.20228004e-01,\n",
              "           -8.11211884e-01, -2.55614728e-01,  1.91457093e+00,\n",
              "            2.23396510e-01, -1.77862632e+00, -7.37666070e-01,\n",
              "           -8.15623105e-01, -3.59940290e-01,  1.19601834e+00,\n",
              "            1.01320076e+00,  1.19483864e+00],\n",
              "          [ 7.93771982e-01, -5.85280478e-01,  7.40210414e-01,\n",
              "            2.80409425e-01, -5.71230531e-01, -1.16085839e+00,\n",
              "            1.04051721e+00, -1.37867486e+00, -1.28932595e+00,\n",
              "           -8.55535209e-01,  3.02910954e-01,  1.02304280e+00,\n",
              "           -4.47842836e-01, -4.33402419e-01, -1.10815966e+00,\n",
              "           -1.21533737e-01,  3.39720130e-01],\n",
              "          [ 3.04865122e-01, -1.00492251e+00,  6.59074783e-01,\n",
              "            2.00284767e+00,  5.82944453e-01, -1.24383175e+00,\n",
              "           -1.52612254e-01, -2.56896663e+00,  1.50902116e+00,\n",
              "            1.06153047e+00,  2.03272009e+00,  2.11641026e+00,\n",
              "           -2.74741578e+00,  6.53148711e-01, -6.73721969e-01,\n",
              "            1.15984313e-01,  2.79265499e+00],\n",
              "          [ 8.93243253e-02,  1.15470946e+00, -1.37981725e+00,\n",
              "            2.53946686e+00,  4.65390950e-01, -1.04417038e+00,\n",
              "            9.06253099e-01, -1.31085598e+00, -3.85791123e-01,\n",
              "           -1.38316655e+00,  5.50052643e-01, -1.30517709e+00,\n",
              "           -1.63545877e-01, -1.51224577e+00, -1.46088159e+00,\n",
              "           -1.12326741e+00, -3.16193271e+00],\n",
              "          [ 5.34556448e-01, -1.54164910e+00, -4.97292399e-01,\n",
              "            6.85631216e-01, -1.81395817e+00,  1.03011680e+00,\n",
              "            1.35374939e+00,  8.23001564e-01, -2.95437765e+00,\n",
              "           -1.49921596e+00, -5.34572661e-01, -1.04522943e+00,\n",
              "            5.25844097e-01, -2.42572761e+00,  1.61326182e+00,\n",
              "            2.42720342e+00, -1.37620115e+00],\n",
              "          [ 1.21695173e+00,  9.19752657e-01,  6.12440884e-01,\n",
              "           -8.29116285e-01, -7.19894409e-01, -9.72402096e-01,\n",
              "           -7.63579071e-01, -1.28749478e+00, -1.80657864e+00,\n",
              "            2.57615387e-01,  1.92560747e-01, -5.68293743e-02,\n",
              "           -1.02436781e+00,  2.17471194e+00, -1.90490186e+00,\n",
              "           -9.08337653e-01,  1.22634494e+00],\n",
              "          [-8.48501697e-02,  1.02649951e+00,  1.82997513e+00,\n",
              "           -1.78367209e+00,  1.19086063e+00, -6.97250605e-01,\n",
              "           -9.19146955e-01,  2.83470362e-01,  7.58569896e-01,\n",
              "           -2.68275762e+00, -6.87203050e-01, -2.01644135e+00,\n",
              "           -1.04203629e+00, -2.92142248e+00,  1.15270413e-01,\n",
              "           -4.04500818e+00, -2.41265082e+00],\n",
              "          [ 1.11629212e+00,  7.93980956e-01, -1.37647355e+00,\n",
              "           -1.50278342e+00, -6.38423324e-01,  3.00925672e-02,\n",
              "            2.76443213e-01, -1.25859767e-01, -7.46700346e-01,\n",
              "           -2.08227134e+00, -2.60891485e+00, -1.78797853e+00,\n",
              "            1.94256842e-01, -3.81763875e-01,  1.29079866e+00,\n",
              "            6.99159622e-01,  1.03020084e+00],\n",
              "          [ 1.06336784e+00, -1.95782924e+00, -3.46350968e-02,\n",
              "            6.21916592e-01, -2.23011327e+00,  6.00443721e-01,\n",
              "           -9.56476986e-01, -1.65676999e+00, -5.95359981e-01,\n",
              "           -4.36754562e-02, -4.03144211e-01,  4.69883710e-01,\n",
              "            1.81521583e+00,  4.71176982e-01,  6.20055318e-01,\n",
              "            1.30979741e+00,  1.87675178e+00]], dtype=float32),\n",
              "   array([ 1.3004961 , -0.11050223, -0.02817711, -0.30962402, -0.5181354 ,\n",
              "           0.3915542 ,  0.01566633, -0.72608864, -2.0538058 , -0.997631  ,\n",
              "           0.3324473 , -0.5295414 , -1.0065742 , -2.3540046 , -1.1619717 ,\n",
              "          -1.8773602 , -2.4214408 ], dtype=float32)),\n",
              "  ()),\n",
              " ((), (((), ((), ())), ((), ()), ()), (), ()))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYNXN_Wez8GA"
      },
      "source": [
        "<a name=\"4\"></a>\n",
        "# Part 4:  Compute Accuracy\n",
        "\n",
        "You will now evaluate in the test set. Previously, you have seen the accuracy on the training set and the validation (noted as eval) set. You will now evaluate on your test set. To get a good evaluation, you will need to create a mask to avoid counting the padding tokens when computing the accuracy. \n",
        "\n",
        "<a name=\"ex04\"></a>\n",
        "### Exercise 04\n",
        "\n",
        "**Instructions:** Write a program that takes in your model and uses it to evaluate on the test set. You should be able to get an accuracy of 95%.  \n",
        "\n",
        "\n",
        "\n",
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>More Detailed Instructions </b></font>\n",
        "</summary>\n",
        "\n",
        "* *Step 1*: model(sentences) will give you the predicted output. \n",
        "\n",
        "* *Step 2*: Prediction will produce an output with an added dimension. For each sentence, for each word, there will be a vector of probabilities for each tag type. For each sentence,word, you need to pick the maximum valued tag. This will require `np.argmax` and careful use of the `axis` argument.\n",
        "* *Step 3*: Create a mask to prevent counting pad characters. It has the same dimension as output. An example below on matrix comparison provides a hint.\n",
        "* *Step 4*: Compute the accuracy metric by comparing your outputs against your test labels. Take the sum of that and divide by the total number of **unpadded** tokens. Use your mask value to mask the padded tokens. Return the accuracy. \n",
        "</detail>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHLtXCrFzZka",
        "outputId": "07a20f17-d230-40b7-d958-688efe7c10e4"
      },
      "source": [
        "#Example of a comparision on a matrix \n",
        "a = np.array([1, 2, 3, 4])\n",
        "a == 2\n",
        "\n",
        "# create the evaluation inputs\n",
        "x, y = next(data_generator(len(test_sentences), test_sentences, test_labels, vocab['<PAD>']))\n",
        "print(\"input shapes\", x.shape, y.shape)\n",
        "\n",
        "# sample prediction\n",
        "tmp_pred = model(x)\n",
        "print(type(tmp_pred))\n",
        "print(f\"tmp_pred has shape: {tmp_pred.shape}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input shapes (7194, 70) (7194, 70)\n",
            "<class 'jaxlib.xla_extension.DeviceArray'>\n",
            "tmp_pred has shape: (7194, 70, 17)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wdz_xI7t3rSA"
      },
      "source": [
        "Note that the model's prediction has 3 axes: \n",
        "- the number of examples\n",
        "- the number of words in each example (padded to be as long as the longest sentence in the batch)\n",
        "- the number of possible targets (the 17 named entity tags)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5IyaFiU3pj7",
        "outputId": "a368d7f1-3ffd-496d-ee8e-4378b656586b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "# GRADED FUNCTION: evaluate_prediction\n",
        "def evaluate_prediction(pred, labels, pad):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "        pred: prediction array with shape \n",
        "            (num examples, max sentence length in batch, num of classes)\n",
        "        labels: array of size (batch_size, seq_len)\n",
        "        pad: integer representing pad character\n",
        "    Outputs:\n",
        "        accuracy: float\n",
        "    \"\"\"\n",
        "    ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
        "## step 1 ##\n",
        "    outputs = np.argmax(pred,axis = 2)\n",
        "    print(\"outputs shape:\", outputs.shape)\n",
        "\n",
        "## step 2 ##\n",
        "    mask = ~np.equal(labels,pad)\n",
        "    print(\"mask shape:\", mask.shape, \"mask[0][20:30]:\", mask[0][20:30])\n",
        "## step 3 ##\n",
        "    accuracy = np.sum(outputs == labels) / float(np.sum(mask))\n",
        "    ### END CODE HERE ###\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "accuracy = evaluate_prediction(model(x), y, vocab['<PAD>'])\n",
        "print(\"accuracy: \", accuracy)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "outputs shape: (7194, 70)\n",
            "mask shape: (7194, 70) mask[0][20:30]: [ True  True  True False False False False False False False]\n",
            "accuracy:  0.95383847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdzasELg_QgM"
      },
      "source": [
        "# This is the function you will be using to test your own sentence.\n",
        "def predict(sentence, model, vocab, tag_map):\n",
        "    s = [vocab[token] if token in vocab else vocab['UNK'] for token in sentence.split(' ')]\n",
        "    batch_data = np.ones((1, len(s)))\n",
        "    batch_data[0][:] = s\n",
        "    sentence = np.array(batch_data).astype(int)\n",
        "    output = model(sentence)\n",
        "    outputs = np.argmax(output, axis=2)\n",
        "    labels = list(tag_map.keys())\n",
        "    pred = []\n",
        "    for i in range(len(outputs[0])):\n",
        "        idx = outputs[0][i] \n",
        "        pred_label = labels[idx]\n",
        "        pred.append(pred_label)\n",
        "    return pred\n",
        "    "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVXOROYw_gzz",
        "outputId": "1eaf888b-5ae0-4d78-e572-b1204d150b51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Try the output for the introduction example\n",
        "#sentence = \"Many French citizens are goin to visit Morocco for summer\"\n",
        "#sentence = \"Sharon Floyd flew to Miami last Friday\"\n",
        "\n",
        "# New york times news:\n",
        "sentence = \"\"\"Prime Minister Narendra Modi revamped his council of ministers on Wednesday in a first since assuming charges for a second term. The Union council of ministers, which will be expanded with the swearing-in of new entrants this evening, is expected to have more representation from socially and economically backward communities, of women and people with administrative and legislative experience, people aware of the matter said.\n",
        "\n",
        "\n",
        "\n",
        "As many as 43 new ministers were sworn in Wednesday evening in the Prime Minister's new cabinet. In another pointer to the imminent Cabinet reshuffle, social justice and empowerment minister Thaawarchand Gehlot’s appointment as Karnataka governor caused another ministerial vacancy.\n",
        "\n",
        "Ahead of the rejig, several ministers resigned from their posts, Union health minister Harsh Vardhan was one of them. Union ministers Babul Supriyo, Santosh Gangwar, Ramesh Pokhriyal Nishank, Sadananda Gowda among others stepped down from their office on Wednesday.\n",
        "\n",
        "\"\"\"\n",
        "s = [vocab[token] if token in vocab else vocab['UNK'] for token in sentence.split(' ')]\n",
        "predictions = predict(sentence, model, vocab, tag_map)\n",
        "for x,y in zip(sentence.split(' '), predictions):\n",
        "    if y != 'O':\n",
        "        print(x,y)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prime B-per\n",
            "Minister I-per\n",
            "Narendra I-per\n",
            "Modi I-per\n",
            "revamped I-per\n",
            "Wednesday B-tim\n",
            "assuming I-tim\n",
            "Union I-org\n",
            "Wednesday B-tim\n",
            "evening I-tim\n",
            "Prime B-geo\n",
            "Minister's I-geo\n",
            "Cabinet B-geo\n",
            "reshuffle, I-org\n",
            "Karnataka B-geo\n",
            "Union B-geo\n",
            "Nishank, I-per\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xic8aI72_iV3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}